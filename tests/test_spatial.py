"""
Tests for spatial analysis utilities.
"""

import pytest
import numpy as np
from unittest.mock import patch, MagicMock

from driada.utils.spatial import (
    compute_occupancy_map,
    compute_rate_map,
    extract_place_fields,
    compute_spatial_information_rate,
    compute_grid_score,
    compute_spatial_decoding_accuracy,
    compute_spatial_information,
    filter_by_speed,
    filter_by_direction,
    analyze_spatial_coding,
    compute_spatial_metrics,
)
from driada.information import TimeSeries, MultiTimeSeries


class TestOccupancyMap:
    """Test occupancy map computation."""
    
    def test_compute_occupancy_map_basic(self):
        """Test basic occupancy map computation."""
        # Create simple trajectory
        positions = np.array([
            [0.0, 0.0],
            [0.1, 0.0],
            [0.2, 0.0],
            [0.3, 0.1],
            [0.4, 0.2],
        ])
        
        occupancy, x_edges, y_edges = compute_occupancy_map(
            positions, 
            arena_bounds=((0, 0.5), (0, 0.5)),
            bin_size=0.1,
            min_occupancy=0
        )
        
        # Check shape
        assert occupancy.shape == (5, 5)
        assert len(x_edges) == 6
        assert len(y_edges) == 6
        
        # Check that visited bins have non-zero occupancy
        assert occupancy[0, 0] > 0  # Bottom-left visited
        assert np.sum(occupancy > 0) > 0
    
    def test_compute_occupancy_map_smoothing(self):
        """Test occupancy map with smoothing."""
        positions = np.random.rand(100, 2)
        
        # Without smoothing
        occ_no_smooth, _, _ = compute_occupancy_map(
            positions,
            bin_size=0.1,
            smooth_sigma=None
        )
        
        # With smoothing
        occ_smooth, _, _ = compute_occupancy_map(
            positions,
            bin_size=0.1,
            smooth_sigma=1.0
        )
        
        # Smoothed should have fewer NaN values
        assert np.sum(np.isnan(occ_smooth)) <= np.sum(np.isnan(occ_no_smooth))
    
    def test_compute_occupancy_map_min_occupancy(self):
        """Test minimum occupancy threshold."""
        positions = np.array([[0.05, 0.05]])  # Single point
        
        occupancy, _, _ = compute_occupancy_map(
            positions,
            arena_bounds=((0, 0.1), (0, 0.1)),
            bin_size=0.05,
            min_occupancy=2.0  # Higher than single visit
        )
        
        # All bins should be NaN due to min occupancy
        assert np.all(np.isnan(occupancy))
    
    def test_compute_occupancy_map_auto_bounds(self):
        """Test automatic arena bounds detection."""
        positions = np.random.rand(100, 2) * 2.0  # Range 0-2
        
        occupancy, x_edges, y_edges = compute_occupancy_map(
            positions,
            arena_bounds=None,  # Auto-detect
            bin_size=0.1
        )
        
        # Check bounds include all data with margin
        assert x_edges[0] < positions[:, 0].min()
        assert x_edges[-1] > positions[:, 0].max()
        assert y_edges[0] < positions[:, 1].min()
        assert y_edges[-1] > positions[:, 1].max()


class TestRateMap:
    """Test firing rate map computation."""
    
    def test_compute_rate_map_basic(self):
        """Test basic rate map computation."""
        # Create occupancy map
        positions = np.random.rand(1000, 2)
        occupancy, x_edges, y_edges = compute_occupancy_map(
            positions, bin_size=0.1, min_occupancy=0
        )
        
        # Create continuous neural signal (e.g., calcium)
        neural_signal = np.random.exponential(1.0, 1000)  # Positive continuous signal
        
        rate_map = compute_rate_map(
            neural_signal, positions, occupancy, x_edges, y_edges,
            smooth_sigma=None
        )
        
        # Check shape matches occupancy
        assert rate_map.shape == occupancy.shape
        
        # Check no negative rates
        assert np.all(rate_map >= 0)
        
        # Check NaN handling
        assert not np.any(np.isnan(rate_map[~np.isnan(occupancy)]))
    
    def test_compute_rate_map_smoothing(self):
        """Test rate map smoothing."""
        positions = np.random.rand(1000, 2)
        occupancy, x_edges, y_edges = compute_occupancy_map(
            positions, bin_size=0.1
        )
        
        # Create continuous signal with some structure
        neural_signal = np.abs(np.random.normal(2.0, 0.5, 1000))
        
        # Without smoothing
        rate_no_smooth = compute_rate_map(
            neural_signal, positions, occupancy, x_edges, y_edges,
            smooth_sigma=None
        )
        
        # With smoothing
        rate_smooth = compute_rate_map(
            neural_signal, positions, occupancy, x_edges, y_edges,
            smooth_sigma=2.0
        )
        
        # Smoothed map should be smoother (have valid values)
        valid_mask = ~np.isnan(occupancy)
        if np.sum(valid_mask) > 10:
            # Check that smoothing was applied (values should differ)
            assert not np.allclose(rate_smooth[valid_mask], rate_no_smooth[valid_mask])
    
    def test_compute_rate_map_no_spikes(self):
        """Test rate map with no activity."""
        positions = np.random.rand(100, 2)
        occupancy, x_edges, y_edges = compute_occupancy_map(positions)
        
        neural_signal = np.zeros(100)  # No activity
        
        rate_map = compute_rate_map(
            neural_signal, positions, occupancy, x_edges, y_edges
        )
        
        # Should be all zeros
        assert np.all(rate_map == 0)


class TestPlaceFields:
    """Test place field extraction."""
    
    def test_extract_place_fields_single_field(self):
        """Test extraction of single place field."""
        # Create rate map with single peak
        rate_map = np.zeros((20, 20))
        rate_map[8:12, 8:12] = 5.0  # Central place field
        rate_map[10, 10] = 10.0  # Peak
        
        fields = extract_place_fields(
            rate_map,
            min_peak_rate=5.0,
            min_field_size=4,
            peak_to_mean_ratio=1.2
        )
        
        assert len(fields) == 1
        assert fields[0]['peak_rate'] == 10.0
        assert fields[0]['size'] >= 4
        # Center should be near (10, 10) - allow for center of mass calculation differences
        center = fields[0]['center']
        assert abs(center[0] - 10) <= 1
        assert abs(center[1] - 10) <= 1
    
    def test_extract_place_fields_multiple(self):
        """Test extraction of multiple place fields."""
        # Create rate map with two peaks
        rate_map = np.zeros((30, 30))
        rate_map[5:8, 5:8] = 3.0
        rate_map[6, 6] = 6.0  # First peak
        rate_map[20:23, 20:23] = 3.0
        rate_map[21, 21] = 6.0  # Second peak
        
        fields = extract_place_fields(
            rate_map,
            min_peak_rate=5.0,
            min_field_size=4
        )
        
        assert len(fields) == 2
        assert all(f['peak_rate'] >= 5.0 for f in fields)
    
    def test_extract_place_fields_size_threshold(self):
        """Test field size threshold."""
        # Small field that should be rejected
        rate_map = np.zeros((20, 20))
        rate_map[10, 10] = 10.0  # Single bin peak
        
        fields = extract_place_fields(
            rate_map,
            min_peak_rate=5.0,
            min_field_size=4  # Requires at least 4 bins
        )
        
        assert len(fields) == 0


class TestSpatialInformation:
    """Test spatial information metrics."""
    
    def test_compute_spatial_information_rate_uniform(self):
        """Test spatial information for uniform firing."""
        # Uniform rate map and occupancy
        rate_map = np.ones((10, 10))
        occupancy_map = np.ones((10, 10))
        
        info = compute_spatial_information_rate(rate_map, occupancy_map)
        
        # Uniform firing has zero spatial information
        assert info == pytest.approx(0.0, abs=1e-10)
    
    def test_compute_spatial_information_rate_localized(self):
        """Test spatial information for localized firing."""
        # Highly localized firing
        rate_map = np.zeros((10, 10))
        rate_map[5, 5] = 10.0  # Single location
        
        occupancy_map = np.ones((10, 10))
        
        info = compute_spatial_information_rate(rate_map, occupancy_map)
        
        # Localized firing has high spatial information
        assert info > 0.0
    
    def test_compute_spatial_information_rate_no_firing(self):
        """Test spatial information with no firing."""
        rate_map = np.zeros((10, 10))
        occupancy_map = np.ones((10, 10))
        
        info = compute_spatial_information_rate(rate_map, occupancy_map)
        
        # No firing means no information
        assert info == 0.0


class TestGridScore:
    """Test grid score computation."""
    
    def test_compute_grid_score_regular_grid(self):
        """Test grid score for regular hexagonal pattern."""
        # Create simple hexagonal-like pattern
        size = 60
        rate_map = np.zeros((size, size))
        
        # Add peaks in hexagonal pattern (simplified)
        centers = [(30, 30), (40, 30), (35, 38), (25, 38), (20, 30), (25, 22), (35, 22)]
        for cx, cy in centers:
            rate_map[cy-2:cy+3, cx-2:cx+3] = 1.0
        
        score = compute_grid_score(rate_map)
        
        # Should have positive grid score for regular pattern
        assert score > -2.0
        assert score <= 2.0
    
    def test_compute_grid_score_random(self):
        """Test grid score for random pattern."""
        rate_map = np.random.rand(50, 50)
        
        score = compute_grid_score(rate_map)
        
        # Random pattern should have low grid score
        assert -2.0 <= score <= 2.0
    
    def test_compute_grid_score_single_peak(self):
        """Test grid score for single peak (not a grid)."""
        rate_map = np.zeros((30, 30))
        rate_map[15, 15] = 1.0
        
        score = compute_grid_score(rate_map, min_peaks=3)
        
        # Single peak should have low/negative score
        assert score < 0.0  # Not grid-like
        assert score >= -2.0  # Within valid range


class TestSpatialDecoding:
    """Test position decoding from neural activity."""
    
    def test_compute_spatial_decoding_accuracy_perfect(self):
        """Test decoding with perfect position encoding."""
        # Create neural activity that perfectly encodes position
        n_samples = 1000
        positions = np.column_stack([
            np.sin(np.linspace(0, 4*np.pi, n_samples)),
            np.cos(np.linspace(0, 4*np.pi, n_samples))
        ])
        
        # Neural activity directly encodes position
        neural_activity = positions.T  # 2 neurons encoding x and y
        
        metrics = compute_spatial_decoding_accuracy(
            neural_activity,
            positions,
            test_size=0.3,
            n_estimators=10,
            random_state=42
        )
        
        # Should have high accuracy
        assert metrics['r2_avg'] > 0.8
        assert metrics['r2_x'] > 0.8
        assert metrics['r2_y'] > 0.8
        assert metrics['mse'] < 0.1
    
    def test_compute_spatial_decoding_accuracy_random(self):
        """Test decoding with random neural activity."""
        n_samples = 500
        positions = np.random.rand(n_samples, 2)
        neural_activity = np.random.rand(10, n_samples)  # Random activity
        
        metrics = compute_spatial_decoding_accuracy(
            neural_activity,
            positions,
            test_size=0.3,
            random_state=42
        )
        
        # Random activity should have poor decoding
        assert metrics['r2_avg'] < 0.3  # Low R²
        assert metrics['mse'] > 0.05  # High error
    
    def test_compute_spatial_decoding_accuracy_with_logger(self):
        """Test decoding with logger."""
        import logging
        logger = logging.getLogger('test')
        
        positions = np.random.rand(100, 2)
        neural_activity = np.random.rand(5, 100)
        
        with patch.object(logger, 'info') as mock_info:
            metrics = compute_spatial_decoding_accuracy(
                neural_activity,
                positions,
                logger=logger
            )
            
            # Should log progress
            assert mock_info.call_count >= 2


class TestSpatialMI:
    """Test spatial mutual information computation."""
    
    def test_compute_spatial_information_arrays(self):
        """Test MI computation with numpy arrays."""
        # Create correlated data
        n_samples = 1000
        positions = np.random.rand(n_samples, 2)
        
        # Neural activity correlates with position
        neural_activity = positions[:, 0] + 0.1 * np.random.randn(n_samples)
        
        metrics = compute_spatial_information(neural_activity, positions)
        
        assert 'mi_x' in metrics
        assert 'mi_y' in metrics
        assert 'mi_total' in metrics
        
        # Should have higher MI with X than Y
        assert metrics['mi_x'] > metrics['mi_y']
        assert metrics['mi_total'] > 0
    
    def test_compute_spatial_information_timeseries(self):
        """Test MI computation with TimeSeries objects."""
        n_samples = 500
        positions = np.random.rand(n_samples, 2)
        neural_ts = TimeSeries(np.random.rand(n_samples), discrete=False)
        
        metrics = compute_spatial_information(neural_ts, positions)
        
        assert all(k in metrics for k in ['mi_x', 'mi_y', 'mi_total'])
        assert all(v >= 0 for v in metrics.values())
    
    def test_compute_spatial_information_multitimeseries(self):
        """Test MI computation with MultiTimeSeries."""
        n_samples = 500
        positions = np.random.rand(n_samples, 2)
        
        # Multiple neurons
        neural_data = [
            TimeSeries(np.random.rand(n_samples), discrete=False)
            for _ in range(3)
        ]
        neural_mts = MultiTimeSeries(neural_data)
        
        metrics = compute_spatial_information(neural_mts, positions)
        
        assert all(k in metrics for k in ['mi_x', 'mi_y', 'mi_total'])
    
    def test_compute_spatial_information_invalid_positions(self):
        """Test MI computation with invalid position dimensions."""
        neural_activity = np.random.rand(100)
        positions = np.random.rand(100, 3)  # 3D positions
        
        with pytest.raises(ValueError, match="Positions must be 2D"):
            compute_spatial_information(neural_activity, positions)


class TestSpeedFiltering:
    """Test speed-based data filtering."""
    
    def test_filter_by_speed_basic(self):
        """Test basic speed filtering."""
        # Create trajectory with varying speed
        t = np.linspace(0, 10, 100)
        positions = np.column_stack([t, np.sin(t)])
        
        data = {
            'positions': positions,
            'neural_activity': np.random.rand(100),
            'other_data': np.arange(100)
        }
        
        # Filter for moderate speeds
        filtered = filter_by_speed(data, speed_range=(0.5, 1.5))
        
        # Check filtering
        assert len(filtered['positions']) < len(positions)
        assert 'speed' in filtered
        assert np.all(filtered['speed'] >= 0.5)
        assert np.all(filtered['speed'] <= 1.5)
        
        # Check all arrays filtered consistently
        assert len(filtered['neural_activity']) == len(filtered['positions'])
        assert len(filtered['other_data']) == len(filtered['positions'])
    
    def test_filter_by_speed_no_movement(self):
        """Test filtering stationary periods."""
        # Stationary positions
        positions = np.ones((100, 2))
        
        data = {'positions': positions}
        
        # Filter out low speeds
        filtered = filter_by_speed(data, speed_range=(0.1, float('inf')))
        
        # Should filter out most/all samples
        assert len(filtered['positions']) <= 1  # Maybe keep first sample
    
    def test_filter_by_speed_smoothing(self):
        """Test speed smoothing effect."""
        # Create noisy trajectory
        positions = np.cumsum(np.random.randn(100, 2) * 0.1, axis=0)
        
        data = {'positions': positions}
        
        # Filter with smoothing
        filtered_smooth = filter_by_speed(
            data, 
            speed_range=(0, float('inf')),
            smooth_window=5
        )
        
        # Filter without smoothing  
        filtered_no_smooth = filter_by_speed(
            data,
            speed_range=(0, float('inf')),
            smooth_window=1
        )
        
        # Smoothed speed should have less variance
        assert np.var(filtered_smooth['speed']) < np.var(filtered_no_smooth['speed'])


class TestDirectionFiltering:
    """Test direction-based filtering."""
    
    def test_filter_by_direction_basic(self):
        """Test basic direction filtering."""
        # Create trajectory moving in different directions
        angles = np.linspace(0, 2*np.pi, 100)
        positions = np.column_stack([
            np.cumsum(np.cos(angles)),
            np.cumsum(np.sin(angles))
        ])
        
        data = {
            'positions': positions,
            'neural_activity': np.random.rand(100)
        }
        
        # Filter for eastward movement (around 0 radians)
        filtered = filter_by_direction(
            data,
            direction_range=(-np.pi/4, np.pi/4)
        )
        
        assert len(filtered['positions']) < 100
        assert 'direction' in filtered
        
        # Check directions are in range
        dirs = filtered['direction']
        assert np.all((dirs >= -np.pi/4) & (dirs <= np.pi/4))
    
    def test_filter_by_direction_wrapped(self):
        """Test direction filtering with wrapped angles."""
        # Movement around north (wrapping around ±π)
        positions = np.column_stack([
            np.arange(100) * 0.01,
            np.arange(100)  # Mostly northward
        ])
        
        data = {'positions': positions}
        
        # Filter for northward movement (π/2 ± π/4)
        filtered = filter_by_direction(
            data,
            direction_range=(np.pi/4, 3*np.pi/4)
        )
        
        # Most samples should pass
        assert len(filtered['positions']) > 50


class TestSpatialAnalysisPipeline:
    """Test comprehensive spatial analysis."""
    
    def test_analyze_spatial_coding_basic(self):
        """Test basic spatial coding analysis."""
        # Use synthetic data generation utilities
        from driada.experiment.synthetic import (
            generate_2d_random_walk,
            generate_2d_manifold_neurons,
            generate_pseudo_calcium_signal
        )
        
        # Generate trajectory
        n_samples = 1000
        positions = generate_2d_random_walk(
            length=n_samples,
            bounds=(0, 1),
            step_size=0.02,
            momentum=0.8,
            seed=42
        ).T  # Transpose to (n_samples, 2)
        
        # Generate place cell with center at (0.5, 0.5)
        firing_rates, centers = generate_2d_manifold_neurons(
            n_neurons=1,
            positions=positions.T,  # Expects (2, n_samples)
            field_sigma=0.15,  # Wider field for better detection
            baseline_rate=0.5,  # Hz
            peak_rate=10.0,  # Hz
            noise_std=0.1,
            grid_arrangement=False,
            seed=42
        )
        
        # Manually set center to ensure it's at (0.5, 0.5)
        centers[0] = [0.5, 0.5]
        
        # Regenerate with fixed center
        from driada.experiment.synthetic.manifold_spatial_2d import gaussian_place_field
        place_response = gaussian_place_field(positions.T, centers[0], sigma=0.15)
        firing_rate = 0.5 + (10.0 - 0.5) * place_response
        
        # Convert to calcium signal
        calcium_signal = generate_pseudo_calcium_signal(
            firing_rate,
            sampling_rate=20.0,
            decay_time=2.0,
            noise_std=0.5
        )
        
        # Reshape for analysis (needs n_neurons x n_samples)
        neural_activity = calcium_signal.reshape(1, -1)
        
        results = analyze_spatial_coding(
            neural_activity,
            positions,
            arena_bounds=((0, 1), (0, 1)),
            bin_size=0.1,
            min_peak_rate=2.0,  # Reasonable for calcium
            speed_range=None,  # No speed filtering for this test
            peak_to_mean_ratio=1.3,  # Lower ratio for calcium signals
            min_field_size=4  # At least 4 bins
        )
        
        # Check all expected outputs
        assert 'rate_maps' in results
        assert 'place_fields' in results
        assert 'spatial_info' in results
        assert 'grid_scores' in results
        assert 'decoding_accuracy' in results
        assert 'spatial_mi' in results
        assert 'summary' in results
        
        # Check dimensions
        assert len(results['rate_maps']) == 1
        assert len(results['spatial_info']) == 1
        
        # Debug info if test fails
        if results['summary']['n_place_cells'] == 0:
            rate_map = results['rate_maps'][0]
            print(f"Rate map shape: {rate_map.shape}")
            print(f"Rate map max: {np.nanmax(rate_map)}")
            print(f"Rate map mean: {np.nanmean(rate_map)}")
            print(f"Place fields found: {results['place_fields'][0]}")
            print(f"Spatial info: {results['spatial_info'][0]}")
        
        # Should detect place cell
        assert results['summary']['n_place_cells'] >= 1
        assert results['summary']['mean_spatial_info'] > 0
    
    def test_analyze_spatial_coding_with_speed_filter(self):
        """Test spatial analysis with speed filtering."""
        # Create trajectory with variable speed
        t = np.linspace(0, 20, 1000)
        positions = np.column_stack([
            t % 1,  # Sawtooth X
            (t // 1) * 0.1  # Stepped Y
        ])
        
        neural_activity = np.random.rand(2, 1000)
        
        results = analyze_spatial_coding(
            neural_activity,
            positions,
            speed_range=(0.05, 0.5)  # Filter speeds
        )
        
        # Should complete without error
        assert 'summary' in results
        assert results['summary']['n_place_cells'] >= 0
    
    def test_analyze_spatial_coding_with_logger(self):
        """Test spatial analysis with logging."""
        import logging
        logger = logging.getLogger('test')
        
        positions = np.random.rand(100, 2)
        neural_activity = np.random.rand(3, 100)
        
        with patch.object(logger, 'info') as mock_info:
            results = analyze_spatial_coding(
                neural_activity,
                positions,
                logger=logger
            )
            
            # Should log progress
            assert mock_info.called


class TestComputeSpatialMetrics:
    """Test selective metric computation."""
    
    def test_compute_spatial_metrics_all(self):
        """Test computing all metrics."""
        positions = np.random.rand(200, 2)
        neural_activity = np.random.rand(5, 200)
        
        results = compute_spatial_metrics(
            neural_activity,
            positions,
            metrics=None  # Compute all
        )
        
        # Should have all metric types
        assert 'decoding' in results
        assert 'information' in results
        assert 'place_fields' in results
        assert 'grid_scores' in results
    
    def test_compute_spatial_metrics_subset(self):
        """Test computing subset of metrics."""
        positions = np.random.rand(200, 2)
        neural_activity = np.random.rand(5, 200)
        
        results = compute_spatial_metrics(
            neural_activity,
            positions,
            metrics=['decoding', 'information']
        )
        
        # Should only have requested metrics
        assert 'decoding' in results
        assert 'information' in results
        assert 'place_fields' not in results
        assert 'grid_scores' not in results
    
    def test_compute_spatial_metrics_with_kwargs(self):
        """Test passing kwargs to analysis functions."""
        positions = np.random.rand(200, 2)
        neural_activity = np.random.rand(5, 200)
        
        results = compute_spatial_metrics(
            neural_activity,
            positions,
            metrics=['decoding'],
            test_size=0.2,  # Kwarg for decoding
            n_estimators=5  # Another kwarg
        )
        
        # Should complete without error
        assert 'decoding' in results
        assert 'r2_avg' in results['decoding']