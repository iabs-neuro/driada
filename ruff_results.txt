archive/repo.py:9:5: F841 Local variable `rp` is assigned to but never used
   |
 8 | def clone_org_repo(repo, org='iabs-neuro', branch='main', path_to_clone=None):
 9 |     rp = git.Repo.clone_from(f'https://github.com/{org}/{repo}',
   |     ^^ F841
10 |                              branch=branch,
11 |                              to_path=path_to_clone)
   |
   = help: Remove assignment to unused variable `rp`

deprecated/tests/unit/intense/test_intense_pipelines.py:25:5: F401 [*] `driada.experiment.synthetic.generate_multiselectivity_patterns` imported but unused
   |
23 |     generate_synthetic_exp,
24 |     generate_synthetic_exp_with_mixed_selectivity,
25 |     generate_multiselectivity_patterns,
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F401
26 |     discretize_via_roi
27 | )
   |
   = help: Remove unused import: `driada.experiment.synthetic.generate_multiselectivity_patterns`

deprecated/tests/unit/intense/test_intense_pipelines.py:304:48: F401 [*] `driada.intense.disentanglement.DEFAULT_MULTIFEATURE_MAP` imported but unused
    |
302 | def test_disentanglement_integration(discrete_only_experiment):
303 |     """Test integration with disentanglement module."""
304 |     from driada.intense.disentanglement import DEFAULT_MULTIFEATURE_MAP
    |                                                ^^^^^^^^^^^^^^^^^^^^^^^^ F401
305 |     
306 |     # Use fixture with discrete features for place-related testing
    |
    = help: Remove unused import: `driada.intense.disentanglement.DEFAULT_MULTIFEATURE_MAP`

deprecated/tests/unit/intense/test_intense_pipelines_fast.py:9:27: F401 [*] `unittest.mock.Mock` imported but unused
   |
 7 | import pytest
 8 | import numpy as np
 9 | from unittest.mock import Mock, patch, MagicMock
   |                           ^^^^ F401
10 | from types import SimpleNamespace
   |
   = help: Remove unused import

deprecated/tests/unit/intense/test_intense_pipelines_fast.py:9:40: F401 [*] `unittest.mock.MagicMock` imported but unused
   |
 7 | import pytest
 8 | import numpy as np
 9 | from unittest.mock import Mock, patch, MagicMock
   |                                        ^^^^^^^^^ F401
10 | from types import SimpleNamespace
   |
   = help: Remove unused import

deprecated/tests/unit/intense/test_intense_pipelines_fast.py:183:16: E712 Avoid equality comparisons to `True`; use `sig_mat[0, 1]:` for truth checks
    |
181 |         # Verify mocked correlation was detected
182 |         assert sim_mat[0, 1] > sim_mat[0, 2]
183 |         assert sig_mat[0, 1] == True
    |                ^^^^^^^^^^^^^^^^^^^^^ E712
184 |     
185 |     def test_edge_cases_with_mocking(self, mock_experiment):
    |
    = help: Replace with `sig_mat[0, 1]`

deprecated/tests/unit/visualization/test_visual.py:15:8: F811 [*] Redefinition of unused `pytest` from line 4
   |
13 | import matplotlib.pyplot as plt
14 | from types import SimpleNamespace
15 | import pytest
   |        ^^^^^^ F811
   |
   = help: Remove definition: `pytest`

deprecated/tests/unit/visualization/test_visual.py:135:5: F841 Local variable `n_features` is assigned to but never used
    |
133 |     """Test disentanglement heatmap plotting."""
134 |     # Create test data
135 |     n_features = 4
    |     ^^^^^^^^^^ F841
136 |     disent_matrix = np.array([
137 |         [0, 10, 20, 5],
    |
    = help: Remove assignment to unused variable `n_features`

deprecated/tests/unit/visualization/test_visual.py:190:5: F841 Local variable `n_features` is assigned to but never used
    |
188 |     """Test disentanglement summary plotting."""
189 |     # Create test data for single experiment
190 |     n_features = 4
    |     ^^^^^^^^^^ F841
191 |     disent_matrix = np.array([
192 |         [0, 10, 20, 5],
    |
    = help: Remove assignment to unused variable `n_features`

deprecated/tests/unit/visualization/test_visual_fast.py:5:27: F401 [*] `unittest.mock.Mock` imported but unused
  |
3 | import numpy as np
4 | import pytest
5 | from unittest.mock import Mock, patch, MagicMock, PropertyMock
  |                           ^^^^ F401
6 | from types import SimpleNamespace
  |
  = help: Remove unused import

deprecated/tests/unit/visualization/test_visual_fast.py:5:51: F401 [*] `unittest.mock.PropertyMock` imported but unused
  |
3 | import numpy as np
4 | import pytest
5 | from unittest.mock import Mock, patch, MagicMock, PropertyMock
  |                                                   ^^^^^^^^^^^^ F401
6 | from types import SimpleNamespace
  |
  = help: Remove unused import

deprecated/tests/unit/visualization/test_visual_mocked.py:5:27: F401 [*] `unittest.mock.Mock` imported but unused
  |
3 | import numpy as np
4 | import pytest
5 | from unittest.mock import Mock, patch, MagicMock
  |                           ^^^^ F401
6 | from types import SimpleNamespace
  |
  = help: Remove unused import: `unittest.mock.Mock`

deprecated/tests/unit/visualization/test_visual_mocked.py:307:42: F841 Local variable `mock_heatmap` is assigned to but never used
    |
305 |              patch('matplotlib.pyplot.figure') as mock_figure, \
306 |              patch('scipy.stats.gaussian_kde') as mock_kde, \
307 |              patch('seaborn.heatmap') as mock_heatmap:
    |                                          ^^^^^^^^^^^^ F841
308 |             
309 |             # Setup basic mocks
    |
    = help: Remove assignment to unused variable `mock_heatmap`

docs/research/distribution_investigation.py:19:8: F401 [*] `warnings` imported but unused
   |
17 | from scipy.stats import normaltest, shapiro, anderson, kstest, gamma, norm, lognorm
18 | from typing import Dict, List, Tuple, Optional, Union
19 | import warnings
   |        ^^^^^^^^ F401
20 | from dataclasses import dataclass
21 | from pathlib import Path
   |
   = help: Remove unused import: `warnings`

docs/research/distribution_investigation.py:21:21: F401 [*] `pathlib.Path` imported but unused
   |
19 | import warnings
20 | from dataclasses import dataclass
21 | from pathlib import Path
   |                     ^^^^ F401
22 |
23 | from .stats import get_mi_distr_pvalue, get_distribution_function
   |
   = help: Remove unused import: `pathlib.Path`

docs/research/distribution_investigation.py:23:41: F401 [*] `.stats.get_distribution_function` imported but unused
   |
21 | from pathlib import Path
22 |
23 | from .stats import get_mi_distr_pvalue, get_distribution_function
   |                                         ^^^^^^^^^^^^^^^^^^^^^^^^^ F401
24 | from .pipelines import compute_cell_feat_significance
25 | from ..experiment import generate_mixed_population_exp, generate_circular_manifold_exp
   |
   = help: Remove unused import: `.stats.get_distribution_function`

docs/research/distribution_investigation.py:24:24: F401 [*] `.pipelines.compute_cell_feat_significance` imported but unused
   |
23 | from .stats import get_mi_distr_pvalue, get_distribution_function
24 | from .pipelines import compute_cell_feat_significance
   |                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F401
25 | from ..experiment import generate_mixed_population_exp, generate_circular_manifold_exp
   |
   = help: Remove unused import: `.pipelines.compute_cell_feat_significance`

docs/research/distribution_investigation.py:287:9: E722 Do not use bare `except`
    |
285 |         try:
286 |             shapiro_stat, shapiro_p = shapiro(data)
287 |         except:
    |         ^^^^^^ E722
288 |             shapiro_stat, shapiro_p = np.nan, np.nan
    |

docs/research/distribution_investigation.py:292:9: E722 Do not use bare `except`
    |
290 |         try:
291 |             normaltest_stat, normaltest_p = normaltest(data)
292 |         except:
    |         ^^^^^^ E722
293 |             normaltest_stat, normaltest_p = np.nan, np.nan
    |

docs/research/distribution_investigation.py:300:9: E722 Do not use bare `except`
    |
298 |             anderson_stat = anderson_result.statistic
299 |             anderson_critical = anderson_result.critical_values[2]  # 5% level
300 |         except:
    |         ^^^^^^ E722
301 |             anderson_stat, anderson_critical = np.nan, np.nan
    |

docs/research/distribution_investigation.py:505:23: F541 [*] f-string without any placeholders
    |
504 |         # Data summary
505 |         report.append(f"\nDATA SUMMARY:")
    |                       ^^^^^^^^^^^^^^^^^^ F541
506 |         report.append(f"  Total shuffle distributions analyzed: {len(self.shuffle_data)}")
    |
    = help: Remove extraneous `f` prefix

docs/research/distribution_investigation.py:513:23: F541 [*] f-string without any placeholders
    |
512 |         # Statistical properties summary
513 |         report.append(f"\nSTATISTICAL PROPERTIES SUMMARY:")
    |                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
514 |         
515 |         # Average statistics across all distributions
    |
    = help: Remove extraneous `f` prefix

docs/research/distribution_investigation.py:529:27: F541 [*] f-string without any placeholders
    |
527 |         # Distribution fitting summary
528 |         if self.fit_results:
529 |             report.append(f"\nDISTRIBUTION FITTING SUMMARY:")
    |                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
530 |             
531 |             # Calculate average AIC/BIC for each distribution
    |
    = help: Remove extraneous `f` prefix

docs/research/distribution_investigation.py:559:23: F541 [*] f-string without any placeholders
    |
557 |         # Detection performance summary
558 |         performance = self.compare_detection_performance()
559 |         report.append(f"\nDETECTION PERFORMANCE COMPARISON:")
    |                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
560 |         
561 |         for dist_name, metrics in performance.items():
    |
    = help: Remove extraneous `f` prefix

docs/research/distribution_investigation.py:569:23: F541 [*] f-string without any placeholders
    |
568 |         # Recommendations
569 |         report.append(f"\nRECOMMENDATIONS:")
    |                       ^^^^^^^^^^^^^^^^^^^^^ F541
570 |         
571 |         # Find best performing distribution
    |
    = help: Remove extraneous `f` prefix

examples/circular_manifold/extract_circular_manifold.py:26:20: F401 [*] `driada.dimensionality.pca_dimension_profile` imported but unused
   |
24 | from driada.dimensionality import (
25 |     eff_dim, nn_dimension, correlation_dimension,
26 |     pca_dimension, pca_dimension_profile, effective_rank
   |                    ^^^^^^^^^^^^^^^^^^^^^ F401
27 | )
28 | from driada.dim_reduction.manifold_metrics import (
   |
   = help: Remove unused import: `driada.dimensionality.pca_dimension_profile`

examples/circular_manifold/extract_circular_manifold.py:29:5: F401 [*] `driada.dim_reduction.manifold_metrics.compute_embedding_quality` imported but unused
   |
27 | )
28 | from driada.dim_reduction.manifold_metrics import (
29 |     compute_embedding_quality,
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^ F401
30 |     compute_decoding_accuracy,
31 |     manifold_reconstruction_score,
   |
   = help: Remove unused import

examples/circular_manifold/extract_circular_manifold.py:30:5: F401 [*] `driada.dim_reduction.manifold_metrics.compute_decoding_accuracy` imported but unused
   |
28 | from driada.dim_reduction.manifold_metrics import (
29 |     compute_embedding_quality,
30 |     compute_decoding_accuracy,
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^ F401
31 |     manifold_reconstruction_score,
32 |     compute_reconstruction_error,
   |
   = help: Remove unused import

examples/circular_manifold/extract_circular_manifold.py:31:5: F401 [*] `driada.dim_reduction.manifold_metrics.manifold_reconstruction_score` imported but unused
   |
29 |     compute_embedding_quality,
30 |     compute_decoding_accuracy,
31 |     manifold_reconstruction_score,
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F401
32 |     compute_reconstruction_error,
33 |     compute_embedding_alignment_metrics
   |
   = help: Remove unused import

examples/circular_manifold/extract_circular_manifold.py:32:5: F401 [*] `driada.dim_reduction.manifold_metrics.compute_reconstruction_error` imported but unused
   |
30 |     compute_decoding_accuracy,
31 |     manifold_reconstruction_score,
32 |     compute_reconstruction_error,
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F401
33 |     compute_embedding_alignment_metrics
34 | )
   |
   = help: Remove unused import

examples/circular_manifold/extract_circular_manifold.py:36:20: F401 [*] `driada.MultiTimeSeries` imported but unused
   |
34 | )
35 | from driada.dim_reduction import MVData
36 | from driada import MultiTimeSeries
   |                    ^^^^^^^^^^^^^^^ F401
37 | import os
   |
   = help: Remove unused import: `driada.MultiTimeSeries`

examples/circular_manifold/extract_circular_manifold.py:338:5: F841 Local variable `eigen_fig` is assigned to but never used
    |
336 |     # Plot eigenspectrum
337 |     print("\n3. Plotting eigenvalue spectrum...")
338 |     eigen_fig = plot_eigenspectrum(neural_data)
    |     ^^^^^^^^^ F841
339 |     plt.savefig('circular_manifold_results/eigenspectrum.png', dpi=150, bbox_inches='tight')
    |
    = help: Remove assignment to unused variable `eigen_fig`

examples/circular_manifold/extract_circular_manifold.py:381:5: F841 Local variable `fig1` is assigned to but never used
    |
380 |     # Create embedding comparison using visual utility
381 |     fig1 = plot_embedding_comparison(
    |     ^^^^ F841
382 |         embeddings=embeddings_dict,
383 |         features=features,
    |
    = help: Remove assignment to unused variable `fig1`

examples/circular_manifold/extract_circular_manifold.py:394:5: F841 Local variable `fig2` is assigned to but never used
    |
392 |     # Keep the custom reconstruction analysis
393 |     embeddings_list = [embeddings_dict[method] for method in ['PCA', 'Isomap', 'UMAP']]
394 |     fig2 = visualize_manifold_extraction(embeddings_list, true_angles_ds, ['PCA', 'Isomap', 'UMAP'])
    |     ^^^^ F841
395 |     plt.savefig('circular_manifold_results/reconstruction_analysis.png', dpi=DEFAULT_DPI, bbox_inches='tight')
    |
    = help: Remove assignment to unused variable `fig2`

examples/circular_manifold/extract_circular_manifold.py:405:5: F841 Local variable `fig3` is assigned to but never used
    |
403 |     trajectories_dict = {method: emb[:traj_len] for method, emb in embeddings_dict.items()}
404 |     
405 |     fig3 = plot_trajectories(
    |     ^^^^ F841
406 |         embeddings=trajectories_dict,
407 |         trajectory_kwargs={
    |
    = help: Remove assignment to unused variable `fig3`

examples/circular_manifold/test_metrics.py:87:7: F541 [*] f-string without any placeholders
   |
85 | # Embedding quality
86 | quality = compute_embedding_quality(embedding, true_angles, 'circular')
87 | print(f"\nEmbedding quality:")
   |       ^^^^^^^^^^^^^^^^^^^^^^^ F541
88 | print(f"  Train error: {quality['train_error']:.3f}")
89 | print(f"  Test error: {quality['test_error']:.3f}")
   |
   = help: Remove extraneous `f` prefix

examples/compare_dr_methods/compare_dr_methods.py:28:26: F401 [*] `typing.List` imported but unused
   |
26 | import tracemalloc
27 | import warnings
28 | from typing import Dict, List, Tuple, Optional
   |                          ^^^^ F401
29 | import pandas as pd
   |
   = help: Remove unused import

examples/compare_dr_methods/compare_dr_methods.py:28:39: F401 [*] `typing.Optional` imported but unused
   |
26 | import tracemalloc
27 | import warnings
28 | from typing import Dict, List, Tuple, Optional
   |                                       ^^^^^^^^ F401
29 | import pandas as pd
   |
   = help: Remove unused import

examples/compare_dr_methods/compare_dr_methods.py:33:13: F401 [*] `driada.dim_reduction.METHODS_DICT` imported but unused
   |
31 | # Import DRIADA modules
32 | from driada.dim_reduction import (
33 |     MVData, METHODS_DICT, 
   |             ^^^^^^^^^^^^ F401
34 |     knn_preservation_rate, trustworthiness, continuity, 
35 |     stress, procrustes_analysis, manifold_preservation_score
   |
   = help: Remove unused import

examples/compare_dr_methods/compare_dr_methods.py:35:13: F401 [*] `driada.dim_reduction.procrustes_analysis` imported but unused
   |
33 |     MVData, METHODS_DICT, 
34 |     knn_preservation_rate, trustworthiness, continuity, 
35 |     stress, procrustes_analysis, manifold_preservation_score
   |             ^^^^^^^^^^^^^^^^^^^ F401
36 | )
   |
   = help: Remove unused import

examples/compare_dr_methods/compare_dr_methods.py:35:34: F401 [*] `driada.dim_reduction.manifold_preservation_score` imported but unused
   |
33 |     MVData, METHODS_DICT, 
34 |     knn_preservation_rate, trustworthiness, continuity, 
35 |     stress, procrustes_analysis, manifold_preservation_score
   |                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^ F401
36 | )
   |
   = help: Remove unused import

examples/compare_dr_methods/compare_dr_methods.py:471:9: F841 Local variable `n_methods` is assigned to but never used
    |
470 |     if len(swiss_results) > 0:
471 |         n_methods = len(swiss_results)
    |         ^^^^^^^^^ F841
472 |         fig, axes = plt.subplots(2, 3, figsize=(15, 10))
473 |         axes = axes.ravel()
    |
    = help: Remove assignment to unused variable `n_methods`

examples/compare_dr_methods/compare_dr_methods.py:483:13: F841 Local variable `scatter` is assigned to but never used
    |
481 |             labels = result['labels']
482 |             
483 |             scatter = ax.scatter(
    |             ^^^^^^^ F841
484 |                 embedding[:, 0],
485 |                 embedding[:, 1],
    |
    = help: Remove assignment to unused variable `scatter`

examples/compare_dr_methods/compare_dr_methods.py:623:11: F541 [*] f-string without any placeholders
    |
621 |     # Save results
622 |     results_df.to_csv('dr_comparison_results.csv', index=False)
623 |     print(f"\nResults saved to: dr_comparison_results.csv")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
624 |     
625 |     # Visualize results
    |
    = help: Remove extraneous `f` prefix

examples/dr_sequence/dr_sequence_neural_example.py:17:5: F401 [*] `driada.dim_reduction.manifold_metrics.circular_structure_preservation` imported but unused
   |
15 |     continuity,
16 |     manifold_preservation_score,
17 |     circular_structure_preservation
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F401
18 | )
19 | from driada.utils.visual import plot_embedding_comparison
   |
   = help: Remove unused import: `driada.dim_reduction.manifold_metrics.circular_structure_preservation`

examples/dr_sequence/dr_sequence_neural_example.py:203:5: F841 Local variable `fig_comparison` is assigned to but never used
    |
202 |     # Use plot_embedding_comparison for comprehensive visualization
203 |     fig_comparison = plot_embedding_comparison(
    |     ^^^^^^^^^^^^^^ F841
204 |         embeddings=embeddings_dict,
205 |         features=features_dict,
    |
    = help: Remove assignment to unused variable `fig_comparison`

examples/dr_simplified_api/dr_simplified_api_demo.py:22:17: F401 [*] `numpy` imported but unused
   |
20 | """
21 |
22 | import numpy as np
   |                 ^^ F401
23 | import matplotlib.pyplot as plt
24 | from sklearn.datasets import make_swiss_roll
   |
   = help: Remove unused import: `numpy`

examples/dr_simplified_api/dr_simplified_api_demo.py:177:5: F841 Local variable `mvdata` is assigned to but never used
    |
175 |     # Generate data
176 |     X, _ = generate_demo_data()
177 |     mvdata = MVData(X)
    |     ^^^^^^ F841
178 |     
179 |     print("\n1. Working with high-dimensional data:")
    |
    = help: Remove assignment to unused variable `mvdata`

examples/full_pipeline/full_pipeline.py:94:15: F541 [*] f-string without any placeholders
   |
92 |     # MI statistics
93 |     if all_mi_values:
94 |         print(f"\nMutual Information statistics:")
   |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
95 |         print(f"  Mean MI: {np.mean(all_mi_values):.4f}")
96 |         print(f"  Median MI: {np.median(all_mi_values):.4f}")
   |
   = help: Remove extraneous `f` prefix

examples/full_pipeline/full_pipeline.py:103:15: F541 [*] f-string without any placeholders
    |
101 |     # P-value statistics
102 |     if all_pvalues:
103 |         print(f"\nP-value statistics:")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^ F541
104 |         print(f"  Mean p-value: {np.mean(all_pvalues):.2e}")
105 |         print(f"  Median p-value: {np.median(all_pvalues):.2e}")
    |
    = help: Remove extraneous `f` prefix

examples/full_pipeline/full_pipeline.py:132:11: F541 [*] f-string without any placeholders
    |
131 |     # Print statistics
132 |     print(f"\nHeatmap statistics:")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^ F541
133 |     print(f"  • Matrix size: {exp.n_cells} neurons × {len([f for f in exp.dynamic_features.keys() if isinstance(f, str)])} features")
134 |     print(f"  • Selective neurons: {stats['n_selective']} ({stats['selectivity_rate']:.1f}%)")
    |
    = help: Remove extraneous `f` prefix

examples/full_pipeline/full_pipeline.py:139:15: F541 [*] f-string without any placeholders
    |
138 |     if stats['metric_values']:
139 |         print(f"\nMI value statistics:")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^ F541
140 |         print(f"  • Min: {min(stats['metric_values']):.4f}")
141 |         print(f"  • Max: {max(stats['metric_values']):.4f}")
    |
    = help: Remove extraneous `f` prefix

examples/full_pipeline/full_pipeline.py:201:11: F541 [*] f-string without any placeholders
    |
199 |     )
200 |     
201 |     print(f"\n   Performance comparison:")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
202 |     print(f"   Standard (1000 shuffles): {analysis_time:.2f}s")
203 |     print(f"   High-precision (2000 shuffles): {analysis_time_hp:.2f}s")
    |
    = help: Remove extraneous `f` prefix

examples/full_pipeline/full_pipeline.py:230:11: F541 [*] f-string without any placeholders
    |
228 |         }
229 |     
230 |     print(f"\nParameter sensitivity results:")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
231 |     print(f"{'Shuffles':<10} {'Neurons':<10} {'Pairs':<10} {'Runtime':<10}")
232 |     print("-" * 40)
    |
    = help: Remove extraneous `f` prefix

examples/full_pipeline/full_pipeline.py:268:11: F541 [*] f-string without any placeholders
    |
266 |     print("=" * 80)
267 |     
268 |     print(f"\nFinal Summary:")
    |           ^^^^^^^^^^^^^^^^^^^ F541
269 |     print(f"• Dataset: {exp.n_cells} neurons, {len(exp.dynamic_features)} features")
270 |     print(f"• Significant neurons: {len(significant_neurons)}/{exp.n_cells} ({len(significant_neurons)/exp.n_cells*100:.1f}%)")
    |
    = help: Remove extraneous `f` prefix

examples/full_pipeline/full_pipeline.py:280:11: F541 [*] f-string without any placeholders
    |
278 |     print("• neuronal_selectivity_heatmap.png - Selectivity matrix visualization")
279 |     
280 |     print(f"\nNext steps:")
    |           ^^^^^^^^^^^^^^^^ F541
281 |     print("• Try mixed_selectivity.py for disentanglement analysis")
282 |     print("• Modify parameters to explore different scenarios")
    |
    = help: Remove extraneous `f` prefix

examples/intense_dr_pipeline/intense_dr_pipeline.py:20:5: F401 [*] `driada.TimeSeries` imported but unused
   |
18 |     compute_cell_feat_significance,
19 |     generate_mixed_population_exp,
20 |     TimeSeries,
   |     ^^^^^^^^^^ F401
21 |     MultiTimeSeries,
22 | )
   |
   = help: Remove unused import

examples/intense_dr_pipeline/intense_dr_pipeline.py:21:5: F401 [*] `driada.MultiTimeSeries` imported but unused
   |
19 |     generate_mixed_population_exp,
20 |     TimeSeries,
21 |     MultiTimeSeries,
   |     ^^^^^^^^^^^^^^^ F401
22 | )
23 | from driada.dim_reduction import MVData
   |
   = help: Remove unused import

examples/intense_dr_pipeline/intense_dr_pipeline.py:24:32: F401 [*] `driada.information.get_sim` imported but unused
   |
22 | )
23 | from driada.dim_reduction import MVData
24 | from driada.information import get_sim
   |                                ^^^^^^^ F401
25 | from driada.utils import filter_signals, adaptive_filter_signals
26 | from driada.utils import (
   |
   = help: Remove unused import: `driada.information.get_sim`

examples/intense_dr_pipeline/intense_dr_pipeline.py:90:5: E722 Do not use bare `except`
   |
88 |         # Pearson correlation
89 |         metrics['distance_correlation'] = np.corrcoef(dist_embed, dist_true)[0, 1]
90 |     except:
   |     ^^^^^^ E722
91 |         metrics['distance_correlation'] = 0.0
   |

examples/intense_dr_pipeline/intense_dr_pipeline.py:106:5: E722 Do not use bare `except`
    |
104 |         _, _, disparity = procrustes(true_centered, embed_centered)
105 |         metrics['procrustes_disparity'] = disparity
106 |     except:
    |     ^^^^^^ E722
107 |         metrics['procrustes_disparity'] = 1.0
    |

examples/intense_dr_pipeline/intense_dr_pipeline.py:344:9: E722 Do not use bare `except`
    |
342 |             if feat_neurons:
343 |                 selective_neurons.update(feat_neurons.keys())
344 |         except:
    |         ^^^^^^ E722
345 |             # Feature might not have been tested
346 |             pass
    |

examples/intense_dr_pipeline/intense_dr_pipeline.py:568:9: F841 Local variable `fig_summary` is assigned to but never used
    |
566 |         }
567 |         
568 |         fig_summary = plot_neuron_selectivity_summary(
    |         ^^^^^^^^^^^ F841
569 |             selectivity_counts=selectivity_counts,
570 |             total_neurons=exp.n_cells,
    |
    = help: Remove assignment to unused variable `fig_summary`

examples/intense_dr_pipeline/intense_dr_pipeline.py:716:12: F401 [*] `sys` imported but unused
    |
715 | if __name__ == "__main__":
716 |     import sys
    |            ^^^ F401
717 |     import argparse
    |
    = help: Remove unused import: `sys`

examples/mixed_selectivity/mixed_selectivity.py:134:11: F541 [*] f-string without any placeholders
    |
132 |         return None, None, None
133 |     
134 |     print(f"Disentanglement analysis completed by pipeline")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
135 |     print(f"Matrix shape: {disent_matrix.shape}, Non-zero entries: {np.count_nonzero(count_matrix)}")
136 |     print(f"Feature names analyzed: {feat_names}")
    |
    = help: Remove extraneous `f` prefix

examples/mixed_selectivity/mixed_selectivity.py:143:19: F541 [*] f-string without any placeholders
    |
141 |         if 'overall_stats' in summary:
142 |             stats = summary['overall_stats']
143 |             print(f"\nOverall statistics:")
    |                   ^^^^^^^^^^^^^^^^^^^^^^^^ F541
144 |             print(f"  Total neuron pairs: {stats.get('total_neuron_pairs', 0)}")
145 |             print(f"  Redundancy rate: {stats.get('redundancy_rate', 0):.1f}%")
    |
    = help: Remove extraneous `f` prefix

examples/mixed_selectivity/mixed_selectivity.py:187:5: F841 Local variable `total_pairs` is assigned to but never used
    |
186 |     # Summary statistics
187 |     total_pairs = len(redundancy_cases) + len(synergy_cases) + len(independence_cases)
    |     ^^^^^^^^^^^ F841
188 |     print(f"Found {len(redundancy_cases)} redundancy, {len(independence_cases)} independence, {len(synergy_cases)} synergy cases")
    |
    = help: Remove assignment to unused variable `total_pairs`

examples/mixed_selectivity/mixed_selectivity.py:295:11: F541 [*] f-string without any placeholders
    |
293 |     )
294 |     
295 |     print(f"\nVisualization files created:")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
296 |     print(f"  - neuron_feature_selectivity.png: Shows MI values for all neuron-feature pairs")
297 |     print(f"  - disentanglement_heatmap.png: Shows feature relationship disentanglement")
    |
    = help: Remove extraneous `f` prefix

examples/mixed_selectivity/mixed_selectivity.py:296:11: F541 [*] f-string without any placeholders
    |
295 |     print(f"\nVisualization files created:")
296 |     print(f"  - neuron_feature_selectivity.png: Shows MI values for all neuron-feature pairs")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
297 |     print(f"  - disentanglement_heatmap.png: Shows feature relationship disentanglement")
    |
    = help: Remove extraneous `f` prefix

examples/mixed_selectivity/mixed_selectivity.py:297:11: F541 [*] f-string without any placeholders
    |
295 |     print(f"\nVisualization files created:")
296 |     print(f"  - neuron_feature_selectivity.png: Shows MI values for all neuron-feature pairs")
297 |     print(f"  - disentanglement_heatmap.png: Shows feature relationship disentanglement")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
    |
    = help: Remove extraneous `f` prefix

examples/recursive_embedding/recursive_embedding_example.py:86:12: F401 `torch` imported but unused; consider using `importlib.util.find_spec` to test for availability
   |
84 | # Stage 1: Autoencoder for non-linear reduction (if torch available)
85 | try:
86 |     import torch
   |            ^^^^^ F401
87 |     print("\nStage 1: Autoencoder 100D → 50D...")
88 |     ae_embedding = mvdata.get_embedding(method='ae', dim=50, epochs=20, verbose=False)
   |
   = help: Remove unused import: `torch`

examples/recursive_embedding/recursive_embedding_example.py:100:11: F541 [*] f-string without any placeholders
    |
 98 |     tsne_embedding = pca_mvdata2.get_embedding(method='tsne', dim=2)
 99 |     
100 |     print(f"\nPipeline complete: 100D → 50D → 10D → 2D")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
101 |     print(f"Final embedding shape: {tsne_embedding.coords.shape}")
    |
    = help: Remove extraneous `f` prefix

examples/recursive_embedding/recursive_embedding_example.py:117:11: F541 [*] f-string without any placeholders
    |
115 |     final = isomap.to_mvdata().get_embedding(method='umap', dim=2, n_neighbors=15)
116 |     
117 |     print(f"\nPipeline complete: 100D → 30D → 5D → 2D")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
118 |     print(f"Final embedding shape: {final.coords.shape}")
    |
    = help: Remove extraneous `f` prefix

examples/rsa/rsa_example.py:82:5: F841 Local variable `fig` is assigned to but never used
   |
81 |     # Visualize RDM with standardized plotting
82 |     fig = rsa.plot_rdm(
   |     ^^^ F841
83 |         rdm,
84 |         labels=label_names[:len(labels)],
   |
   = help: Remove assignment to unused variable `fig`

examples/rsa/rsa_example.py:144:5: F841 Local variable `fig` is assigned to but never used
    |
142 |     rdm2 = rsa.compute_rdm(v2_data)
143 |     
144 |     fig = rsa.plot_rdm_comparison(
    |     ^^^ F841
145 |         [rdm1, rdm2],
146 |         titles=['V1 Representation', 'V2 Representation']
    |
    = help: Remove assignment to unused variable `fig`

examples/rsa/rsa_example.py:260:5: F841 Local variable `fig` is assigned to but never used
    |
259 |     # Visualize with dendrogram
260 |     fig = rsa.plot_rdm(
    |     ^^^ F841
261 |         rdm,
262 |         labels=labels,
    |
    = help: Remove assignment to unused variable `fig`

examples/rsa/rsa_example.py:336:5: F841 Local variable `fig` is assigned to but never used
    |
335 |     # Visualize both RDMs
336 |     fig = rsa.plot_rdm_comparison(
    |     ^^^ F841
337 |         [rdm1, rdm2],
338 |         labels=list(labels1),
    |
    = help: Remove assignment to unused variable `fig`

examples/rsa/rsa_example.py:409:5: F841 Local variable `fig` is assigned to but never used
    |
408 |     # Visualize RDM
409 |     fig = rsa.plot_rdm(
    |     ^^^ F841
410 |         rdm,
411 |         labels=[f"Cond {i}" for i in labels],
    |
    = help: Remove assignment to unused variable `fig`

examples/spatial_analysis/visualize_spatial_maps.py:127:9: F841 Local variable `scatter` is assigned to but never used
    |
125 |         # Row 1: Calcium signal colored by position
126 |         ax = plt.subplot(3, n_neurons + 1, 3 + i)
127 |         scatter = ax.scatter(positions[:, 0], positions[:, 1], 
    |         ^^^^^^^ F841
128 |                            c=calcium_signals[i], s=1, 
129 |                            cmap='hot', alpha=0.5)
    |
    = help: Remove assignment to unused variable `scatter`

examples/spatial_analysis/visualize_spatial_maps.py:157:22: F541 [*] f-string without any placeholders
    |
155 |         time = np.arange(n_samples) / 20.0  # Convert to seconds
156 |         ax.plot(time[:500], calcium_signals[i, :500], 'k-', linewidth=0.5)
157 |         ax.set_title(f'Calcium Trace (first 25s)')
    |                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
158 |         ax.set_xlabel('Time (s)')
159 |         ax.set_ylabel('ΔF/F')
    |
    = help: Remove extraneous `f` prefix

examples/spatial_analysis/visualize_spatial_maps.py:206:11: F541 [*] f-string without any placeholders
    |
204 |     )
205 |     
206 |     print(f"\nAnalysis Summary:")
    |           ^^^^^^^^^^^^^^^^^^^^^^ F541
207 |     print(f"  Place cells detected: {results['summary']['n_place_cells']}")
208 |     print(f"  Grid cells detected: {results['summary']['n_grid_cells']}")
    |
    = help: Remove extraneous `f` prefix

examples/spatial_map/extract_spatial_map.py:20:27: F401 [*] `scipy.spatial.distance_matrix` imported but unused
   |
18 | from sklearn.manifold import Isomap
19 | import umap
20 | from scipy.spatial import distance_matrix
   |                           ^^^^^^^^^^^^^^^ F401
21 |
22 | # Import DRIADA modules
   |
   = help: Remove unused import: `scipy.spatial.distance_matrix`

examples/spatial_map/extract_spatial_map.py:29:5: F401 [*] `driada.dim_reduction.manifold_metrics.geodesic_distance_correlation` imported but unused
   |
27 | from driada.dim_reduction.manifold_metrics import (
28 |     knn_preservation_rate, trustworthiness, continuity,
29 |     geodesic_distance_correlation, procrustes_analysis
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F401
30 | )
   |
   = help: Remove unused import: `driada.dim_reduction.manifold_metrics.geodesic_distance_correlation`

examples/spatial_map/extract_spatial_map.py:186:64: F401 [*] `driada.utils.visual.plot_trajectories` imported but unused
    |
184 | def visualize_embeddings(embeddings, true_positions, metrics):
185 |     """Visualize DR embeddings colored by true position."""
186 |     from driada.utils.visual import plot_embedding_comparison, plot_trajectories, DEFAULT_DPI
    |                                                                ^^^^^^^^^^^^^^^^^ F401
187 |     
188 |     # Use position magnitude for coloring
    |
    = help: Remove unused import: `driada.utils.visual.plot_trajectories`

examples/spatial_map/extract_spatial_map.py:359:5: F841 Local variable `field_fig` is assigned to but never used
    |
357 |     # Visualize place fields
358 |     print("\n2. Visualizing place field arrangement...")
359 |     field_fig = visualize_place_fields(place_centers, info['field_sigma'])
    |     ^^^^^^^^^ F841
360 |     plt.savefig('spatial_map_place_fields.png', dpi=150, bbox_inches='tight')
    |
    = help: Remove assignment to unused variable `field_fig`

examples/spatial_map/extract_spatial_map.py:396:5: F841 Local variable `embed_fig` is assigned to but never used
    |
394 |     # Visualize embeddings
395 |     print("\n5. Visualizing extracted spatial representations...")
396 |     embed_fig = visualize_embeddings(embeddings, positions, metrics)
    |     ^^^^^^^^^ F841
397 |     plt.savefig('spatial_map_embeddings.png', dpi=150, bbox_inches='tight')
    |
    = help: Remove assignment to unused variable `embed_fig`

examples/spatial_map/extract_spatial_map.py:407:5: F841 Local variable `robust_fig` is assigned to but never used
    |
406 |     # Plot robustness
407 |     robust_fig = plot_noise_robustness(robustness_results)
    |     ^^^^^^^^^^ F841
408 |     plt.savefig('spatial_map_noise_robustness.png', dpi=150, bbox_inches='tight')
    |
    = help: Remove assignment to unused variable `robust_fig`

examples/spike_reconstruction/spike_reconstruction_comparison.py:103:11: F541 [*] f-string without any placeholders
    |
101 |     print("WAVELET METHOD METADATA")
102 |     print("="*50)
103 |     print(f"Parameters used:")
    |           ^^^^^^^^^^^^^^^^^^^ F541
104 |     for key, value in meta_wavelet['parameters'].items():
105 |         if isinstance(value, (int, float, str)):
    |
    = help: Remove extraneous `f` prefix

examples/spike_reconstruction/spike_reconstruction_comparison.py:112:11: F541 [*] f-string without any placeholders
    |
110 |     print("THRESHOLD METHOD METADATA")
111 |     print("="*50)
112 |     print(f"Parameters used:")
    |           ^^^^^^^^^^^^^^^^^^^ F541
113 |     for key, value in meta_threshold['parameters'].items():
114 |         print(f"  {key}: {value}")
    |
    = help: Remove extraneous `f` prefix

examples/task_variables/extract_task_variables.py:25:36: F401 [*] `scipy.spatial.distance.pdist` imported but unused
   |
23 | import matplotlib.pyplot as plt
24 | from scipy.stats import pearsonr, spearmanr
25 | from scipy.spatial.distance import pdist, squareform
   |                                    ^^^^^ F401
26 |
27 | from driada.experiment import generate_mixed_population_exp
   |
   = help: Remove unused import

examples/task_variables/extract_task_variables.py:25:43: F401 [*] `scipy.spatial.distance.squareform` imported but unused
   |
23 | import matplotlib.pyplot as plt
24 | from scipy.stats import pearsonr, spearmanr
25 | from scipy.spatial.distance import pdist, squareform
   |                                           ^^^^^^^^^^ F401
26 |
27 | from driada.experiment import generate_mixed_population_exp
   |
   = help: Remove unused import

examples/task_variables/extract_task_variables.py:30:34: F401 [*] `driada.dim_reduction.MVData` imported but unused
   |
28 | from driada.intense import compute_cell_feat_significance
29 | from driada.dimensionality import pca_dimension, eff_dim, nn_dimension
30 | from driada.dim_reduction import MVData, knn_preservation_rate, procrustes_analysis
   |                                  ^^^^^^ F401
31 | from driada.dim_reduction.manifold_metrics import trustworthiness, continuity
   |
   = help: Remove unused import

examples/task_variables/extract_task_variables.py:30:65: F401 [*] `driada.dim_reduction.procrustes_analysis` imported but unused
   |
28 | from driada.intense import compute_cell_feat_significance
29 | from driada.dimensionality import pca_dimension, eff_dim, nn_dimension
30 | from driada.dim_reduction import MVData, knn_preservation_rate, procrustes_analysis
   |                                                                 ^^^^^^^^^^^^^^^^^^^ F401
31 | from driada.dim_reduction.manifold_metrics import trustworthiness, continuity
   |
   = help: Remove unused import

examples/task_variables/extract_task_variables.py:31:51: F401 [*] `driada.dim_reduction.manifold_metrics.trustworthiness` imported but unused
   |
29 | from driada.dimensionality import pca_dimension, eff_dim, nn_dimension
30 | from driada.dim_reduction import MVData, knn_preservation_rate, procrustes_analysis
31 | from driada.dim_reduction.manifold_metrics import trustworthiness, continuity
   |                                                   ^^^^^^^^^^^^^^^ F401
   |
   = help: Remove unused import

examples/task_variables/extract_task_variables.py:31:68: F401 [*] `driada.dim_reduction.manifold_metrics.continuity` imported but unused
   |
29 | from driada.dimensionality import pca_dimension, eff_dim, nn_dimension
30 | from driada.dim_reduction import MVData, knn_preservation_rate, procrustes_analysis
31 | from driada.dim_reduction.manifold_metrics import trustworthiness, continuity
   |                                                                    ^^^^^^^^^^ F401
   |
   = help: Remove unused import

examples/task_variables/extract_task_variables.py:102:11: F541 [*] f-string without any placeholders
    |
100 |     }
101 |     
102 |     print(f"\nFeature mapping:")
    |           ^^^^^^^^^^^^^^^^^^^^^ F541
103 |     for old_name, new_meaning in feature_mapping.items():
104 |         if old_name in exp.dynamic_features:
    |
    = help: Remove extraneous `f` prefix

examples/task_variables/extract_task_variables.py:134:11: F541 [*] f-string without any placeholders
    |
132 |     print(f"  - Feature-selective cells: ~{int(exp.n_cells * 0.4)}")
133 |     print(f"  - Expected mixed selectivity: ~{int(exp.n_cells * 0.4 * 0.6)}")
134 |     print(f"  - Task variables: position (2D), speed, head_direction, reward")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
135 |     print(f"  - Recording duration: {duration}s at {fps} Hz")
    |
    = help: Remove extraneous `f` prefix

examples/task_variables/extract_task_variables.py:196:11: F541 [*] f-string without any placeholders
    |
194 |     mixed_selectivity_neurons = exp.get_significant_neurons(min_nspec=2)
195 |     
196 |     print(f"\nSelectivity Summary:")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^ F541
197 |     print(f"  - Total selective neurons: {len(significant_neurons)}/{exp.n_cells}")
198 |     print(f"  - Mixed selectivity neurons: {len(mixed_selectivity_neurons)}")
    |
    = help: Remove extraneous `f` prefix

examples/task_variables/extract_task_variables.py:205:11: F541 [*] f-string without any placeholders
    |
203 |             feature_counts[feat] = feature_counts.get(feat, 0) + 1
204 |     
205 |     print(f"\nSelectivity by feature:")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
206 |     for feat, count in sorted(feature_counts.items()):
207 |         print(f"  - {feat}: {count} neurons")
    |
    = help: Remove extraneous `f` prefix

examples/task_variables/extract_task_variables.py:210:15: F541 [*] f-string without any placeholders
    |
209 |     if mixed_selectivity_neurons:
210 |         print(f"\nMixed selectivity patterns (top 5):")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
211 |         for i, (neuron_id, features) in enumerate(list(mixed_selectivity_neurons.items())[:5]):
212 |             print(f"  Neuron {neuron_id}: {', '.join(features)}")
    |
    = help: Remove extraneous `f` prefix

examples/task_variables/extract_task_variables.py:270:25: F841 [*] Local variable `e` is assigned to but never used
    |
268 |         eff_dim_value = eff_dim(data_t.T, enable_correction=True)
269 |         print(f"  - Effective dimension (corrected): {eff_dim_value:.2f}")
270 |     except Exception as e:
    |                         ^ F841
271 |         # Correction can fail with near-singular matrices
272 |         try:
    |
    = help: Remove assignment to unused variable `e`

examples/task_variables/extract_task_variables.py:285:5: E722 Do not use bare `except`
    |
283 |         nn_dim = nn_dimension(data_sample, k=5)
284 |         print(f"  - k-NN dimension: {nn_dim:.2f}")
285 |     except:
    |     ^^^^^^ E722
286 |         print(f"  - k-NN dimension: Failed")
    |

examples/task_variables/extract_task_variables.py:286:15: F541 [*] f-string without any placeholders
    |
284 |         print(f"  - k-NN dimension: {nn_dim:.2f}")
285 |     except:
286 |         print(f"  - k-NN dimension: Failed")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
287 |     
288 |     embeddings = {}
    |
    = help: Remove extraneous `f` prefix

examples/task_variables/extract_task_variables.py:307:11: F541 [*] f-string without any placeholders
    |
305 |     )
306 |     embeddings['isomap'] = isomap_emb.coords.T
307 |     print(f"  - Isomap: embedded into 2D manifold")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
308 |     
309 |     # Use the new simplified API for UMAP
    |
    = help: Remove extraneous `f` prefix

examples/task_variables/extract_task_variables.py:317:11: F541 [*] f-string without any placeholders
    |
315 |     )
316 |     embeddings['umap'] = umap_emb.coords.T
317 |     print(f"  - UMAP: embedded into 2D space")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
318 |     
319 |     return embeddings
    |
    = help: Remove extraneous `f` prefix

examples/task_variables/extract_task_variables.py:448:5: F841 Local variable `fig1` is assigned to but never used
    |
446 |         features['angle'] = np.arctan2(pos_y - 0.5, pos_x - 0.5)
447 |     
448 |     fig1 = plot_embedding_comparison(
    |     ^^^^ F841
449 |         embeddings=embeddings,
450 |         features=features,
    |
    = help: Remove assignment to unused variable `fig1`

examples/under_construction/selectivity_manifold_mapper/selectivity_manifold_mapper_demo.py:31:31: F401 [*] `matplotlib.gridspec` imported but unused
   |
29 | import numpy as np
30 | import matplotlib.pyplot as plt
31 | import matplotlib.gridspec as gridspec
   |                               ^^^^^^^^ F401
32 | import seaborn as sns
33 | import argparse
   |
   = help: Remove unused import: `matplotlib.gridspec`

examples/under_construction/selectivity_manifold_mapper/selectivity_manifold_mapper_demo.py:32:19: F401 [*] `seaborn` imported but unused
   |
30 | import matplotlib.pyplot as plt
31 | import matplotlib.gridspec as gridspec
32 | import seaborn as sns
   |                   ^^^ F401
33 | import argparse
34 | from typing import Dict, List, Tuple, Optional
   |
   = help: Remove unused import: `seaborn`

examples/under_construction/selectivity_manifold_mapper/selectivity_manifold_mapper_demo.py:34:32: F401 [*] `typing.Tuple` imported but unused
   |
32 | import seaborn as sns
33 | import argparse
34 | from typing import Dict, List, Tuple, Optional
   |                                ^^^^^ F401
35 | import time
36 | import os
   |
   = help: Remove unused import: `typing.Tuple`

examples/under_construction/selectivity_manifold_mapper/selectivity_manifold_mapper_demo.py:166:11: F541 [*] f-string without any placeholders
    |
164 |     print(f"  - Expected mixed selectivity: ~{int(exp.n_cells * (1-manifold_fraction) * mixed_sel_prob)}")
165 |     print(f"  - Recording duration: {duration}s at 20 Hz")
166 |     print(f"  - Manifold type: Circular (head direction)")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
167 |     print(f"  - Features: Independent of head direction")
    |
    = help: Remove extraneous `f` prefix

examples/under_construction/selectivity_manifold_mapper/selectivity_manifold_mapper_demo.py:167:11: F541 [*] f-string without any placeholders
    |
165 |     print(f"  - Recording duration: {duration}s at 20 Hz")
166 |     print(f"  - Manifold type: Circular (head direction)")
167 |     print(f"  - Features: Independent of head direction")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
168 |     
169 |     return exp, info
    |
    = help: Remove extraneous `f` prefix

examples/under_construction/selectivity_manifold_mapper/selectivity_manifold_mapper_demo.py:237:11: F541 [*] f-string without any placeholders
    |
235 |     mixed_selectivity_neurons = exp.get_significant_neurons(min_nspec=2)
236 |     
237 |     print(f"\nSelectivity Summary:")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^ F541
238 |     print(f"  - Total selective neurons: {len(significant_neurons)}/{exp.n_cells}")
239 |     print(f"  - Mixed selectivity neurons: {len(mixed_selectivity_neurons)}")
    |
    = help: Remove extraneous `f` prefix

examples/under_construction/selectivity_manifold_mapper/selectivity_manifold_mapper_demo.py:247:11: F541 [*] f-string without any placeholders
    |
245 |             feature_counts[feat] = feature_counts.get(feat, 0) + 1
246 |     
247 |     print(f"\nSelectivity by feature:")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
248 |     for feat, count in sorted(feature_counts.items()):
249 |         print(f"  - {feat}: {count} neurons")
    |
    = help: Remove extraneous `f` prefix

examples/under_construction/selectivity_manifold_mapper/selectivity_manifold_mapper_demo.py:346:9: E722 Do not use bare `except`
    |
344 |             exp.get_embedding(method, 'calcium')
345 |             successful_methods.append(method)
346 |         except:
    |         ^^^^^^ E722
347 |             pass
    |

examples/under_construction/selectivity_manifold_mapper/selectivity_manifold_mapper_demo.py:383:15: F541 [*] f-string without any placeholders
    |
381 |         print(f"\n{method.upper()}:")
382 |         print(f"  - Neurons selective to components: {n_sig_neurons}")
383 |         print(f"  - Components with selective neurons:")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
384 |         
385 |         for comp_idx, neuron_list in results['component_selectivity'].items():
    |
    = help: Remove extraneous `f` prefix

examples/under_construction/selectivity_manifold_mapper/selectivity_manifold_mapper_demo.py:983:5: F841 Local variable `intense_results` is assigned to but never used
    |
982 |     # Step 2: Run INTENSE analysis
983 |     intense_results = run_intense_analysis(exp, args.quick)
    |     ^^^^^^^^^^^^^^^ F841
984 |     
985 |     # Step 3: Create embeddings and analyze component selectivity
    |
    = help: Remove assignment to unused variable `intense_results`

notebooks/01_quick_start.ipynb:cell 5:10:7: F541 [*] f-string without any placeholders
   |
 8 | )
 9 |
10 | print(f"Created experiment with:")
   |       ^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
11 | print(f"  • {exp.n_cells} neurons")
12 | print(f"  • {exp.n_frames} timepoints")
   |
   = help: Remove extraneous `f` prefix

notebooks/02_understanding_results.ipynb:cell 2:10:33: F401 [*] `matplotlib.gridspec.GridSpec` imported but unused
   |
 8 | import matplotlib.pyplot as plt
 9 | import seaborn as sns
10 | from matplotlib.gridspec import GridSpec
   |                                 ^^^^^^^^ F401
11 |
12 | # Configure plotting
   |
   = help: Remove unused import: `matplotlib.gridspec.GridSpec`

notebooks/02_understanding_results.ipynb:cell 14:50:11: F541 [*] f-string without any placeholders
   |
49 |     # Interpretation
50 |     print(f"Delay Statistics:")
   |           ^^^^^^^^^^^^^^^^^^^^ F541
51 |     print(f"  • Mean delay: {np.mean(delays):.3f}s")
52 |     print(f"  • Median delay: {np.median(delays):.3f}s")
   |
   = help: Remove extraneous `f` prefix

notebooks/02_understanding_results.ipynb:cell 16:46:11: F541 [*] f-string without any placeholders
   |
44 |     plt.show()
45 |     
46 |     print(f"Statistical Summary:")
   |           ^^^^^^^^^^^^^^^^^^^^^^^ F541
47 |     print(f"  • Median p-value: {np.median(pvals):.2e}")
48 |     print(f"  • Highly significant (p<0.001): {np.sum(np.array(pvals) < 0.001)}")
   |
   = help: Remove extraneous `f` prefix

notebooks/03_real_data_workflow.ipynb:cell 2:10:19: F401 [*] `scipy.signal` imported but unused
   |
 8 | import matplotlib.pyplot as plt
 9 | import pandas as pd
10 | from scipy import signal
   |                   ^^^^^^ F401
11 | import h5py
   |
   = help: Remove unused import: `scipy.signal`

notebooks/03_real_data_workflow.ipynb:cell 5:60:7: F541 [*] f-string without any placeholders
   |
58 |         reward[end-int(2*fps):end] = 1  # 2 second reward period
59 |
60 | print(f"Generated behavioral variables:")
   |       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
61 | print(f"  - Position (x, y): continuous, {x_pos.shape[0]} samples")
62 | print(f"  - Speed: continuous, range {speed.min():.1f} to {speed.max():.1f} cm/s")
   |
   = help: Remove extraneous `f` prefix

notebooks/03_real_data_workflow.ipynb:cell 5:63:7: F541 [*] f-string without any placeholders
   |
61 | print(f"  - Position (x, y): continuous, {x_pos.shape[0]} samples")
62 | print(f"  - Speed: continuous, range {speed.min():.1f} to {speed.max():.1f} cm/s")
63 | print(f"  - Head direction: continuous, -π to π")
   |       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
64 | print(f"  - Trial type: discrete, {len(np.unique(trial_type))} types")
65 | print(f"  - Reward: discrete, {reward.sum()/fps:.1f} seconds total")
   |
   = help: Remove extraneous `f` prefix

notebooks/03_real_data_workflow.ipynb:cell 7:30:7: F541 [*] f-string without any placeholders
   |
28 | )
29 |
30 | print(f"Created Experiment:")
   |       ^^^^^^^^^^^^^^^^^^^^^^ F541
31 | print(f"  - Neurons: {exp.n_cells}")
32 | print(f"  - Duration: {exp.n_frames / exp.fps / 60:.1f} minutes")
   |
   = help: Remove extraneous `f` prefix

notebooks/03_real_data_workflow.ipynb:cell 19:29:25: E722 Do not use bare `except`
   |
27 |                         try:
28 |                             res_grp.attrs[key] = value
29 |                         except:
   |                         ^^^^^^ E722
30 |                             pass  # Skip non-serializable values
   |

src/driada/dim_reduction/data.py:6:1: F403 `from .dr_base import *` used; unable to detect undefined names
  |
4 | import scipy.sparse as sp
5 |
6 | from .dr_base import *
  | ^^^^^^^^^^^^^^^^^^^^^^ F403
7 | from ..utils.data import correlation_matrix, to_numpy_array, rescale
8 | from .embedding import Embedding
  |

src/driada/dim_reduction/data.py:191:47: F405 `METHODS_DICT` may be undefined, or defined from star imports
    |
189 |         if 'e_method' not in e_params or e_params['e_method'] is None:
190 |             method_name = e_params.get('e_method_name')
191 |             if method_name and method_name in METHODS_DICT:
    |                                               ^^^^^^^^^^^^ F405
192 |                 e_params['e_method'] = METHODS_DICT[method_name]
    |

src/driada/dim_reduction/data.py:192:40: F405 `METHODS_DICT` may be undefined, or defined from star imports
    |
190 |             method_name = e_params.get('e_method_name')
191 |             if method_name and method_name in METHODS_DICT:
192 |                 e_params['e_method'] = METHODS_DICT[method_name]
    |                                        ^^^^^^^^^^^^ F405
193 |         
194 |         method = e_params['e_method']
    |

src/driada/dim_reduction/data.py:197:31: F405 `EMBEDDING_CONSTRUCTION_METHODS` may be undefined, or defined from star imports
    |
195 |         method_name = e_params['e_method_name']
196 |
197 |         if method_name not in EMBEDDING_CONSTRUCTION_METHODS:
    |                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F405
198 |             raise Exception('Unknown embedding construction method!')
    |

src/driada/dim_reduction/data.py:237:45: F405 `GRAPH_CONSTRUCTION_METHODS` may be undefined, or defined from star imports
    |
236 |     def get_proximity_graph(self, m_params, g_params):
237 |         if g_params['g_method_name'] not in GRAPH_CONSTRUCTION_METHODS:
    |                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^ F405
238 |             raise Exception('Unknown graph construction method!')
    |

src/driada/dim_reduction/dr_base.py:2:8: F401 [*] `sys` imported but unused
  |
1 | from pynndescent.distances import named_distances
2 | import sys
  |        ^^^ F401
3 | from typing import Dict, Optional, Any, Callable, Union
  |
  = help: Remove unused import: `sys`

src/driada/dim_reduction/dr_base.py:3:41: F401 [*] `typing.Callable` imported but unused
  |
1 | from pynndescent.distances import named_distances
2 | import sys
3 | from typing import Dict, Optional, Any, Callable, Union
  |                                         ^^^^^^^^ F401
4 |
5 | class DRMethod(object):
  |
  = help: Remove unused import

src/driada/dim_reduction/dr_base.py:3:51: F401 [*] `typing.Union` imported but unused
  |
1 | from pynndescent.distances import named_distances
2 | import sys
3 | from typing import Dict, Optional, Any, Callable, Union
  |                                                   ^^^^^ F401
4 |
5 | class DRMethod(object):
  |
  = help: Remove unused import

src/driada/dim_reduction/embedding.py:13:1: F403 `from .dr_base import *` used; unable to detect undefined names
   |
11 | # warnings.filterwarnings("ignore")
12 |
13 | from .dr_base import *
   | ^^^^^^^^^^^^^^^^^^^^^^ F403
14 | from .graph import ProximityGraph
15 | try:
   |

src/driada/dim_reduction/embedding.py:16:5: F403 `from .neural import *` used; unable to detect undefined names
   |
14 | from .graph import ProximityGraph
15 | try:
16 |     from .neural import *
   |     ^^^^^^^^^^^^^^^^^^^^^ F403
17 | except ImportError:
18 |     # torch is optional dependency
   |

src/driada/dim_reduction/embedding.py:20:1: F403 `from .mvu import *` used; unable to detect undefined names
   |
18 |     # torch is optional dependency
19 |     pass
20 | from .mvu import *
   | ^^^^^^^^^^^^^^^^^^ F403
21 |
22 | from ..network.matrix_utils import get_inv_sqrt_diag_matrix
   |

src/driada/dim_reduction/embedding.py:25:14: F405 `np` may be undefined, or defined from star imports
   |
24 | def norm_cross_corr(a, b):
25 |     a = (a - np.mean(a)) / (np.std(a) * len(a))
   |              ^^ F405
26 |     b = (b - np.mean(b)) / (np.std(b))
27 |     c = np.correlate(a, b, 'full')
   |

src/driada/dim_reduction/embedding.py:25:29: F405 `np` may be undefined, or defined from star imports
   |
24 | def norm_cross_corr(a, b):
25 |     a = (a - np.mean(a)) / (np.std(a) * len(a))
   |                             ^^ F405
26 |     b = (b - np.mean(b)) / (np.std(b))
27 |     c = np.correlate(a, b, 'full')
   |

src/driada/dim_reduction/embedding.py:26:14: F405 `np` may be undefined, or defined from star imports
   |
24 | def norm_cross_corr(a, b):
25 |     a = (a - np.mean(a)) / (np.std(a) * len(a))
26 |     b = (b - np.mean(b)) / (np.std(b))
   |              ^^ F405
27 |     c = np.correlate(a, b, 'full')
28 |     return c
   |

src/driada/dim_reduction/embedding.py:26:29: F405 `np` may be undefined, or defined from star imports
   |
24 | def norm_cross_corr(a, b):
25 |     a = (a - np.mean(a)) / (np.std(a) * len(a))
26 |     b = (b - np.mean(b)) / (np.std(b))
   |                             ^^ F405
27 |     c = np.correlate(a, b, 'full')
28 |     return c
   |

src/driada/dim_reduction/embedding.py:27:9: F405 `np` may be undefined, or defined from star imports
   |
25 |     a = (a - np.mean(a)) / (np.std(a) * len(a))
26 |     b = (b - np.mean(b)) / (np.std(b))
27 |     c = np.correlate(a, b, 'full')
   |         ^^ F405
28 |     return c
   |

src/driada/dim_reduction/embedding.py:32:12: F405 `np` may be undefined, or defined from star imports
   |
31 | def remove_outliers(data, thr_percentile):
32 |     thr1 = np.mean(data) + thr_percentile * np.std(data)
   |            ^^ F405
33 |     thr2 = np.mean(data) - thr_percentile * np.std(data)
34 |     good_points = np.where((data < thr1) & (data > thr2))[0]
   |

src/driada/dim_reduction/embedding.py:32:45: F405 `np` may be undefined, or defined from star imports
   |
31 | def remove_outliers(data, thr_percentile):
32 |     thr1 = np.mean(data) + thr_percentile * np.std(data)
   |                                             ^^ F405
33 |     thr2 = np.mean(data) - thr_percentile * np.std(data)
34 |     good_points = np.where((data < thr1) & (data > thr2))[0]
   |

src/driada/dim_reduction/embedding.py:33:12: F405 `np` may be undefined, or defined from star imports
   |
31 | def remove_outliers(data, thr_percentile):
32 |     thr1 = np.mean(data) + thr_percentile * np.std(data)
33 |     thr2 = np.mean(data) - thr_percentile * np.std(data)
   |            ^^ F405
34 |     good_points = np.where((data < thr1) & (data > thr2))[0]
   |

src/driada/dim_reduction/embedding.py:33:45: F405 `np` may be undefined, or defined from star imports
   |
31 | def remove_outliers(data, thr_percentile):
32 |     thr1 = np.mean(data) + thr_percentile * np.std(data)
33 |     thr2 = np.mean(data) - thr_percentile * np.std(data)
   |                                             ^^ F405
34 |     good_points = np.where((data < thr1) & (data > thr2))[0]
   |

src/driada/dim_reduction/embedding.py:34:19: F405 `np` may be undefined, or defined from star imports
   |
32 |     thr1 = np.mean(data) + thr_percentile * np.std(data)
33 |     thr2 = np.mean(data) - thr_percentile * np.std(data)
34 |     good_points = np.where((data < thr1) & (data > thr2))[0]
   |                   ^^ F405
35 |
36 |     return good_points, data[good_points]
   |

src/driada/dim_reduction/embedding.py:51:27: F405 `e_param_filter` may be undefined, or defined from star imports
   |
49 |                 raise Exception('Wrong graph type!')
50 |
51 |         self.all_params = e_param_filter(params)
   |                           ^^^^^^^^^^^^^^ F405
52 |         for key in params:
53 |             setattr(self, key, params[key])
   |

src/driada/dim_reduction/embedding.py:66:9: E722 Do not use bare `except`
   |
64 |         try:
65 |             self.nclasses = len(set(self.labels))
66 |         except:
   |         ^^^^^^ E722
67 |             self.nclasses = np.unique(self.labels)
   |

src/driada/dim_reduction/embedding.py:67:29: F405 `np` may be undefined, or defined from star imports
   |
65 |             self.nclasses = len(set(self.labels))
66 |         except:
67 |             self.nclasses = np.unique(self.labels)
   |                             ^^ F405
68 |
69 |         if self.e_method.nn_based:
   |

src/driada/dim_reduction/embedding.py:120:15: F405 `MaximumVarianceUnfolding` may be undefined, or defined from star imports
    |
119 |     def create_mvu_embedding_(self):
120 |         mvu = MaximumVarianceUnfolding(equation="berkley", solver=cp.SCS, solver_tol=1e-2,
    |               ^^^^^^^^^^^^^^^^^^^^^^^^ F405
121 |                                        eig_tol=1.0e-10, solver_iters=2500,
122 |                                        warm_start=False, seed=None)
    |

src/driada/dim_reduction/embedding.py:120:67: F405 `cp` may be undefined, or defined from star imports
    |
119 |     def create_mvu_embedding_(self):
120 |         mvu = MaximumVarianceUnfolding(equation="berkley", solver=cp.SCS, solver_tol=1e-2,
    |                                                                   ^^ F405
121 |                                        eig_tol=1.0e-10, solver_iters=2500,
122 |                                        warm_start=False, seed=None)
    |

src/driada/dim_reduction/embedding.py:148:19: F405 `np` may be undefined, or defined from star imports
    |
146 |         P = self.graph.get_matrix('trans')
147 |
148 |         start_v = np.ones(n)
    |                   ^^ F405
149 |         # LR mode is much more stable, this is why we use P matrix largest eigenvalues
150 |         eigvals, eigvecs = eigs(P, k=dim + 1, which='LR', v0=start_v, maxiter=n * 1000)
    |

src/driada/dim_reduction/embedding.py:153:19: F405 `np` may be undefined, or defined from star imports
    |
151 |         # eigvals, vecs = eigs(nL, k = dim2 + 1, which = 'SM')
152 |
153 |         eigvals = np.asarray([np.round(np.real(x), 6) for x in eigvals])
    |                   ^^ F405
154 |
155 |         if np.count_nonzero(eigvals == 1.0) > 1:
    |

src/driada/dim_reduction/embedding.py:153:31: F405 `np` may be undefined, or defined from star imports
    |
151 |         # eigvals, vecs = eigs(nL, k = dim2 + 1, which = 'SM')
152 |
153 |         eigvals = np.asarray([np.round(np.real(x), 6) for x in eigvals])
    |                               ^^ F405
154 |
155 |         if np.count_nonzero(eigvals == 1.0) > 1:
    |

src/driada/dim_reduction/embedding.py:153:40: F405 `np` may be undefined, or defined from star imports
    |
151 |         # eigvals, vecs = eigs(nL, k = dim2 + 1, which = 'SM')
152 |
153 |         eigvals = np.asarray([np.round(np.real(x), 6) for x in eigvals])
    |                                        ^^ F405
154 |
155 |         if np.count_nonzero(eigvals == 1.0) > 1:
    |

src/driada/dim_reduction/embedding.py:155:12: F405 `np` may be undefined, or defined from star imports
    |
153 |         eigvals = np.asarray([np.round(np.real(x), 6) for x in eigvals])
154 |
155 |         if np.count_nonzero(eigvals == 1.0) > 1:
    |            ^^ F405
156 |             raise Exception('Graph is not connected, LE will result in errors!')
157 |         else:
    |

src/driada/dim_reduction/embedding.py:158:20: F405 `np` may be undefined, or defined from star imports
    |
156 |             raise Exception('Graph is not connected, LE will result in errors!')
157 |         else:
158 |             vecs = np.real(eigvecs.T[1:])
    |                    ^^ F405
159 |             vec_norms = np.array([np.real(sum([x * x for x in v])) for v in vecs])
160 |             vecs = vecs / vec_norms[:, np.newaxis]
    |

src/driada/dim_reduction/embedding.py:159:25: F405 `np` may be undefined, or defined from star imports
    |
157 |         else:
158 |             vecs = np.real(eigvecs.T[1:])
159 |             vec_norms = np.array([np.real(sum([x * x for x in v])) for v in vecs])
    |                         ^^ F405
160 |             vecs = vecs / vec_norms[:, np.newaxis]
161 |             vecs = vecs.dot(DH.toarray())
    |

src/driada/dim_reduction/embedding.py:159:35: F405 `np` may be undefined, or defined from star imports
    |
157 |         else:
158 |             vecs = np.real(eigvecs.T[1:])
159 |             vec_norms = np.array([np.real(sum([x * x for x in v])) for v in vecs])
    |                                   ^^ F405
160 |             vecs = vecs / vec_norms[:, np.newaxis]
161 |             vecs = vecs.dot(DH.toarray())
    |

src/driada/dim_reduction/embedding.py:160:40: F405 `np` may be undefined, or defined from star imports
    |
158 |             vecs = np.real(eigvecs.T[1:])
159 |             vec_norms = np.array([np.real(sum([x * x for x in v])) for v in vecs])
160 |             vecs = vecs / vec_norms[:, np.newaxis]
    |                                        ^^ F405
161 |             vecs = vecs.dot(DH.toarray())
162 |             self.coords = vecs
    |

src/driada/dim_reduction/embedding.py:170:35: F405 `np` may be undefined, or defined from star imports
    |
168 |         A = A.asfptype()
169 |         # Convert to numpy array instead of matrix to avoid sklearn compatibility issues
170 |         vecs = spectral_embedding(np.asarray(A.todense()), n_components=dim, eigen_solver=None,
    |                                   ^^ F405
171 |                                   random_state=None, eigen_tol=0.0, norm_laplacian=True, drop_first=True).T
    |

src/driada/dim_reduction/embedding.py:221:9: F405 `torch` may be undefined, or defined from star imports
    |
219 |         # ---------------------------------------------------------------------------
220 |
221 |         torch.manual_seed(seed)
    |         ^^^^^ F405
222 |         torch.backends.cudnn.benchmark = False
223 |         torch.backends.cudnn.deterministic = True
    |

src/driada/dim_reduction/embedding.py:222:9: F405 `torch` may be undefined, or defined from star imports
    |
221 |         torch.manual_seed(seed)
222 |         torch.backends.cudnn.benchmark = False
    |         ^^^^^ F405
223 |         torch.backends.cudnn.deterministic = True
    |

src/driada/dim_reduction/embedding.py:223:9: F405 `torch` may be undefined, or defined from star imports
    |
221 |         torch.manual_seed(seed)
222 |         torch.backends.cudnn.benchmark = False
223 |         torch.backends.cudnn.deterministic = True
    |         ^^^^^ F405
224 |
225 |         # TODO: add train_test_split
    |

src/driada/dim_reduction/embedding.py:226:25: F405 `NeuroDataset` may be undefined, or defined from star imports
    |
225 |         # TODO: add train_test_split
226 |         train_dataset = NeuroDataset(self.init_data[:, :int(train_size * self.init_data.shape[1])])
    |                         ^^^^^^^^^^^^ F405
227 |         test_dataset = NeuroDataset(self.init_data[:, int(train_size * self.init_data.shape[1]):])
228 |         train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    |

src/driada/dim_reduction/embedding.py:227:24: F405 `NeuroDataset` may be undefined, or defined from star imports
    |
225 |         # TODO: add train_test_split
226 |         train_dataset = NeuroDataset(self.init_data[:, :int(train_size * self.init_data.shape[1])])
227 |         test_dataset = NeuroDataset(self.init_data[:, int(train_size * self.init_data.shape[1]):])
    |                        ^^^^^^^^^^^^ F405
228 |         train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
229 |         test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)
    |

src/driada/dim_reduction/embedding.py:228:24: F405 `DataLoader` may be undefined, or defined from star imports
    |
226 |         train_dataset = NeuroDataset(self.init_data[:, :int(train_size * self.init_data.shape[1])])
227 |         test_dataset = NeuroDataset(self.init_data[:, int(train_size * self.init_data.shape[1]):])
228 |         train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    |                        ^^^^^^^^^^ F405
229 |         test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)
    |

src/driada/dim_reduction/embedding.py:229:23: F405 `DataLoader` may be undefined, or defined from star imports
    |
227 |         test_dataset = NeuroDataset(self.init_data[:, int(train_size * self.init_data.shape[1]):])
228 |         train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
229 |         test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)
    |                       ^^^^^^^^^^ F405
230 |
231 |         # ---------------------------------------------------------------------------
    |

src/driada/dim_reduction/embedding.py:234:22: F405 `torch` may be undefined, or defined from star imports
    |
232 |         if device is None:
233 |             #  use gpu if available
234 |             device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    |                      ^^^^^ F405
235 |             if verbose:
236 |                 print('device:', device)
    |

src/driada/dim_reduction/embedding.py:234:45: F405 `torch` may be undefined, or defined from star imports
    |
232 |         if device is None:
233 |             #  use gpu if available
234 |             device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    |                                             ^^^^^ F405
235 |             if verbose:
236 |                 print('device:', device)
    |

src/driada/dim_reduction/embedding.py:246:21: F405 `AE` may be undefined, or defined from star imports
    |
244 |             if dec_kwargs is None:
245 |                 dec_kwargs = {}
246 |             model = AE(orig_dim=self.init_data.shape[0], inter_dim=inter_dim, code_dim=self.dim,
    |                     ^^ F405
247 |                        enc_kwargs=enc_kwargs, dec_kwargs=dec_kwargs, device=device)
    |

src/driada/dim_reduction/embedding.py:254:21: F405 `optim` may be undefined, or defined from star imports
    |
253 |         # create an optimizer object
254 |         optimizer = optim.Adam(model.parameters(), lr=lr)
    |                     ^^^^^ F405
255 |
256 |         # mean-squared error loss
    |

src/driada/dim_reduction/embedding.py:257:21: F405 `nn` may be undefined, or defined from star imports
    |
256 |         # mean-squared error loss
257 |         criterion = nn.MSELoss()
    |                     ^^ F405
258 |
259 |         def correlation_loss(data):
    |

src/driada/dim_reduction/embedding.py:261:20: F405 `torch` may be undefined, or defined from star imports
    |
259 |         def correlation_loss(data):
260 |             #print('corr')
261 |             corr = torch.corrcoef(data)
    |                    ^^^^^ F405
262 |             #print(corr)
263 |             nv = corr.shape[0]
    |

src/driada/dim_reduction/embedding.py:264:21: F405 `torch` may be undefined, or defined from star imports
    |
262 |             #print(corr)
263 |             nv = corr.shape[0]
264 |             closs = torch.abs((torch.sum(torch.abs(corr)) - 1*nv)/(nv**2 - nv))  # average pairwise correlation amplitude
    |                     ^^^^^ F405
265 |             #print(closs)
266 |             return closs
    |

src/driada/dim_reduction/embedding.py:264:32: F405 `torch` may be undefined, or defined from star imports
    |
262 |             #print(corr)
263 |             nv = corr.shape[0]
264 |             closs = torch.abs((torch.sum(torch.abs(corr)) - 1*nv)/(nv**2 - nv))  # average pairwise correlation amplitude
    |                                ^^^^^ F405
265 |             #print(closs)
266 |             return closs
    |

src/driada/dim_reduction/embedding.py:264:42: F405 `torch` may be undefined, or defined from star imports
    |
262 |             #print(corr)
263 |             nv = corr.shape[0]
264 |             closs = torch.abs((torch.sum(torch.abs(corr)) - 1*nv)/(nv**2 - nv))  # average pairwise correlation amplitude
    |                                          ^^^^^ F405
265 |             #print(closs)
266 |             return closs
    |

src/driada/dim_reduction/embedding.py:277:24: F405 `torch` may be undefined, or defined from star imports
    |
275 |             #print(ortdata)
276 |             n1, n2 = data.shape[0], ortdata.shape[1]
277 |             fulldata = torch.cat((data, ortdata), dim=0)
    |                        ^^^^^ F405
278 |             corr = torch.corrcoef(fulldata)
279 |             #print(corr)
    |

src/driada/dim_reduction/embedding.py:278:20: F405 `torch` may be undefined, or defined from star imports
    |
276 |             n1, n2 = data.shape[0], ortdata.shape[1]
277 |             fulldata = torch.cat((data, ortdata), dim=0)
278 |             corr = torch.corrcoef(fulldata)
    |                    ^^^^^ F405
279 |             #print(corr)
280 |             #print(corr[n1:, :n1])
    |

src/driada/dim_reduction/embedding.py:282:21: F405 `torch` may be undefined, or defined from star imports
    |
280 |             #print(corr[n1:, :n1])
281 |             nvar = n1*n2
282 |             closs = torch.abs(
    |                     ^^^^^ F405
283 |                 (torch.sum(torch.abs(corr))) / nvar)  # average pairwise correlation amplitude
284 |             #print(closs)
    |

src/driada/dim_reduction/embedding.py:283:18: F405 `torch` may be undefined, or defined from star imports
    |
281 |             nvar = n1*n2
282 |             closs = torch.abs(
283 |                 (torch.sum(torch.abs(corr))) / nvar)  # average pairwise correlation amplitude
    |                  ^^^^^ F405
284 |             #print(closs)
285 |             #print()
    |

src/driada/dim_reduction/embedding.py:283:28: F405 `torch` may be undefined, or defined from star imports
    |
281 |             nvar = n1*n2
282 |             closs = torch.abs(
283 |                 (torch.sum(torch.abs(corr))) / nvar)  # average pairwise correlation amplitude
    |                            ^^^^^ F405
284 |             #print(closs)
285 |             #print()
    |

src/driada/dim_reduction/embedding.py:289:21: F405 `nn` may be undefined, or defined from star imports
    |
288 |         # ---------------------------------------------------------------------------
289 |         f_dropout = nn.Dropout(feature_dropout)
    |                     ^^ F405
290 |
291 |         best_test_epoch = -1
    |

src/driada/dim_reduction/embedding.py:304:50: F405 `torch` may be undefined, or defined from star imports
    |
303 |                 # compute reconstructions
304 |                 noisy_batch_features = f_dropout(torch.ones(batch_features.shape).to(device)) * batch_features
    |                                                  ^^^^^ F405
305 |                 outputs = model(noisy_batch_features.float())
306 |                 code = model.encoder(noisy_batch_features.float()).T
    |

src/driada/dim_reduction/embedding.py:350:31: F405 `torch` may be undefined, or defined from star imports
    |
349 |                 if add_mi_loss:
350 |                     ortdata = torch.tensor(minimize_mi_data[:, indices]).float().to(device)
    |                               ^^^^^ F405
351 |                     train_loss += mi_hyperweight * data_orthogonality_loss(code, ortdata)
    |

src/driada/dim_reduction/embedding.py:376:54: F405 `torch` may be undefined, or defined from star imports
    |
374 |                     batch_features = batch_features.to(device)
375 |                     # compute reconstructions
376 |                     noisy_batch_features = f_dropout(torch.ones(batch_features.shape).to(device)) * batch_features
    |                                                      ^^^^^ F405
377 |                     outputs = model(noisy_batch_features.float())
    |

src/driada/dim_reduction/embedding.py:383:35: F405 `torch` may be undefined, or defined from star imports
    |
382 |                     if add_mi_loss:
383 |                         ortdata = torch.tensor(minimize_mi_data[:, indices]).float().to(device)
    |                                   ^^^^^ F405
384 |                         train_loss += mi_hyperweight * data_orthogonality_loss(code, ortdata)
    |

src/driada/dim_reduction/embedding.py:406:18: F405 `torch` may be undefined, or defined from star imports
    |
405 |         self.nnmodel = best_test_model
406 |         input_ = torch.tensor(self.init_data.T).float().to(device)
    |                  ^^^^^ F405
407 |         self.coords = model.get_code_embedding(input_)
408 |         self.nn_loss = tloss
    |

src/driada/dim_reduction/embedding.py:418:9: F405 `torch` may be undefined, or defined from star imports
    |
416 |     # TODO: add best model mechanism as above
417 |         # ---------------------------------------------------------------------------
418 |         torch.manual_seed(seed)
    |         ^^^^^ F405
419 |         torch.backends.cudnn.benchmark = False
420 |         torch.backends.cudnn.deterministic = True
    |

src/driada/dim_reduction/embedding.py:419:9: F405 `torch` may be undefined, or defined from star imports
    |
417 |         # ---------------------------------------------------------------------------
418 |         torch.manual_seed(seed)
419 |         torch.backends.cudnn.benchmark = False
    |         ^^^^^ F405
420 |         torch.backends.cudnn.deterministic = True
    |

src/driada/dim_reduction/embedding.py:420:9: F405 `torch` may be undefined, or defined from star imports
    |
418 |         torch.manual_seed(seed)
419 |         torch.backends.cudnn.benchmark = False
420 |         torch.backends.cudnn.deterministic = True
    |         ^^^^^ F405
421 |
422 |         # TODO: add train_test_split
    |

src/driada/dim_reduction/embedding.py:424:25: F405 `NeuroDataset` may be undefined, or defined from star imports
    |
422 |         # TODO: add train_test_split
423 |         # TODO: move out data loading for autoencoders
424 |         train_dataset = NeuroDataset(self.init_data[:, :int(train_size * self.init_data.shape[1])])
    |                         ^^^^^^^^^^^^ F405
425 |         test_dataset = NeuroDataset(self.init_data[:, int(train_size * self.init_data.shape[1]):])
426 |         train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    |

src/driada/dim_reduction/embedding.py:425:24: F405 `NeuroDataset` may be undefined, or defined from star imports
    |
423 |         # TODO: move out data loading for autoencoders
424 |         train_dataset = NeuroDataset(self.init_data[:, :int(train_size * self.init_data.shape[1])])
425 |         test_dataset = NeuroDataset(self.init_data[:, int(train_size * self.init_data.shape[1]):])
    |                        ^^^^^^^^^^^^ F405
426 |         train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
427 |         test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)
    |

src/driada/dim_reduction/embedding.py:426:24: F405 `DataLoader` may be undefined, or defined from star imports
    |
424 |         train_dataset = NeuroDataset(self.init_data[:, :int(train_size * self.init_data.shape[1])])
425 |         test_dataset = NeuroDataset(self.init_data[:, int(train_size * self.init_data.shape[1]):])
426 |         train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    |                        ^^^^^^^^^^ F405
427 |         test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)
    |

src/driada/dim_reduction/embedding.py:427:23: F405 `DataLoader` may be undefined, or defined from star imports
    |
425 |         test_dataset = NeuroDataset(self.init_data[:, int(train_size * self.init_data.shape[1]):])
426 |         train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
427 |         test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)
    |                       ^^^^^^^^^^ F405
428 |
429 |         # ---------------------------------------------------------------------------
    |

src/driada/dim_reduction/embedding.py:431:18: F405 `torch` may be undefined, or defined from star imports
    |
429 |         # ---------------------------------------------------------------------------
430 |         #  use gpu if available
431 |         device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    |                  ^^^^^ F405
432 |
433 |         if not continue_learning:
    |

src/driada/dim_reduction/embedding.py:431:41: F405 `torch` may be undefined, or defined from star imports
    |
429 |         # ---------------------------------------------------------------------------
430 |         #  use gpu if available
431 |         device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    |                                         ^^^^^ F405
432 |
433 |         if not continue_learning:
    |

src/driada/dim_reduction/embedding.py:436:21: F405 `VAE` may be undefined, or defined from star imports
    |
434 |             # create a model from `VAE` autoencoder class
435 |             # load it to the specified device, either gpu or cpu
436 |             model = VAE(orig_dim=len(self.init_data), inter_dim=inter_dim, code_dim=self.dim,
    |                     ^^^ F405
437 |                         enc_kwargs=enc_kwargs, dec_kwargs=dec_kwargs, device=device)
438 |             model = model.to(device)
    |

src/driada/dim_reduction/embedding.py:444:21: F405 `optim` may be undefined, or defined from star imports
    |
442 |         # create an optimizer object
443 |         # Adam optimizer with learning rate lr
444 |         optimizer = optim.Adam(model.parameters(), lr=lr)
    |                     ^^^^^ F405
445 |
446 |         # BCE error loss
    |

src/driada/dim_reduction/embedding.py:448:21: F405 `nn` may be undefined, or defined from star imports
    |
446 |         # BCE error loss
447 |         #criterion = nn.BCELoss(reduction='sum')
448 |         criterion = nn.MSELoss()
    |                     ^^ F405
449 |
450 |         # ---------------------------------------------------------------------------
    |

src/driada/dim_reduction/embedding.py:451:21: F405 `nn` may be undefined, or defined from star imports
    |
450 |         # ---------------------------------------------------------------------------
451 |         f_dropout = nn.Dropout(feature_dropout)
    |                     ^^ F405
452 |
453 |         for epoch in range(epochs):
    |

src/driada/dim_reduction/embedding.py:464:34: F405 `torch` may be undefined, or defined from star imports
    |
463 |                 # compute reconstructions
464 |                 data = f_dropout(torch.ones(batch_features.shape).to(device)) * batch_features
    |                                  ^^^^^ F405
465 |                 data = data.to(device).float()  # Ensure float32
466 |                 reconstruction, mu, logvar = model(data)
    |

src/driada/dim_reduction/embedding.py:470:35: F405 `torch` may be undefined, or defined from star imports
    |
468 |                 # compute training reconstruction loss
469 |                 mse_loss = criterion(reconstruction, data)
470 |                 kld_loss = -0.5 * torch.sum(
    |                                   ^^^^^ F405
471 |                     1 + logvar - mu.pow(2) - logvar.exp())  # * train_dataset.__len__()/batch_size
472 |                 train_loss = mse_loss + kld_weight*kld_loss
    |

src/driada/dim_reduction/embedding.py:496:38: F405 `torch` may be undefined, or defined from star imports
    |
494 |                 tloss = 0
495 |                 for batch_features, _, _ in test_loader:  # NeuroDataset returns 3 values
496 |                     data = f_dropout(torch.ones(batch_features.shape).to(device)) * batch_features
    |                                      ^^^^^ F405
497 |                     data = data.to(device).float()  # Ensure float32
498 |                     reconstruction, mu, logvar = model(data)
    |

src/driada/dim_reduction/embedding.py:502:39: F405 `torch` may be undefined, or defined from star imports
    |
500 |                     # compute training reconstruction loss
501 |                     mse_loss = criterion(reconstruction, data)
502 |                     kld_loss = -0.5 * torch.sum(
    |                                       ^^^^^ F405
503 |                         1 + logvar - mu.pow(2) - logvar.exp())  # * train_dataset.__len__()/batch_size
504 |                     test_loss = mse_loss + kld_weight * kld_loss
    |

src/driada/dim_reduction/embedding.py:513:18: F405 `torch` may be undefined, or defined from star imports
    |
512 |         self.nnmodel = model
513 |         input_ = torch.tensor(self.init_data.T).float().to(device)
    |                  ^^^^^ F405
514 |         self.coords = model.get_code_embedding(input_)
    |

src/driada/dim_reduction/graph.py:15:1: F403 `from .dr_base import *` used; unable to detect undefined names
   |
13 | from scipy.sparse.csgraph import shortest_path
14 | from umap.umap_ import fuzzy_simplicial_set
15 | from .dr_base import *
   | ^^^^^^^^^^^^^^^^^^^^^^ F403
16 |
17 | from ..network.net_base import Network
   |

src/driada/dim_reduction/graph.py:26:34: F405 `m_param_filter` may be undefined, or defined from star imports
   |
25 |     def __init__(self, d, m_params, g_params, create_nx_graph=False):
26 |         self.all_metric_params = m_param_filter(m_params)
   |                                  ^^^^^^^^^^^^^^ F405
27 |         self.metric = m_params['metric_name']
28 |         self.metric_args = {key: self.all_metric_params[key] for key in self.all_metric_params.keys()
   |

src/driada/dim_reduction/graph.py:31:22: F405 `g_param_filter` may be undefined, or defined from star imports
   |
29 |                             if key not in ['metric_name', 'sigma']}
30 |
31 |         all_params = g_param_filter(g_params)
   |                      ^^^^^^^^^^^^^^ F405
32 |         for key in all_params:
33 |             setattr(self, key, g_params[key])
   |

src/driada/dim_reduction/graph.py:123:29: F405 `named_distances` may be undefined, or defined from star imports
    |
121 |             # Custom metric function passed directly
122 |             curr_metric = self.metric
123 |         elif self.metric in named_distances:
    |                             ^^^^^^^^^^^^^^^ F405
124 |             # Built-in metric name
125 |             curr_metric = self.metric
    |

src/driada/dim_reduction/graph.py:133:89: F405 `named_distances` may be undefined, or defined from star imports
    |
131 |                     raise ValueError(f"Global '{self.metric}' is not a callable metric function")
132 |             except KeyError:
133 |                 raise ValueError(f"Unknown metric '{self.metric}'. Must be one of {list(named_distances.keys())}, "
    |                                                                                         ^^^^^^^^^^^^^^^ F405
134 |                                f"a callable function, or a global function name.")
    |

src/driada/dim_reduction/graph.py:276:9: F841 Local variable `avg` is assigned to but never used
    |
274 |         distr_x = hist[1][:-1] + dx / 2
275 |         distr_y = hist[0] / max(hist[0][0:nbins])
276 |         avg = np.mean(all_dists)
    |         ^^^ F841
277 |         std = np.std(all_dists / dmax)
    |
    = help: Remove assignment to unused variable `avg`

src/driada/dim_reduction/graph.py:306:13: F841 Local variable `ax` is assigned to but never used
    |
304 |         if plot:
305 |             fig = plt.figure(1, figsize=(12, 10))
306 |             ax = fig.add_subplot(111)
    |             ^^ F841
307 |             plt.hist(all_dists / dmax, bins=nbins, histtype='stepfilled', density=True, log=True)
    |
    = help: Remove assignment to unused variable `ax`

src/driada/dim_reduction/manifold_metrics.py:20:37: F401 [*] `typing.Union` imported but unused
   |
18 | from scipy.stats import spearmanr
19 | from scipy.linalg import orthogonal_procrustes
20 | from typing import Optional, Tuple, Union
   |                                     ^^^^^ F401
   |
   = help: Remove unused import: `typing.Union`

src/driada/dim_reduction/manifold_metrics.py:139:5: F841 Local variable `dist_low` is assigned to but never used
    |
137 |     # Compute distance matrices
138 |     dist_high = compute_distance_matrix(X_high)
139 |     dist_low = compute_distance_matrix(X_low)
    |     ^^^^^^^^ F841
140 |     
141 |     # Get k-NN in embedded space
    |
    = help: Remove assignment to unused variable `dist_low`

src/driada/dim_reduction/manifold_metrics.py:200:5: F841 Local variable `dist_high` is assigned to but never used
    |
199 |     # Compute distance matrices
200 |     dist_high = compute_distance_matrix(X_high)
    |     ^^^^^^^^^ F841
201 |     dist_low = compute_distance_matrix(X_low)
    |
    = help: Remove assignment to unused variable `dist_high`

src/driada/dim_reduction/manifold_metrics.py:680:5: F841 Local variable `n` is assigned to but never used
    |
679 |     # Compute circular correlation
680 |     n = len(z1)
    |     ^ F841
681 |     mean_z1 = np.mean(z1)
682 |     mean_z2 = np.mean(z2)
    |
    = help: Remove assignment to unused variable `n`

src/driada/dim_reduction/neural.py:15:27: F401 [*] `torch.optim` imported but unused
   |
13 |     import torch.nn as nn
14 |     import torch.nn.functional as F
15 |     import torch.optim as optim
   |                           ^^^^^ F401
16 |     from torch.utils.data import Dataset, DataLoader
   |
   = help: Remove unused import: `torch.optim`

src/driada/dim_reduction/neural.py:16:43: F401 [*] `torch.utils.data.DataLoader` imported but unused
   |
14 |     import torch.nn.functional as F
15 |     import torch.optim as optim
16 |     from torch.utils.data import Dataset, DataLoader
   |                                           ^^^^^^^^^^ F401
   |
   = help: Remove unused import: `torch.utils.data.DataLoader`

src/driada/dimensionality/effective.py:1:1: F403 `from .utils import *` used; unable to detect undefined names
  |
1 | from .utils import *
  | ^^^^^^^^^^^^^^^^^^^^ F403
2 | from scipy.stats import entropy
3 | import warnings
  |

src/driada/dimensionality/effective.py:14:34: F405 `np` may be undefined, or defined from star imports
   |
12 |         raise ValueError('Renyi entropy is undefined for q<0')
13 |
14 |     norm_corr_eigs = corr_eigs / np.sum(corr_eigs)
   |                                  ^^ F405
15 |     if q == 1:
16 |         # standard entropy
   |

src/driada/dimensionality/effective.py:23:15: F405 `np` may be undefined, or defined from star imports
   |
21 |         return (sum(corr_eigs)**2)/sum([e**2 for e in corr_eigs])
22 |
23 |     elif q == np.inf:
   |               ^^ F405
24 |         # min-entropy
25 |         return np.sum(corr_eigs)/np.max(corr_eigs)
   |

src/driada/dimensionality/effective.py:25:16: F405 `np` may be undefined, or defined from star imports
   |
23 |     elif q == np.inf:
24 |         # min-entropy
25 |         return np.sum(corr_eigs)/np.max(corr_eigs)
   |                ^^ F405
26 |
27 |     else:
   |

src/driada/dimensionality/effective.py:25:34: F405 `np` may be undefined, or defined from star imports
   |
23 |     elif q == np.inf:
24 |         # min-entropy
25 |         return np.sum(corr_eigs)/np.max(corr_eigs)
   |                                  ^^ F405
26 |
27 |     else:
   |

src/driada/dimensionality/effective.py:28:30: F405 `np` may be undefined, or defined from star imports
   |
27 |     else:
28 |         return 1.0/(1.0 - q)*np.log(np.sum([p**q for p in norm_corr_eigs]))
   |                              ^^ F405
   |

src/driada/dimensionality/effective.py:28:37: F405 `np` may be undefined, or defined from star imports
   |
27 |     else:
28 |         return 1.0/(1.0 - q)*np.log(np.sum([p**q for p in norm_corr_eigs]))
   |                                     ^^ F405
   |

src/driada/dimensionality/effective.py:38:26: F405 `correct_cov_spectrum` may be undefined, or defined from star imports
   |
36 |     cmat = correlation_matrix(data)
37 |     if enable_correction:
38 |         corrected_eigs = correct_cov_spectrum(n, t, cmat, **correction_kwargs)
   |                          ^^^^^^^^^^^^^^^^^^^^ F405
39 |         final_eigs = corrected_eigs[-1]
40 |     else:
   |

src/driada/dimensionality/effective.py:41:22: F405 `eigh` may be undefined, or defined from star imports
   |
39 |         final_eigs = corrected_eigs[-1]
40 |     else:
41 |         final_eigs = eigh(cmat, eigvals_only=True)
   |                      ^^^^ F405
42 |
43 |     return _eff_dim(final_eigs, q=q)
   |

src/driada/dimensionality/intrinsic.py:294:32: F401 [*] `scipy.optimize.curve_fit` imported but unused
    |
292 |     import scipy.sparse as sp
293 |     from scipy.sparse.csgraph import shortest_path
294 |     from scipy.optimize import curve_fit
    |                                ^^^^^^^^^ F401
295 |     from sklearn.neighbors import kneighbors_graph
    |
    = help: Remove unused import: `scipy.optimize.curve_fit`

src/driada/dimensionality/utils.py:1:36: F401 [*] `scipy.spatial.distance.pdist` imported but unused
  |
1 | from scipy.spatial.distance import pdist, cdist
  |                                    ^^^^^ F401
2 | from scipy.sparse.csgraph import shortest_path
3 | from scipy.stats import pearsonr, norm
  |
  = help: Remove unused import

src/driada/dimensionality/utils.py:1:43: F401 [*] `scipy.spatial.distance.cdist` imported but unused
  |
1 | from scipy.spatial.distance import pdist, cdist
  |                                           ^^^^^ F401
2 | from scipy.sparse.csgraph import shortest_path
3 | from scipy.stats import pearsonr, norm
  |
  = help: Remove unused import

src/driada/dimensionality/utils.py:2:34: F401 [*] `scipy.sparse.csgraph.shortest_path` imported but unused
  |
1 | from scipy.spatial.distance import pdist, cdist
2 | from scipy.sparse.csgraph import shortest_path
  |                                  ^^^^^^^^^^^^^ F401
3 | from scipy.stats import pearsonr, norm
4 | from scipy.linalg import eigh
  |
  = help: Remove unused import: `scipy.sparse.csgraph.shortest_path`

src/driada/experiment/exp_base.py:4:23: F401 [*] `itertools.combinations` imported but unused
  |
2 | import warnings
3 | import tqdm
4 | from itertools import combinations
  |                       ^^^^^^^^^^^^ F401
5 | import pickle
  |
  = help: Remove unused import: `itertools.combinations`

src/driada/experiment/exp_base.py:10:38: F401 [*] `.wavelet_event_detection.WVT_EVENT_DETECTION_PARAMS` imported but unused
   |
 8 | from ..information.info_base import MultiTimeSeries
 9 | from .neuron import DEFAULT_MIN_BEHAVIOUR_TIME, DEFAULT_T_OFF, DEFAULT_FPS, MIN_CA_SHIFT, Neuron
10 | from .wavelet_event_detection import WVT_EVENT_DETECTION_PARAMS, extract_wvt_events, events_to_ts_array, ridges_to_containers
   |                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^ F401
11 | from ..utils.data import get_hash, populate_nested_dict
12 | from ..information.info_base import get_1d_mi
   |
   = help: Remove unused import

src/driada/experiment/exp_base.py:10:66: F401 [*] `.wavelet_event_detection.extract_wvt_events` imported but unused
   |
 8 | from ..information.info_base import MultiTimeSeries
 9 | from .neuron import DEFAULT_MIN_BEHAVIOUR_TIME, DEFAULT_T_OFF, DEFAULT_FPS, MIN_CA_SHIFT, Neuron
10 | from .wavelet_event_detection import WVT_EVENT_DETECTION_PARAMS, extract_wvt_events, events_to_ts_array, ridges_to_containers
   |                                                                  ^^^^^^^^^^^^^^^^^^ F401
11 | from ..utils.data import get_hash, populate_nested_dict
12 | from ..information.info_base import get_1d_mi
   |
   = help: Remove unused import

src/driada/experiment/exp_base.py:10:86: F401 [*] `.wavelet_event_detection.events_to_ts_array` imported but unused
   |
 8 | from ..information.info_base import MultiTimeSeries
 9 | from .neuron import DEFAULT_MIN_BEHAVIOUR_TIME, DEFAULT_T_OFF, DEFAULT_FPS, MIN_CA_SHIFT, Neuron
10 | from .wavelet_event_detection import WVT_EVENT_DETECTION_PARAMS, extract_wvt_events, events_to_ts_array, ridges_to_containers
   |                                                                                      ^^^^^^^^^^^^^^^^^^ F401
11 | from ..utils.data import get_hash, populate_nested_dict
12 | from ..information.info_base import get_1d_mi
   |
   = help: Remove unused import

src/driada/experiment/exp_base.py:10:106: F401 [*] `.wavelet_event_detection.ridges_to_containers` imported but unused
   |
 8 | from ..information.info_base import MultiTimeSeries
 9 | from .neuron import DEFAULT_MIN_BEHAVIOUR_TIME, DEFAULT_T_OFF, DEFAULT_FPS, MIN_CA_SHIFT, Neuron
10 | from .wavelet_event_detection import WVT_EVENT_DETECTION_PARAMS, extract_wvt_events, events_to_ts_array, ridges_to_containers
   |                                                                                                          ^^^^^^^^^^^^^^^^^^^^ F401
11 | from ..utils.data import get_hash, populate_nested_dict
12 | from ..information.info_base import get_1d_mi
   |
   = help: Remove unused import

src/driada/experiment/exp_base.py:70:13: F541 [*] f-string without any placeholders
   |
68 |                       for feat, length in dfeat_lengths.items()]
69 |         raise ValueError(
70 |             f"Dynamic features have different lengths:\n" + "\n".join(length_info)
   |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
71 |         )
   |
   = help: Remove extraneous `f` prefix

src/driada/experiment/exp_base.py:559:23: F541 [*] f-string without any placeholders
    |
557 |         else:
558 |             if not force_update:
559 |                 print(f'To forcefully update the stats, set "force_update=True"')
    |                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
560 |             else:
561 |                 self._update_stats_and_significance(stats, mode, cell_id, feat_id, stage2_only=stage2_only)
    |
    = help: Remove extraneous `f` prefix

src/driada/experiment/exp_base.py:590:19: F541 [*] f-string without any placeholders
    |
588 |             stats = self.stats_tables[mode][feat_id][cell_id]
589 |         else:
590 |             print(f'Consider recalculating stats')
    |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
591 |
592 |         return stats
    |
    = help: Remove extraneous `f` prefix

src/driada/experiment/exp_base.py:603:19: F541 [*] f-string without any placeholders
    |
601 |             sig = self.significance_tables[mode][feat_id][cell_id]
602 |         else:
603 |             print(f'Consider recalculating stats')
    |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
604 |
605 |         return sig
    |
    = help: Remove extraneous `f` prefix

src/driada/experiment/neuron.py:6:1: F403 `from .wavelet_event_detection import *` used; unable to detect undefined names
  |
4 | from scipy.optimize import minimize
5 | from ..information.info_base import TimeSeries
6 | from .wavelet_event_detection import *
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F403
7 |
8 | DEFAULT_T_RISE = 0.25 #sec
  |

src/driada/experiment/neuron.py:170:20: F841 Local variable `noise_amplitude` is assigned to but never used
    |
169 |         shuf_ca = np.zeros(self.n_frames)
170 |         opt_t_off, noise_amplitude = self.get_t_off(), self.get_noise_ampl()
    |                    ^^^^^^^^^^^^^^^ F841
171 |
172 |         #noise = np.random.normal(loc = 0, scale = noise_amplitude, size = len(self.ca))
    |
    = help: Remove assignment to unused variable `noise_amplitude`

src/driada/experiment/spike_reconstruction.py:9:48: F401 [*] `typing.Callable` imported but unused
   |
 8 | import numpy as np
 9 | from typing import Tuple, Dict, Any, Optional, Callable
   |                                                ^^^^^^^^ F401
10 | from scipy.ndimage import gaussian_filter1d
11 | from scipy.signal import find_peaks
   |
   = help: Remove unused import: `typing.Callable`

src/driada/experiment/synthetic/core.py:10:1: F403 `from ..exp_base import *` used; unable to detect undefined names
   |
 8 | import numpy as np
 9 | import warnings
10 | from ..exp_base import *
   | ^^^^^^^^^^^^^^^^^^^^^^^^ F403
11 | from ...information.info_base import TimeSeries, MultiTimeSeries, aggregate_multiple_ts
   |

src/driada/experiment/synthetic/core.py:11:38: F401 [*] `...information.info_base.TimeSeries` imported but unused
   |
 9 | import warnings
10 | from ..exp_base import *
11 | from ...information.info_base import TimeSeries, MultiTimeSeries, aggregate_multiple_ts
   |                                      ^^^^^^^^^^ F401
   |
   = help: Remove unused import

src/driada/experiment/synthetic/core.py:11:50: F401 [*] `...information.info_base.MultiTimeSeries` imported but unused
   |
 9 | import warnings
10 | from ..exp_base import *
11 | from ...information.info_base import TimeSeries, MultiTimeSeries, aggregate_multiple_ts
   |                                                  ^^^^^^^^^^^^^^^ F401
   |
   = help: Remove unused import

src/driada/experiment/synthetic/core.py:11:67: F401 [*] `...information.info_base.aggregate_multiple_ts` imported but unused
   |
 9 | import warnings
10 | from ..exp_base import *
11 | from ...information.info_base import TimeSeries, MultiTimeSeries, aggregate_multiple_ts
   |                                                                   ^^^^^^^^^^^^^^^^^^^^^ F401
   |
   = help: Remove unused import

src/driada/experiment/synthetic/experiment_generators.py:10:19: F401 [*] `.core.validate_peak_rate` imported but unused
   |
 8 | import numpy as np
 9 | import tqdm
10 | from .core import validate_peak_rate, generate_pseudo_calcium_signal, generate_pseudo_calcium_multisignal
   |                   ^^^^^^^^^^^^^^^^^^ F401
11 | from .time_series import (
12 |     generate_binary_time_series, generate_fbm_time_series,
   |
   = help: Remove unused import

src/driada/experiment/synthetic/experiment_generators.py:10:71: F401 [*] `.core.generate_pseudo_calcium_multisignal` imported but unused
   |
 8 | import numpy as np
 9 | import tqdm
10 | from .core import validate_peak_rate, generate_pseudo_calcium_signal, generate_pseudo_calcium_multisignal
   |                                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F401
11 | from .time_series import (
12 |     generate_binary_time_series, generate_fbm_time_series,
   |
   = help: Remove unused import

src/driada/experiment/synthetic/experiment_generators.py:592:19: F541 [*] f-string without any placeholders
    |
590 |         # Ensure true independence by regenerating features with different seeds
591 |         if verbose:
592 |             print(f'  Ensuring feature independence by regenerating behavioral features...')
    |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
593 |         
594 |         # Use completely different seeds for independent features
    |
    = help: Remove extraneous `f` prefix

src/driada/experiment/synthetic/experiment_generators.py:856:15: F541 [*] f-string without any placeholders
    |
855 |     if verbose:
856 |         print(f'  Mixed population generated successfully!')
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
857 |         print(f'  Total calcium traces: {combined_calcium.shape}')
858 |         print(f'  Total features: {len(dynamic_features)}')
    |
    = help: Remove extraneous `f` prefix

src/driada/experiment/synthetic/mixed_selectivity.py:13:45: F401 [*] `.time_series.apply_poisson_to_binary_series` imported but unused
   |
11 | from .time_series import (
12 |     generate_binary_time_series, generate_fbm_time_series,
13 |     discretize_via_roi, delete_one_islands, apply_poisson_to_binary_series
   |                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F401
14 | )
15 | from ..exp_base import Experiment
   |
   = help: Remove unused import: `.time_series.apply_poisson_to_binary_series`

src/driada/experiment/wavelet_event_detection.py:1:8: F401 [*] `os` imported but unused
  |
1 | import os
  |        ^^ F401
2 | from os.path import join, splitext
3 | import tqdm
  |
  = help: Remove unused import: `os`

src/driada/experiment/wavelet_event_detection.py:2:21: F401 [*] `os.path.join` imported but unused
  |
1 | import os
2 | from os.path import join, splitext
  |                     ^^^^ F401
3 | import tqdm
4 | import matplotlib.pyplot as plt
  |
  = help: Remove unused import

src/driada/experiment/wavelet_event_detection.py:2:27: F401 [*] `os.path.splitext` imported but unused
  |
1 | import os
2 | from os.path import join, splitext
  |                           ^^^^^^^^ F401
3 | import tqdm
4 | import matplotlib.pyplot as plt
  |
  = help: Remove unused import

src/driada/experiment/wavelet_event_detection.py:18:1: F403 `from .wavelet_ridge import *` used; unable to detect undefined names
   |
16 | from numba import njit
17 |
18 | from .wavelet_ridge import *
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F403
19 |
20 | WVT_EVENT_DETECTION_PARAMS = {
   |

src/driada/experiment/wavelet_event_detection.py:26:36: F405 `np` may be undefined, or defined from star imports
   |
24 |                   'gamma': 3,      # Generalized Morse Wavelet parameter, FIXED
25 |                   'eps': 10,         # spacing between consecutive events, frames
26 |                   'manual_scales': np.logspace(2.5,5.5,50, base=2),
   |                                    ^^ F405
27 |
28 |                   # ridge filtering params
   |

src/driada/experiment/wavelet_event_detection.py:42:19: F405 `np` may be undefined, or defined from star imports
   |
40 |     axs[0].set_xlim(0, len(x))
41 |     axs[0].plot(x, c='b')
42 |     axs[1].imshow(np.abs(Wx), aspect='auto', cmap='turbo')
   |                   ^^ F405
   |

src/driada/experiment/wavelet_event_detection.py:53:15: F405 `np` may be undefined, or defined from star imports
   |
52 |     #wvtdata = np.real(np.abs(W))
53 |     wvtdata = np.real(W)
   |               ^^ F405
54 |     scale_inds = np.arange(scmin, scmax)[::-1]
55 |     if all_wvt_times is None:
   |

src/driada/experiment/wavelet_event_detection.py:54:18: F405 `np` may be undefined, or defined from star imports
   |
52 |     #wvtdata = np.real(np.abs(W))
53 |     wvtdata = np.real(W)
54 |     scale_inds = np.arange(scmin, scmax)[::-1]
   |                  ^^ F405
55 |     if all_wvt_times is None:
56 |         all_wvt_times = [time_resolution(wavelet, scale=wvt_scales[sc], nondim=False, min_decay=200) for sc in scale_inds]
   |

src/driada/experiment/wavelet_event_detection.py:59:13: F405 `np` may be undefined, or defined from star imports
   |
58 |     # determine peak positions for all scales
59 |     peaks = np.zeros((len(scale_inds), len(sig)))
   |             ^^ F405
60 |
61 |     all_ridges = []
   |

src/driada/experiment/wavelet_event_detection.py:70:27: F405 `Ridge` may be undefined, or defined from star imports
   |
69 |         if len(all_ridges) == 0:
70 |             all_ridges = [Ridge(mi, peaks[i, mi], wvt_scales[si], wvt_time) for mi in max_inds]
   |                           ^^^^^ F405
71 |         else:
72 |             # 1. extend old ridges
   |

src/driada/experiment/wavelet_event_detection.py:97:44: F405 `np` may be undefined, or defined from star imports
   |
95 |                 else:
96 |                     # extend ridge with the best maximum, others will later form new ridges
97 |                     best_cand = candidates[np.argmax(peaks[i, np.array(candidates)])]
   |                                            ^^ F405
98 |                     ridge.extend(best_cand, peaks[i, best_cand], wvt_scales[si], wvt_time)
99 |                     maxima_used_for_prolongation.append(best_cand)
   |

src/driada/experiment/wavelet_event_detection.py:97:63: F405 `np` may be undefined, or defined from star imports
   |
95 |                 else:
96 |                     # extend ridge with the best maximum, others will later form new ridges
97 |                     best_cand = candidates[np.argmax(peaks[i, np.array(candidates)])]
   |                                                               ^^ F405
98 |                     ridge.extend(best_cand, peaks[i, best_cand], wvt_scales[si], wvt_time)
99 |                     maxima_used_for_prolongation.append(best_cand)
   |

src/driada/experiment/wavelet_event_detection.py:103:27: F405 `Ridge` may be undefined, or defined from star imports
    |
102 | …     # 2. generate new ridges
103 | …     new_ridges = [Ridge(mi, peaks[i, mi], wvt_scales[si], wvt_time) for mi in max_inds if mi not in maxima_used_for_prolongation]
    |                     ^^^^^ F405
104 | …     all_ridges.extend(new_ridges)
    |

src/driada/experiment/wavelet_event_detection.py:120:20: F405 `np` may be undefined, or defined from star imports
    |
118 |     for si in range(wvtdata.shape[0]):
119 |         wvt_time = wvt_times[si]
120 |         max_inds = np.nonzero(peaks[si,:])[0]
    |                    ^^ F405
121 |
122 |         if start:
    |

src/driada/experiment/wavelet_event_detection.py:123:27: F405 `Ridge` may be undefined, or defined from star imports
    |
122 |         if start:
123 |             all_ridges = [Ridge(mi, peaks[si, mi], wvt_scales[si], wvt_time) for mi in max_inds]
    |                           ^^^^^ F405
124 |             start = False
125 |         else:
    |

src/driada/experiment/wavelet_event_detection.py:151:44: F405 `np` may be undefined, or defined from star imports
    |
149 |                 else:
150 |                     # extend ridge with the best maximum, others will later form new ridges
151 |                     best_cand = candidates[np.argmax(peaks[si, np.array(candidates)])]
    |                                            ^^ F405
152 |                     ridge.extend(best_cand, peaks[si, best_cand], wvt_scales[si], wvt_time)
153 |                     maxima_used_for_prolongation.append(best_cand)
    |

src/driada/experiment/wavelet_event_detection.py:151:64: F405 `np` may be undefined, or defined from star imports
    |
149 |                 else:
150 |                     # extend ridge with the best maximum, others will later form new ridges
151 |                     best_cand = candidates[np.argmax(peaks[si, np.array(candidates)])]
    |                                                                ^^ F405
152 |                     ridge.extend(best_cand, peaks[si, best_cand], wvt_scales[si], wvt_time)
153 |                     maxima_used_for_prolongation.append(best_cand)
    |

src/driada/experiment/wavelet_event_detection.py:157:27: F405 `Ridge` may be undefined, or defined from star imports
    |
156 | …     # 2. generate new ridges
157 | …     new_ridges = [Ridge(mi, peaks[si, mi], wvt_scales[si], wvt_time) for mi in max_inds if mi not in maxima_used_for_prolongation]
    |                     ^^^^^ F405
158 | …     # Use += instead of extend() to fix Numba 0.60+ type inference issue
159 | …     all_ridges += new_ridges
    |

src/driada/experiment/wavelet_event_detection.py:195:19: F405 `np` may be undefined, or defined from star imports
    |
194 |     W, wvt_scales = cwt(sig, wavelet=wavelet, fs=fps, scales=manual_scales)
195 |     rev_wvtdata = np.real(W)
    |                   ^^ F405
196 |
197 |     all_max_inds = argrelmax(rev_wvtdata, axis=1, order=eps)
    |

src/driada/experiment/wavelet_event_detection.py:198:13: F405 `np` may be undefined, or defined from star imports
    |
197 |     all_max_inds = argrelmax(rev_wvtdata, axis=1, order=eps)
198 |     peaks = np.zeros(rev_wvtdata.shape)
    |             ^^ F405
199 |     peaks[all_max_inds] = rev_wvtdata[all_max_inds]
    |

src/driada/experiment/wavelet_event_detection.py:218:53: F405 `np` may be undefined, or defined from star imports
    |
216 |     sigma = wvt_kwargs.get('sigma', 8)
217 |     eps = wvt_kwargs.get('eps', 10)
218 |     manual_scales = wvt_kwargs.get('manual_scales', np.logspace(2.5,5.5,50, base=2))
    |                                                     ^^ F405
219 |
220 |     scale_length_thr = wvt_kwargs.get('scale_length_thr', 40)
    |

src/driada/experiment/wavelet_event_detection.py:255:14: F405 `np` may be undefined, or defined from star imports
    |
253 | def events_to_ts_array_numba(length, ncells, st_ev_inds_flat, end_ev_inds_flat, event_counts, fps, min_event_dur, max_event_dur):
254 |     """Numba-optimized version of events_to_ts_array."""
255 |     spikes = np.zeros((ncells, length))
    |              ^^ F405
256 |
257 |     mindur = int(min_event_dur * fps)
    |

src/driada/experiment/wavelet_event_detection.py:284:20: F405 `np` may be undefined, or defined from star imports
    |
283 |     # Flatten the jagged arrays for numba
284 |     event_counts = np.array([len(st_ev_inds[i]) for i in range(ncells)])
    |                    ^^ F405
285 |     st_ev_inds_flat = np.concatenate([st_ev_inds[i] for i in range(ncells)])
286 |     end_ev_inds_flat = np.concatenate([end_ev_inds[i] for i in range(ncells)])
    |

src/driada/experiment/wavelet_event_detection.py:285:23: F405 `np` may be undefined, or defined from star imports
    |
283 |     # Flatten the jagged arrays for numba
284 |     event_counts = np.array([len(st_ev_inds[i]) for i in range(ncells)])
285 |     st_ev_inds_flat = np.concatenate([st_ev_inds[i] for i in range(ncells)])
    |                       ^^ F405
286 |     end_ev_inds_flat = np.concatenate([end_ev_inds[i] for i in range(ncells)])
    |

src/driada/experiment/wavelet_event_detection.py:286:24: F405 `np` may be undefined, or defined from star imports
    |
284 |     event_counts = np.array([len(st_ev_inds[i]) for i in range(ncells)])
285 |     st_ev_inds_flat = np.concatenate([st_ev_inds[i] for i in range(ncells)])
286 |     end_ev_inds_flat = np.concatenate([end_ev_inds[i] for i in range(ncells)])
    |                        ^^ F405
287 |     
288 |     # Call numba function
    |

src/driada/experiment/wavelet_ridge.py:3:19: F401 [*] `numba.int32` imported but unused
  |
1 | from numba.experimental import jitclass
2 | import numpy as np
3 | from numba import int32, float32, boolean    # import the types
  |                   ^^^^^ F401
4 | from numba import types, typed, njit
  |
  = help: Remove unused import: `numba.int32`

src/driada/gdrive/download.py:8:8: F401 [*] `shutil` imported but unused
  |
6 | import gdown
7 | import pandas as pd
8 | import shutil
  |        ^^^^^^ F401
9 | from pathlib import Path
  |
  = help: Remove unused import: `shutil`

src/driada/gdrive/download.py:11:1: F403 `from .gdrive_utils import *` used; unable to detect undefined names
   |
 9 | from pathlib import Path
10 |
11 | from .gdrive_utils import *
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^ F403
12 | from ..utils.output import *
   |

src/driada/gdrive/download.py:12:1: F403 `from ..utils.output import *` used; unable to detect undefined names
   |
11 | from .gdrive_utils import *
12 | from ..utils.output import *
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F403
   |

src/driada/gdrive/download.py:22:19: F405 `client` may be undefined, or defined from star imports
   |
21 |     return_code = True
22 |     folder_page = client.get(folder)
   |                   ^^^^^^ F405
23 |
24 |     if folder_page.status_code != 200:
   |

src/driada/gdrive/download.py:27:38: F405 `parse_google_drive_file` may be undefined, or defined from star imports
   |
25 |         return False, None
26 |
27 |     gdrive_file, id_name_type_iter = parse_google_drive_file(
   |                                      ^^^^^^^^^^^^^^^^^^^^^^^ F405
28 |         folder,
29 |         folder_page.text,
   |

src/driada/gdrive/download.py:33:39: F405 `MAX_NUMBER_FILES` may be undefined, or defined from star imports
   |
32 |     relevant = []
33 |     if len(list(id_name_type_iter)) > MAX_NUMBER_FILES:
   |                                       ^^^^^^^^^^^^^^^^ F405
34 |         raise MemoryError(
35 |             f'The folder {folder} has {len(list(id_name_type_iter))} elements while max allowed number of files is {MAX_NUMBER_FILES}')
   |

src/driada/gdrive/download.py:35:117: F405 `MAX_NUMBER_FILES` may be undefined, or defined from star imports
   |
33 |     if len(list(id_name_type_iter)) > MAX_NUMBER_FILES:
34 |         raise MemoryError(
35 |             f'The folder {folder} has {len(list(id_name_type_iter))} elements while max allowed number of files is {MAX_NUMBER_FILES}')
   |                                                                                                                     ^^^^^^^^^^^^^^^^ F405
36 |
37 |     for child_id, child_name, child_type in id_name_type_iter:
   |

src/driada/gdrive/download.py:38:26: F405 `folder_type` may be undefined, or defined from star imports
   |
37 |     for child_id, child_name, child_type in id_name_type_iter:
38 |         if child_type != folder_type:
   |                          ^^^^^^^^^^^ F405
39 |             if child_name in whitelist:
40 |                 relevant.append((child_id, child_name))
   |

src/driada/gdrive/download.py:49:62: F405 `folders_url` may be undefined, or defined from star imports
   |
48 |         else:
49 |             return_code, rel_sublist = retrieve_relevant_ids(folders_url + child_id,
   |                                                              ^^^^^^^^^^^ F405
50 |                                                              name_part,
51 |                                                              prohibited_name_part=prohibited_name_part,
   |

src/driada/gdrive/download.py:73:5: F405 `os` may be undefined, or defined from star imports
   |
71 |         maxfiles=None):
72 |
73 |     os.makedirs(output, exist_ok=True)
   |     ^^ F405
74 |
75 |     with Capturing() as load_log:
   |

src/driada/gdrive/download.py:75:10: F405 `Capturing` may be undefined, or defined from star imports
   |
73 |     os.makedirs(output, exist_ok=True)
74 |
75 |     with Capturing() as load_log:
   |          ^^^^^^^^^ F405
76 |         if via_pydrive:
77 |             if gauth is None:
   |

src/driada/gdrive/download.py:83:19: F405 `id_from_link` may be undefined, or defined from star imports
   |
82 |             rel = []
83 |             fid = id_from_link(folder)
   |                   ^^^^^^^^^^^^ F405
84 |             file_list = drive.ListFile({'q': f"'{fid}' in parents and trashed=false"}).GetList()
85 |             if maxfiles is not None:
   |

src/driada/gdrive/download.py:106:51: F405 `os` may be undefined, or defined from star imports
    |
104 |                 for i, pair in enumerate(rel):
105 |                     idx, name = rel[i]
106 |                     gdown.download(id=idx, output=os.path.join(output, name))
    |                                                   ^^ F405
107 |
108 |             else:
    |

src/driada/gdrive/download.py:122:10: F405 `Capturing` may be undefined, or defined from star imports
    |
120 |                          gauth=None):
121 |
122 |     with Capturing() as load_log:
    |          ^^^^^^^^^ F405
123 |         print('-------------------------------------------------------------')
124 |         print(f'Extracting data for {expname} from Google Drive')
    |

src/driada/gdrive/download.py:139:13: F405 `os` may be undefined, or defined from star imports
    |
137 |             links = dict(zip(row.columns, row.values[0]))
138 |
139 |             os.makedirs(join(tdir, expname), exist_ok=True)
    |             ^^ F405
140 |             if data_pieces is None:
141 |                 data_pieces = [d for d in list(data_router.columns.values) if d not in ['Эксперимент', 'Краткое описание', 'Video', '…
    |

src/driada/gdrive/download.py:147:21: F405 `os` may be undefined, or defined from star imports
    |
145 |                     print(f'Loading data: {key}...')
146 |                     ddir = join(tdir, expname, key)
147 |                     os.makedirs(ddir, exist_ok=True)
    |                     ^^ F405
148 |                     # gdown.download_folder(url = links[key], output = dir, quiet=False)
149 |                     return_code, rel, folder_log = download_part_of_folder(ddir,
    |

src/driada/gdrive/download.py:159:25: F405 `os` may be undefined, or defined from star imports
    |
158 |                     if len(rel) == 0:
159 |                         os.rmdir(ddir)
    |                         ^^ F405
160 |                         print('No relevant data found at: ', links[key])
    |

src/driada/gdrive/download.py:176:5: F405 `os` may be undefined, or defined from star imports
    |
174 |     router_name = 'IABS data router.xlsx'
175 |     router_path = join(root, router_name)
176 |     os.makedirs(root, exist_ok=True)
    |     ^^ F405
177 |     if router_name in os.listdir(root):
178 |         os.remove(router_path)
    |

src/driada/gdrive/download.py:177:23: F405 `os` may be undefined, or defined from star imports
    |
175 |     router_path = join(root, router_name)
176 |     os.makedirs(root, exist_ok=True)
177 |     if router_name in os.listdir(root):
    |                       ^^ F405
178 |         os.remove(router_path)
    |

src/driada/gdrive/download.py:178:9: F405 `os` may be undefined, or defined from star imports
    |
176 |     os.makedirs(root, exist_ok=True)
177 |     if router_name in os.listdir(root):
178 |         os.remove(router_path)
    |         ^^ F405
179 |
180 |     global_data_table_url = 'https://docs.google.com/spreadsheets/d/130DDFAoAbmm0jcKLBF6xsWsQLDr2Zsj4cPuOYivXoM8/export?format=xlsx'
    |

src/driada/gdrive/gdrive_utils.py:3:8: F401 [*] `os` imported but unused
  |
1 | import requests
2 | import regex
3 | import os
  |        ^^ F401
4 | from bs4 import BeautifulSoup
5 | from itertools import islice
  |
  = help: Remove unused import: `os`

src/driada/gdrive/upload.py:6:1: F403 `from .gdrive_utils import *` used; unable to detect undefined names
  |
4 | from pydrive2.drive import GoogleDrive
5 |
6 | from .gdrive_utils import *
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^ F403
7 | from .download import retrieve_relevant_ids
  |

src/driada/gdrive/upload.py:34:11: F405 `id_from_link` may be undefined, or defined from star imports
   |
32 |         link = links[destination]
33 |
34 |     fid = id_from_link(link)
   |           ^^^^^^^^^^^^ F405
35 |
36 |     dataname = os.path.basename(path_to_file)
   |

src/driada/information/entropy.py:11:8: F401 [*] `scipy.stats` imported but unused
   |
10 | import numpy as np
11 | import scipy.stats
   |        ^^^^^^^^^^^ F401
12 | from .gcmi import ent_g
   |
   = help: Remove unused import: `scipy.stats`

src/driada/information/gcmi.py:2:17: F401 [*] `numba` imported but unused
  |
1 | import numpy as np
2 | import numba as nb
  |                 ^^ F401
3 | from numba import njit
4 | import warnings
  |
  = help: Remove unused import: `numba`

src/driada/information/gcmi.py:5:39: F401 [*] `scipy.special.digamma` imported but unused
  |
3 | from numba import njit
4 | import warnings
5 | from scipy.special import ndtri, psi, digamma
  |                                       ^^^^^^^ F401
6 |
7 | from .info_utils import py_fast_digamma_arr
  |
  = help: Remove unused import: `scipy.special.digamma`

src/driada/information/gcmi.py:13:9: F401 `.gcmi_jit_utils.mi_gg_jit` imported but unused; consider using `importlib.util.find_spec` to test for availability
   |
11 |     from .gcmi_jit_utils import (
12 |         ctransform_jit, ctransform_2d_jit, copnorm_jit, copnorm_2d_jit,
13 |         mi_gg_jit, cmi_ggg_jit, gcmi_cc_jit
   |         ^^^^^^^^^ F401
14 |     )
15 |     _JIT_AVAILABLE = True
   |
   = help: Remove unused import: `.gcmi_jit_utils.mi_gg_jit`

src/driada/information/gcmi.py:232:5: E741 Ambiguous variable name: `I`
    |
231 |     # MI in bits
232 |     I = (HX + HY - HXY) / ln2
    |     ^ E741
233 |     return I
    |

src/driada/information/gcmi.py:278:5: F841 Local variable `c` is assigned to but never used
    |
276 |     Ntrl_y = np.zeros(Ym)
277 |     Hcond = np.zeros(Ym)
278 |     c = 0.5 * (np.log(2.0 * np.pi) + 1)
    |     ^ F841
279 |
280 |     for yi in range(Ym):
    |
    = help: Remove assignment to unused variable `c`

src/driada/information/gcmi.py:313:5: E741 Ambiguous variable name: `I`
    |
312 |     # MI in bits
313 |     I = (Hunc - np.sum(w * Hcond)) / ln2
    |     ^ E741
314 |     return I
    |

src/driada/information/gcmi.py:331:5: F841 Local variable `Nvarx` is assigned to but never used
    |
329 |         raise ValueError("x and y must be at most 2d")
330 |     Ntrl = x.shape[1]
331 |     Nvarx = x.shape[0]
    |     ^^^^^ F841
332 |     Nvary = y.shape[0]
    |
    = help: Remove assignment to unused variable `Nvarx`

src/driada/information/gcmi.py:332:5: F841 Local variable `Nvary` is assigned to but never used
    |
330 |     Ntrl = x.shape[1]
331 |     Nvarx = x.shape[0]
332 |     Nvary = y.shape[0]
    |     ^^^^^ F841
333 |
334 |     if y.shape[1] != Ntrl:
    |
    = help: Remove assignment to unused variable `Nvary`

src/driada/information/gcmi.py:359:5: E741 Ambiguous variable name: `I`
    |
357 |     cy = copnorm(y)
358 |     # parametric Gaussian MI
359 |     I = mi_gg(cx, cy, True, True)
    |     ^ E741
360 |     return I
    |

src/driada/information/gcmi.py:441:5: E741 Ambiguous variable name: `I`
    |
440 |     # MI in bits
441 |     I = (HXZ + HYZ - HXYZ - HZ) / ln2
    |     ^ E741
442 |     return I
    |

src/driada/information/gcmi_jit_utils.py:7:27: F401 [*] `scipy.special.ndtri` imported but unused
  |
5 | import numpy as np
6 | from numba import njit
7 | from scipy.special import ndtri
  |                           ^^^^^ F401
  |
  = help: Remove unused import: `scipy.special.ndtri`

src/driada/information/gcmi_jit_utils.py:258:5: E741 Ambiguous variable name: `I`
    |
257 |     # MI in bits
258 |     I = (HX + HY - HXY) / ln2
    |     ^ E741
259 |     return I
    |

src/driada/information/gcmi_jit_utils.py:385:5: E741 Ambiguous variable name: `I`
    |
384 |     # CMI in bits: I(X;Y|Z) = H(X,Z) + H(Y,Z) - H(X,Y,Z) - H(Z)
385 |     I = (HXZ + HYZ - HXYZ - HZ) / ln2
    |     ^ E741
386 |     return I
    |

src/driada/information/info_base.py:5:1: F403 `from .ksg import *` used; unable to detect undefined names
  |
3 | import scipy
4 |
5 | from .ksg import *
  | ^^^^^^^^^^^^^^^^^^ F403
6 | from .gcmi import *
7 | from .info_utils import binary_mi_score
  |

src/driada/information/info_base.py:6:1: F403 `from .gcmi import *` used; unable to detect undefined names
  |
5 | from .ksg import *
6 | from .gcmi import *
  | ^^^^^^^^^^^^^^^^^^^ F403
7 | from .info_utils import binary_mi_score
8 | from ..utils.data import correlation_matrix
  |

src/driada/information/info_base.py:15:30: F401 [*] `typing.Literal` imported but unused
   |
13 | import numpy as np
14 | import warnings
15 | from typing import Optional, Literal
   |                              ^^^^^^^ F401
16 | from sklearn.preprocessing import MinMaxScaler
17 | from scipy.stats import entropy, differential_entropy
   |
   = help: Remove unused import: `typing.Literal`

src/driada/information/info_base.py:17:34: F401 [*] `scipy.stats.differential_entropy` imported but unused
   |
15 | from typing import Optional, Literal
16 | from sklearn.preprocessing import MinMaxScaler
17 | from scipy.stats import entropy, differential_entropy
   |                                  ^^^^^^^^^^^^^^^^^^^^ F401
18 |
19 | from ..utils.data import to_numpy_array
   |
   = help: Remove unused import: `scipy.stats.differential_entropy`

src/driada/information/info_base.py:40:9: E722 Do not use bare `except`
   |
38 |         try:
39 |             return is_discrete_time_series(ts)
40 |         except:
   |         ^^^^^^ E722
41 |             # Fallback to legacy logic if new system fails
42 |             if len(ts) < 100:
   |

src/driada/information/info_base.py:203:39: F405 `copnorm` may be undefined, or defined from star imports
    |
202 |         else:
203 |             self.copula_normal_data = copnorm(self.data).ravel()
    |                                       ^^^^^^^ F405
204 |
205 |         self.entropy = dict()  # supports various downsampling constants
    |

src/driada/information/info_base.py:224:16: F405 `build_tree` may be undefined, or defined from star imports
    |
222 |     def _compute_kdtree(self):
223 |         d = self.data.reshape(self.data.shape[0], -1)
224 |         return build_tree(d)
    |                ^^^^^^^^^^ F405
225 |
226 |     def get_kdtree_query(self, k=DEFAULT_NN):
    |

src/driada/information/info_base.py:252:32: F405 `nonparam_entropy_c` may be undefined, or defined from star imports
    |
251 |         else:
252 |             self.entropy[ds] = nonparam_entropy_c(self.data) / np.log(2)
    |                                ^^^^^^^^^^^^^^^^^^ F405
253 |             #self.entropy[ds] = get_tdmi(self.scdata[::ds], min_shift=1, max_shift=2)[0]
254 |             #raise AttributeError('Entropy for continuous variables is not yet implemented'
    |

src/driada/information/info_base.py:412:34: F541 [*] f-string without any placeholders
    |
411 |             if valid_positions == 0:
412 |                 raise ValueError(f'Combined shuffle_mask has NO valid positions for shuffling! '
    |                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
413 |                                 f'This typically happens when combining many neurons with restrictive individual masks. '
414 |                                 f'Consider providing an explicit shuffle_mask parameter to MultiTimeSeries.')
    |
    = help: Remove extraneous `f` prefix

src/driada/information/info_base.py:413:33: F541 [*] f-string without any placeholders
    |
411 |             if valid_positions == 0:
412 |                 raise ValueError(f'Combined shuffle_mask has NO valid positions for shuffling! '
413 |                                 f'This typically happens when combining many neurons with restrictive individual masks. '
    |                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
414 |                                 f'Consider providing an explicit shuffle_mask parameter to MultiTimeSeries.')
415 |             elif valid_positions < 0.1 * total_positions:
    |
    = help: Remove extraneous `f` prefix

src/driada/information/info_base.py:414:33: F541 [*] f-string without any placeholders
    |
412 |                 raise ValueError(f'Combined shuffle_mask has NO valid positions for shuffling! '
413 |                                 f'This typically happens when combining many neurons with restrictive individual masks. '
414 |                                 f'Consider providing an explicit shuffle_mask parameter to MultiTimeSeries.')
    |                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
415 |             elif valid_positions < 0.1 * total_positions:
416 |                 warnings.warn(f'Combined shuffle_mask is extremely restrictive: only {valid_positions}/{total_positions} '
    |
    = help: Remove extraneous `f` prefix

src/driada/information/info_base.py:465:32: F405 `ent_g` may be undefined, or defined from star imports
    |
463 |         else:
464 |             # All continuous - use existing continuous entropy
465 |             self.entropy[ds] = ent_g(self.data[:, ::ds])
    |                                ^^^^^ F405
466 |     
467 |     def filter(self, method='gaussian', **kwargs):
    |

src/driada/information/info_base.py:647:18: F405 `mi_model_gd` may be undefined, or defined from star imports
    |
645 |             if not ny1.flags['C_CONTIGUOUS']:
646 |                 ny1 = np.ascontiguousarray(ny1)
647 |             mi = mi_model_gd(ny1, ny2, np.max(ny2), biascorrect=True, demeaned=True)
    |                  ^^^^^^^^^^^ F405
648 |
649 |         else:
    |

src/driada/information/info_base.py:652:18: F405 `mi_gg` may be undefined, or defined from star imports
    |
650 |             ny1 = mts.copula_normal_data[:, ::ds]
651 |             ny2 = np.roll(ts.copula_normal_data[::ds], shift)
652 |             mi = mi_gg(ny1, ny2, True, True)
    |                  ^^^^^ F405
653 |
654 |         return mi
    |

src/driada/information/info_base.py:673:18: F405 `mi_gg` may be undefined, or defined from star imports
    |
671 |             ny1 = mts1.copula_normal_data[:, ::ds]
672 |             ny2 = np.roll(mts2.copula_normal_data[:, ::ds], shift, axis=1)
673 |             mi = mi_gg(ny1, ny2, True, True)
    |                  ^^^^^ F405
674 |
675 |         return mi
    |

src/driada/information/info_base.py:750:18: F405 `nonparam_mi_cc` may be undefined, or defined from star imports
    |
749 |         if not ts1.discrete and not ts2.discrete:
750 |             mi = nonparam_mi_cc(ts1.data[::ds], y[::ds], k=k,
    |                  ^^^^^^^^^^^^^^ F405
751 |                                     precomputed_tree_x=ts1.get_kdtree(),
752 |                                     precomputed_tree_y=ts2.get_kdtree())
    |

src/driada/information/info_base.py:779:18: F405 `mi_gg` may be undefined, or defined from star imports
    |
777 |             ny1 = ts1.copula_normal_data[::ds]
778 |             ny2 = np.roll(ts2.copula_normal_data[::ds], shift)
779 |             mi = mi_gg(ny1, ny2, True, True)
    |                  ^^^^^ F405
780 |
781 |         elif ts1.discrete and ts2.discrete:
    |

src/driada/information/info_base.py:808:18: F405 `mi_model_gd` may be undefined, or defined from star imports
    |
806 |             if not ny2.flags['C_CONTIGUOUS']:
807 |                 ny2 = np.ascontiguousarray(ny2)
808 |             mi = mi_model_gd(ny2, ny1, np.max(ny1), biascorrect=True, demeaned=True)
    |                  ^^^^^^^^^^^ F405
809 |
810 |         elif not ts1.discrete and ts2.discrete:
    |

src/driada/information/info_base.py:826:18: F405 `mi_model_gd` may be undefined, or defined from star imports
    |
824 |             if not ny1.flags['C_CONTIGUOUS']:
825 |                 ny1 = np.ascontiguousarray(ny1)
826 |             mi = mi_model_gd(ny1, ny2, np.max(ny2), biascorrect=True, demeaned=True)
    |                  ^^^^^^^^^^^ F405
827 |
828 |         if mi < 0:
    |

src/driada/information/info_base.py:848:14: F405 `mi_gg` may be undefined, or defined from star imports
    |
846 |         ny1 = np.vstack(nylist)
847 |         ny2 = np.roll(ts2.copula_normal_data, shift)[::ds]
848 |         mi = mi_gg(ny1, ny2, True, True)
    |              ^^^^^ F405
849 |     else:
850 |         raise ValueError('Multidimensional MI only implemented for continuous data!')
    |

src/driada/information/info_base.py:949:15: F405 `cmi_ggg` may be undefined, or defined from star imports
    |
947 |         g2 = ts2.copula_normal_data[::ds]
948 |         g3 = ts3.copula_normal_data[::ds]
949 |         cmi = cmi_ggg(g1, g2, g3, biascorrect=True, demeaned=True)
    |               ^^^^^^^ F405
950 |
951 |     elif not ts2.discrete and ts3.discrete:
    |

src/driada/information/info_base.py:954:15: F405 `gccmi_ccd` may be undefined, or defined from star imports
    |
952 |         # CCD: X,Y continuous, Z discrete
953 |         unique_discrete_vals = np.unique(ts3.int_data[::ds])
954 |         cmi = gccmi_ccd(ts1.data[::ds],
    |               ^^^^^^^^^ F405
955 |                         ts2.data[::ds],
956 |                         ts3.int_data[::ds],
    |

src/driada/information/info_base.py:970:16: F405 `ent_g` may be undefined, or defined from star imports
    |
968 |         # Joint data for H(X,Z) and marginal H(Z)
969 |         xz_joint = np.vstack([x_data, z_data])
970 |         H_xz = ent_g(xz_joint, biascorrect=True)
    |                ^^^^^ F405
971 |         H_z = ent_g(z_data, biascorrect=True)
972 |         H_x_given_z = H_xz - H_z
    |

src/driada/information/info_base.py:971:15: F405 `ent_g` may be undefined, or defined from star imports
    |
969 |         xz_joint = np.vstack([x_data, z_data])
970 |         H_xz = ent_g(xz_joint, biascorrect=True)
971 |         H_z = ent_g(z_data, biascorrect=True)
    |               ^^^^^ F405
972 |         H_x_given_z = H_xz - H_z
    |

src/driada/information/info_base.py:990:32: F405 `ent_g` may be undefined, or defined from star imports
    |
988 |                 # Joint entropy H(X,Z|Y=y_val)
989 |                 xz_subset = np.vstack([x_subset, z_subset])
990 |                 H_xz_given_y = ent_g(xz_subset, biascorrect=True)
    |                                ^^^^^ F405
991 |                 
992 |                 # Marginal entropy H(Z|Y=y_val)
    |

src/driada/information/info_base.py:993:31: F405 `ent_g` may be undefined, or defined from star imports
    |
992 |                 # Marginal entropy H(Z|Y=y_val)
993 |                 H_z_given_y = ent_g(z_subset, biascorrect=True)
    |                               ^^^^^ F405
994 |                 
995 |                 # Conditional entropy H(X|Z,Y=y_val) = H(X,Z|Y=y_val) - H(Z|Y=y_val)
    |

src/driada/information/time_series_types.py:301:9: E722 Do not use bare `except`
    |
299 |             if kappa > 0.5:  # Significant concentration parameter
300 |                 result['confidence'] += 0.2
301 |         except:
    |         ^^^^^^ E722
302 |             pass
    |

src/driada/integration/selectivity_mapper.py:9:42: F401 [*] `typing.Tuple` imported but unused
   |
 8 | import logging
 9 | from typing import Dict, List, Optional, Tuple, Union, Any
   |                                          ^^^^^ F401
10 | import numpy as np
11 | from scipy import stats
   |
   = help: Remove unused import: `typing.Tuple`

src/driada/integration/selectivity_mapper.py:11:19: F401 [*] `scipy.stats` imported but unused
   |
 9 | from typing import Dict, List, Optional, Tuple, Union, Any
10 | import numpy as np
11 | from scipy import stats
   |                   ^^^^^ F401
12 | from sklearn.decomposition import PCA
   |
   = help: Remove unused import: `scipy.stats`

src/driada/integration/selectivity_mapper.py:12:35: F401 [*] `sklearn.decomposition.PCA` imported but unused
   |
10 | import numpy as np
11 | from scipy import stats
12 | from sklearn.decomposition import PCA
   |                                   ^^^ F401
13 |
14 | from ..experiment import Experiment
   |
   = help: Remove unused import: `sklearn.decomposition.PCA`

src/driada/intense/disentanglement.py:91:15: F541 [*] f-string without any placeholders
   |
90 |         print()
91 |         print(f'Analysis (X=behavior1, Y=behavior2):')
   |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
92 |         print(f'  Redundancy detected: {I_av < 0}')
93 |         print(f'  MI(A,X) < |II|: {mi12 < np.abs(I_av)}')
   |
   = help: Remove extraneous `f` prefix

src/driada/intense/intense_base.py:5:8: F401 [*] `scipy.stats` imported but unused
  |
3 | from joblib import Parallel, delayed
4 | import multiprocessing
5 | import scipy.stats
  |        ^^^^^^^^^^^ F401
6 |
7 | from .stats import *
  |
  = help: Remove unused import: `scipy.stats`

src/driada/intense/intense_base.py:7:1: F403 `from .stats import *` used; unable to detect undefined names
  |
5 | import scipy.stats
6 |
7 | from .stats import *
  | ^^^^^^^^^^^^^^^^^^^^ F403
8 | from ..information.info_base import TimeSeries, MultiTimeSeries, get_1d_mi, get_multi_mi, get_mi, get_sim
9 | from ..utils.data import write_dict_to_hdf5, nested_dict_to_seq_of_tables
  |

src/driada/intense/intense_base.py:8:66: F401 [*] `..information.info_base.get_1d_mi` imported but unused
  |
7 | from .stats import *
8 | from ..information.info_base import TimeSeries, MultiTimeSeries, get_1d_mi, get_multi_mi, get_mi, get_sim
  |                                                                  ^^^^^^^^^ F401
9 | from ..utils.data import write_dict_to_hdf5, nested_dict_to_seq_of_tables
  |
  = help: Remove unused import

src/driada/intense/intense_base.py:8:91: F401 [*] `..information.info_base.get_mi` imported but unused
  |
7 | from .stats import *
8 | from ..information.info_base import TimeSeries, MultiTimeSeries, get_1d_mi, get_multi_mi, get_mi, get_sim
  |                                                                                           ^^^^^^ F401
9 | from ..utils.data import write_dict_to_hdf5, nested_dict_to_seq_of_tables
  |
  = help: Remove unused import

src/driada/intense/intense_base.py:12:8: F401 [*] `os` imported but unused
   |
11 | # Configure joblib backend to avoid PyTorch forking issues
12 | import os
   |        ^^ F401
13 | try:
14 |     import torch
   |
   = help: Remove unused import: `os`

src/driada/intense/intense_base.py:14:12: F401 `torch` imported but unused; consider using `importlib.util.find_spec` to test for availability
   |
12 | import os
13 | try:
14 |     import torch
   |            ^^^^^ F401
15 |     # If PyTorch is available, use threading backend to avoid forking issues
16 |     # This prevents "function '_has_torch_function' already has a docstring" errors
   |
   = help: Remove unused import: `torch`

src/driada/intense/intense_base.py:1193:25: F405 `get_table_of_stats` may be undefined, or defined from star imports
     |
1192 |         # turn computed data tables from stage 1 and precomputed data into dict of stats dicts
1193 |         stage_1_stats = get_table_of_stats(me_total1,
     |                         ^^^^^^^^^^^^^^^^^^ F405
1194 |                                            optimal_delays,
1195 |                                            metric_distr_type=metric_distr_type,
     |

src/driada/intense/intense_base.py:1212:32: F405 `populate_nested_dict` may be undefined, or defined from star imports
     |
1210 |             print('Computing significance for all pairs in stage 1...')
1211 |
1212 |         stage_1_significance = populate_nested_dict(dict(), range(n1), range(n2))
     |                                ^^^^^^^^^^^^^^^^^^^^ F405
1213 |         for i in range(n1):
1214 |             for j in range(n2):
     |

src/driada/intense/intense_base.py:1215:38: F405 `criterion1` may be undefined, or defined from star imports
     |
1213 |         for i in range(n1):
1214 |             for j in range(n2):
1215 |                 pair_passes_stage1 = criterion1(stage_1_stats[i][j],
     |                                      ^^^^^^^^^^ F405
1216 |                                                 n_shuffles_stage1,
1217 |                                                 topk=topk1)
     |

src/driada/intense/intense_base.py:1244:23: F405 `add_names_to_nested_dict` may be undefined, or defined from star imports
     |
1243 |     if mode == 'stage1' or nhyp == 0:
1244 |         final_stats = add_names_to_nested_dict(stage_1_stats, names1, names2)
     |                       ^^^^^^^^^^^^^^^^^^^^^^^^ F405
1245 |         final_significance = add_names_to_nested_dict(stage_1_significance, names1, names2)
     |

src/driada/intense/intense_base.py:1245:30: F405 `add_names_to_nested_dict` may be undefined, or defined from star imports
     |
1243 |     if mode == 'stage1' or nhyp == 0:
1244 |         final_stats = add_names_to_nested_dict(stage_1_stats, names1, names2)
1245 |         final_significance = add_names_to_nested_dict(stage_1_significance, names1, names2)
     |                              ^^^^^^^^^^^^^^^^^^^^^^^^ F405
1246 |
1247 |         return final_stats, final_significance, accumulated_info
     |

src/driada/intense/intense_base.py:1251:25: F405 `populate_nested_dict` may be undefined, or defined from star imports
     |
1249 |     elif mode == 'stage2':
1250 |         # For stage2-only mode, create empty stage 1 structures
1251 |         stage_1_stats = populate_nested_dict(dict(), range(n1), range(n2))
     |                         ^^^^^^^^^^^^^^^^^^^^ F405
1252 |         stage_1_significance = populate_nested_dict(dict(), range(n1), range(n2))
1253 |         # Set all pairs as passing stage 1 with placeholder values
     |

src/driada/intense/intense_base.py:1252:32: F405 `populate_nested_dict` may be undefined, or defined from star imports
     |
1250 |         # For stage2-only mode, create empty stage 1 structures
1251 |         stage_1_stats = populate_nested_dict(dict(), range(n1), range(n2))
1252 |         stage_1_significance = populate_nested_dict(dict(), range(n1), range(n2))
     |                                ^^^^^^^^^^^^^^^^^^^^ F405
1253 |         # Set all pairs as passing stage 1 with placeholder values
1254 |         for i in range(n1):
     |

src/driada/intense/intense_base.py:1285:25: F405 `get_table_of_stats` may be undefined, or defined from star imports
     |
1284 |         # turn data tables from stage 2 to array of stats dicts
1285 |         stage_2_stats = get_table_of_stats(me_total2,
     |                         ^^^^^^^^^^^^^^^^^^ F405
1286 |                                            optimal_delays,
1287 |                                            metric_distr_type=metric_distr_type,
     |

src/driada/intense/intense_base.py:1302:25: F405 `get_all_nonempty_pvals` may be undefined, or defined from star imports
     |
1300 |         all_pvals = None
1301 |         if multicomp_correction in ['holm', 'fdr_bh']:  # these procedures require all p-values
1302 |             all_pvals = get_all_nonempty_pvals(stage_2_stats, range(n1), range(n2))
     |                         ^^^^^^^^^^^^^^^^^^^^^^ F405
1303 |
1304 |         multicorr_thr = get_multicomp_correction_thr(pval_thr,
     |

src/driada/intense/intense_base.py:1309:32: F405 `populate_nested_dict` may be undefined, or defined from star imports
     |
1307 |                                                      nhyp=nhyp)
1308 |
1309 |         stage_2_significance = populate_nested_dict(dict(), range(n1), range(n2))
     |                                ^^^^^^^^^^^^^^^^^^^^ F405
1310 |         for i in range(n1):
1311 |             for j in range(n2):
     |

src/driada/intense/intense_base.py:1312:38: F405 `criterion2` may be undefined, or defined from star imports
     |
1310 |         for i in range(n1):
1311 |             for j in range(n2):
1312 |                 pair_passes_stage2 = criterion2(stage_2_stats[i][j],
     |                                      ^^^^^^^^^^ F405
1313 |                                                 n_shuffles_stage2,
1314 |                                                 multicorr_thr,
     |

src/driada/intense/intense_base.py:1344:24: F405 `merge_stage_stats` may be undefined, or defined from star imports
     |
1343 |         # Always merge stats for consistency
1344 |         merged_stats = merge_stage_stats(stage_1_stats, stage_2_stats)
     |                        ^^^^^^^^^^^^^^^^^ F405
1345 |         merged_significance = merge_stage_significance(stage_1_significance, stage_2_significance)
1346 |         final_stats = add_names_to_nested_dict(merged_stats, names1, names2)
     |

src/driada/intense/intense_base.py:1345:31: F405 `merge_stage_significance` may be undefined, or defined from star imports
     |
1343 |         # Always merge stats for consistency
1344 |         merged_stats = merge_stage_stats(stage_1_stats, stage_2_stats)
1345 |         merged_significance = merge_stage_significance(stage_1_significance, stage_2_significance)
     |                               ^^^^^^^^^^^^^^^^^^^^^^^^ F405
1346 |         final_stats = add_names_to_nested_dict(merged_stats, names1, names2)
1347 |         final_significance = add_names_to_nested_dict(merged_significance, names1, names2)
     |

src/driada/intense/intense_base.py:1346:23: F405 `add_names_to_nested_dict` may be undefined, or defined from star imports
     |
1344 |         merged_stats = merge_stage_stats(stage_1_stats, stage_2_stats)
1345 |         merged_significance = merge_stage_significance(stage_1_significance, stage_2_significance)
1346 |         final_stats = add_names_to_nested_dict(merged_stats, names1, names2)
     |                       ^^^^^^^^^^^^^^^^^^^^^^^^ F405
1347 |         final_significance = add_names_to_nested_dict(merged_significance, names1, names2)
1348 |         return final_stats, final_significance, accumulated_info
     |

src/driada/intense/intense_base.py:1347:30: F405 `add_names_to_nested_dict` may be undefined, or defined from star imports
     |
1345 |         merged_significance = merge_stage_significance(stage_1_significance, stage_2_significance)
1346 |         final_stats = add_names_to_nested_dict(merged_stats, names1, names2)
1347 |         final_significance = add_names_to_nested_dict(merged_significance, names1, names2)
     |                              ^^^^^^^^^^^^^^^^^^^^^^^^ F405
1348 |         return final_stats, final_significance, accumulated_info
     |

src/driada/intense/pipelines.py:1:1: F403 `from .stats import *` used; unable to detect undefined names
  |
1 | from .stats import *
  | ^^^^^^^^^^^^^^^^^^^^ F403
2 | from .intense_base import compute_me_stats, IntenseResults
3 | from ..information.info_base import TimeSeries, MultiTimeSeries
  |

src/driada/intense/pipelines.py:227:8: F841 Local variable `t` is assigned to but never used
    |
225 |                 raise ValueError('Unknown feature id type')
226 |
227 |     n, t, f = len(cells), exp.n_frames, len(feats)
    |        ^ F841
228 |
229 |     precomputed_mask_stage1 = np.ones((n,f))
    |
    = help: Remove assignment to unused variable `t`

src/driada/intense/pipelines.py:229:31: F405 `np` may be undefined, or defined from star imports
    |
227 |     n, t, f = len(cells), exp.n_frames, len(feats)
228 |
229 |     precomputed_mask_stage1 = np.ones((n,f))
    |                               ^^ F405
230 |     precomputed_mask_stage2 = np.ones((n,f))
    |

src/driada/intense/pipelines.py:230:31: F405 `np` may be undefined, or defined from star imports
    |
229 |     precomputed_mask_stage1 = np.ones((n,f))
230 |     precomputed_mask_stage2 = np.ones((n,f))
    |                               ^^ F405
231 |
232 |     if not exp.selectivity_tables_initialized:
    |

src/driada/intense/pipelines.py:250:38: F405 `DEFAULT_STATS` may be undefined, or defined from star imports
    |
248 |                         exp._add_multifeature_to_data_hashes(feat_id, mode=data_type)
249 |                         exp._add_multifeature_to_stats(feat_id, mode=data_type)
250 |                         pair_stats = DEFAULT_STATS.copy()
    |                                      ^^^^^^^^^^^^^ F405
251 |
252 |                 current_data_hash = exp._data_hashes[data_type][feat_id][cell_id]
    |

src/driada/intense/pipelines.py:254:20: F405 `stats_not_empty` may be undefined, or defined from star imports
    |
252 |                 current_data_hash = exp._data_hashes[data_type][feat_id][cell_id]
253 |
254 |                 if stats_not_empty(pair_stats, current_data_hash, stage=1):
    |                    ^^^^^^^^^^^^^^^ F405
255 |                     precomputed_mask_stage1[i,j] = 0
256 |                 if stats_not_empty(pair_stats, current_data_hash, stage=2):
    |

src/driada/intense/pipelines.py:256:20: F405 `stats_not_empty` may be undefined, or defined from star imports
    |
254 |                 if stats_not_empty(pair_stats, current_data_hash, stage=1):
255 |                     precomputed_mask_stage1[i,j] = 0
256 |                 if stats_not_empty(pair_stats, current_data_hash, stage=2):
    |                    ^^^^^^^^^^^^^^^ F405
257 |                     precomputed_mask_stage2[i,j] = 0
    |

src/driada/intense/pipelines.py:259:33: F405 `np` may be undefined, or defined from star imports
    |
257 |                     precomputed_mask_stage2[i,j] = 0
258 |
259 |     combined_precomputed_mask = np.ones((n, f))
    |                                 ^^ F405
260 |     if mode in ['stage2', 'two_stage']:
261 |         combined_precomputed_mask[np.where((precomputed_mask_stage1 == 0) & (precomputed_mask_stage2 == 0))] = 0
    |

src/driada/intense/pipelines.py:261:35: F405 `np` may be undefined, or defined from star imports
    |
259 |     combined_precomputed_mask = np.ones((n, f))
260 |     if mode in ['stage2', 'two_stage']:
261 |         combined_precomputed_mask[np.where((precomputed_mask_stage1 == 0) & (precomputed_mask_stage2 == 0))] = 0
    |                                   ^^ F405
262 |     elif mode == 'stage1':
263 |         combined_precomputed_mask[np.where(precomputed_mask_stage1 == 0)] = 0
    |

src/driada/intense/pipelines.py:263:35: F405 `np` may be undefined, or defined from star imports
    |
261 |         combined_precomputed_mask[np.where((precomputed_mask_stage1 == 0) & (precomputed_mask_stage2 == 0))] = 0
262 |     elif mode == 'stage1':
263 |         combined_precomputed_mask[np.where(precomputed_mask_stage1 == 0)] = 0
    |                                   ^^ F405
264 |     else:
265 |         raise ValueError('Wrong mode!')
    |

src/driada/intense/pipelines.py:414:19: F541 [*] f-string without any placeholders
    |
413 |         if verbose:
414 |             print(f"\nDisentanglement analysis complete!")
    |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
415 |             if summary.get('overall_stats'):
416 |                 print(f"Total mixed selectivity pairs analyzed: {summary['overall_stats']['total_neuron_pairs']}")
    |
    = help: Remove extraneous `f` prefix

src/driada/intense/pipelines.py:654:15: F541 [*] f-string without any placeholders
    |
653 |     if verbose:
654 |         print(f"\nBehavioral similarity matrix computation complete!")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
655 |         print(f"Feature pairs analyzed: {n_features * n_features}")
656 |         print(f"Significant pairs (stage 1): {info.get('n_significant_stage1', 0)}")
    |
    = help: Remove extraneous `f` prefix

src/driada/intense/pipelines.py:877:15: F541 [*] f-string without any placeholders
    |
876 |     if verbose:
877 |         print(f"\nNeuronal similarity matrix computation complete!")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
878 |         print(f"Neuron pairs analyzed: {n_cells * n_cells}")
879 |         print(f"Significant pairs (stage 1): {info.get('n_significant_stage1', 0)}")
    |
    = help: Remove extraneous `f` prefix

src/driada/intense/stats.py:3:1: F403 `from scipy.stats import *` used; unable to detect undefined names
  |
1 | import numpy as np
2 | import scipy
3 | from scipy.stats import *
  | ^^^^^^^^^^^^^^^^^^^^^^^^^ F403
4 | from ..utils.data import populate_nested_dict, add_names_to_nested_dict
5 | from ..experiment.exp_base import DEFAULT_STATS
  |

src/driada/intense/stats.py:4:48: F401 [*] `..utils.data.add_names_to_nested_dict` imported but unused
  |
2 | import scipy
3 | from scipy.stats import *
4 | from ..utils.data import populate_nested_dict, add_names_to_nested_dict
  |                                                ^^^^^^^^^^^^^^^^^^^^^^^^ F401
5 | from ..experiment.exp_base import DEFAULT_STATS
  |
  = help: Remove unused import: `..utils.data.add_names_to_nested_dict`

src/driada/intense/stats.py:5:35: F401 [*] `..experiment.exp_base.DEFAULT_STATS` imported but unused
  |
3 | from scipy.stats import *
4 | from ..utils.data import populate_nested_dict, add_names_to_nested_dict
5 | from ..experiment.exp_base import DEFAULT_STATS
  |                                   ^^^^^^^^^^^^^ F401
  |
  = help: Remove unused import: `..experiment.exp_base.DEFAULT_STATS`

src/driada/intense/stats.py:44:14: F405 `lognorm` may be undefined, or defined from star imports
   |
42 |         P(X >= val) under fitted log-normal distribution.
43 |     """
44 |     params = lognorm.fit(data, floc=0)
   |              ^^^^^^^ F405
45 |     rv = lognorm(*params)
46 |     return rv.sf(val)
   |

src/driada/intense/stats.py:45:10: F405 `lognorm` may be undefined, or defined from star imports
   |
43 |     """
44 |     params = lognorm.fit(data, floc=0)
45 |     rv = lognorm(*params)
   |          ^^^^^^^ F405
46 |     return rv.sf(val)
   |

src/driada/intense/stats.py:65:14: F405 `gamma` may be undefined, or defined from star imports
   |
63 |         P(X >= val) under fitted gamma distribution.
64 |     """
65 |     params = gamma.fit(data, floc=0)
   |              ^^^^^ F405
66 |     rv = gamma(*params)
67 |     return rv.sf(val)
   |

src/driada/intense/stats.py:66:10: F405 `gamma` may be undefined, or defined from star imports
   |
64 |     """
65 |     params = gamma.fit(data, floc=0)
66 |     rv = gamma(*params)
   |          ^^^^^ F405
67 |     return rv.sf(val)
   |

src/driada/intense/stats.py:320:23: F405 `rankdata` may be undefined, or defined from star imports
    |
318 |     stage_stats = populate_nested_dict(dict(), range(a), range(b))
319 |
320 |     ranked_total_mi = rankdata(metable, axis=2, nan_policy='omit')
    |                       ^^^^^^^^ F405
321 |     ranks = (ranked_total_mi[:, :, 0] / (nsh + 1))  # how many shuffles have MI lower than true mi
    |

src/driada/network/drawing.py:1:1: F403 `from ..utils.plot import *` used; unable to detect undefined names
  |
1 | from ..utils.plot import *
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^ F403
2 | from .matrix_utils import *
3 | import numpy as np
  |

src/driada/network/drawing.py:2:1: F403 `from .matrix_utils import *` used; unable to detect undefined names
  |
1 | from ..utils.plot import *
2 | from .matrix_utils import *
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^ F403
3 | import numpy as np
4 | import networkx as nx
  |

src/driada/network/drawing.py:16:15: F405 `create_default_figure` may be undefined, or defined from star imports
   |
14 |         mode = 'all'
15 |
16 |     fig, ax = create_default_figure(10, 8)
   |               ^^^^^^^^^^^^^^^^^^^^^ F405
17 |     ax.set_title('Degree distribution', color='white')
   |

src/driada/network/drawing.py:61:19: F405 `create_default_figure` may be undefined, or defined from star imports
   |
60 |     if ax is None:
61 |         fig, ax = create_default_figure(12,10)
   |                   ^^^^^^^^^^^^^^^^^^^^^ F405
62 |
63 |     if net.directed:
   |

src/driada/network/drawing.py:72:12: F405 `plt` may be undefined, or defined from star imports
   |
71 | def get_vector_coloring(vec, cmap='plasma'):
72 |     cmap = plt.get_cmap(cmap)
   |            ^^^ F405
73 |     vec = np.array(vec).ravel()
74 |     colors = cmap((vec-min(vec))/(max(vec)-min(vec)))
   |

src/driada/network/drawing.py:90:16: F405 `plt` may be undefined, or defined from star imports
   |
88 |     pics_in_a_row = int(np.ceil(np.sqrt(npics)))
89 |     pics_in_a_col = int(np.ceil(1.0 * npics / pics_in_a_row))
90 |     fig, axs = plt.subplots(nrows=pics_in_a_col, ncols=pics_in_a_row, figsize=(8 * pics_in_a_row, 8 * pics_in_a_col))
   |                ^^^ F405
91 |     for ax in axs.ravel():
92 |         ax.set_axis_off()
   |

src/driada/network/drawing.py:93:5: F405 `plt` may be undefined, or defined from star imports
   |
91 |     for ax in axs.ravel():
92 |         ax.set_axis_off()
93 |     plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9,
   |     ^^^ F405
94 |                         hspace=0.2, wspace=0.1)
   |

src/driada/network/drawing.py:119:9: F841 Local variable `nodes` is assigned to but never used
    |
117 |         }
118 |
119 |         nodes = nx.draw_networkx_nodes(net.graph, pos, ax=ax, **options)
    |         ^^^^^ F841
120 |
121 |         if draw_edges:
    |
    = help: Remove assignment to unused variable `nodes`

src/driada/network/drawing.py:122:13: F841 Local variable `edges` is assigned to but never used
    |
121 |         if draw_edges:
122 |             edges = nx.draw_networkx_edges(net.graph, pos, **edge_options)
    |             ^^^^^ F841
123 |         # pc, = mpl.collections.PatchCollection(nodes, cmap = options['cmap'])
124 |         # pc.set_array(edge_colors)
    |
    = help: Remove assignment to unused variable `edges`

src/driada/network/drawing.py:130:5: F405 `plt` may be undefined, or defined from star imports
    |
128 |         ax.set_axis_off()
129 |
130 |     plt.tight_layout()
    |     ^^^ F405
131 |     plt.show()
    |

src/driada/network/drawing.py:131:5: F405 `plt` may be undefined, or defined from star imports
    |
130 |     plt.tight_layout()
131 |     plt.show()
    |     ^^^ F405
    |

src/driada/network/drawing.py:136:19: F405 `plt` may be undefined, or defined from star imports
    |
134 | def draw_net(net, colors=None, nodesize=None, ax=None):
135 |     if ax is None:
136 |         fig, ax = plt.subplots(figsize=(16, 12))
    |                   ^^^ F405
137 |
138 |     if net.pos is None:
    |

src/driada/network/drawing.py:154:5: F841 Local variable `nodes` is assigned to but never used
    |
152 |     edge_options = {}
153 |
154 |     nodes = nx.draw_networkx_nodes(net.graph, pos, node_color=colors, ax=ax, **node_options)
    |     ^^^^^ F841
155 |     edges = nx.draw_networkx_edges(net.graph, pos, ax=ax, **edge_options)
    |
    = help: Remove assignment to unused variable `nodes`

src/driada/network/drawing.py:155:5: F841 Local variable `edges` is assigned to but never used
    |
154 |     nodes = nx.draw_networkx_nodes(net.graph, pos, node_color=colors, ax=ax, **node_options)
155 |     edges = nx.draw_networkx_edges(net.graph, pos, ax=ax, **edge_options)
    |     ^^^^^ F841
156 |
157 |     plt.show()
    |
    = help: Remove assignment to unused variable `edges`

src/driada/network/drawing.py:157:5: F405 `plt` may be undefined, or defined from star imports
    |
155 |     edges = nx.draw_networkx_edges(net.graph, pos, ax=ax, **edge_options)
156 |
157 |     plt.show()
    |     ^^^ F405
    |

src/driada/network/drawing.py:164:19: F405 `get_laplacian` may be undefined, or defined from star imports
    |
162 |     if mat is None:
163 |         if mode in ['lap', 'lap_out']:
164 |             mat = get_laplacian(net.adj)
    |                   ^^^^^^^^^^^^^ F405
165 |         elif mode == 'nlap':
166 |             mat = get_norm_laplacian(net.adj)
    |

src/driada/network/drawing.py:166:19: F405 `get_norm_laplacian` may be undefined, or defined from star imports
    |
164 |             mat = get_laplacian(net.adj)
165 |         elif mode == 'nlap':
166 |             mat = get_norm_laplacian(net.adj)
    |                   ^^^^^^^^^^^^^^^^^^ F405
167 |
168 |     if ax is None:
    |

src/driada/network/drawing.py:169:19: F405 `plt` may be undefined, or defined from star imports
    |
168 |     if ax is None:
169 |         fig, ax = plt.subplots(figsize=(10, 10))
    |                   ^^^ F405
170 |
171 |     if not dtype is None:
    |

src/driada/network/drawing.py:171:12: E714 [*] Test for object identity should be `is not`
    |
169 |         fig, ax = plt.subplots(figsize=(10, 10))
170 |
171 |     if not dtype is None:
    |            ^^^^^^^^^^^^^ E714
172 |         ax.matshow(mat.astype(dtype).toarray())
173 |     else:
    |
    = help: Convert to `is not`

src/driada/network/drawing.py:193:11: F405 `plt` may be undefined, or defined from star imports
    |
191 |     pics_in_a_col = np.ceil(1.0 * npics / pics_in_a_row)
192 |
193 |     fig = plt.figure(figsize=(20, 20))
    |           ^^^ F405
194 |     fig.suptitle('Projections')
195 |     for i in range(len(pairs)):
    |

src/driada/network/drawing.py:200:9: F841 Local variable `legend` is assigned to but never used
    |
198 |         scatter = ax.scatter(data[i1, :], data[i2, :], c=colors, s=psize)
199 |
200 |         legend = ax.legend(*scatter.legend_elements(),
    |         ^^^^^^ F841
201 |                            loc="upper left", title="Classes")
    |
    = help: Remove assignment to unused variable `legend`

src/driada/network/graph_utils.py:5:1: F403 `from .randomization import *` used; unable to detect undefined names
  |
3 | from copy import deepcopy
4 |
5 | from .randomization import *
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F403
6 |
7 | def get_giant_cc_from_graph(G):
  |

src/driada/network/matrix_utils.py:145:29: E741 Ambiguous variable name: `l`
    |
143 |     rows, cols = A.nonzero()
144 |     edgeset = set(zip(rows, cols))
145 |     upper = np.array([l for l in edgeset if l[0] < l[1]])
    |                             ^ E741
146 |     dircount = 0
    |

src/driada/network/matrix_utils.py:146:5: F841 Local variable `dircount` is assigned to but never used
    |
144 |     edgeset = set(zip(rows, cols))
145 |     upper = np.array([l for l in edgeset if l[0] < l[1]])
146 |     dircount = 0
    |     ^^^^^^^^ F841
147 |
148 |     random_tosses = np.random.random(len(upper))
    |
    = help: Remove assignment to unused variable `dircount`

src/driada/network/matrix_utils.py:151:47: E712 Avoid equality comparisons to `True`; use `condition1:` for truth checks
    |
149 |     condition1 = (random_tosses >= directed / 2.0) & (random_tosses < directed)
150 |     condition2 = (random_tosses <= directed / 2.0) & (random_tosses < directed)
151 |     indices_where_upper_is_removed = np.where(condition1 == True)[0]
    |                                               ^^^^^^^^^^^^^^^^^^ E712
152 |     indices_where_lower_is_removed = np.where(condition2 == True)[0]
    |
    = help: Replace with `condition1`

src/driada/network/matrix_utils.py:152:47: E712 Avoid equality comparisons to `True`; use `condition2:` for truth checks
    |
150 |     condition2 = (random_tosses <= directed / 2.0) & (random_tosses < directed)
151 |     indices_where_upper_is_removed = np.where(condition1 == True)[0]
152 |     indices_where_lower_is_removed = np.where(condition2 == True)[0]
    |                                               ^^^^^^^^^^^^^^^^^^ E712
153 |
154 |     u_xdata = [u[0] for u in upper[indices_where_upper_is_removed]]
    |
    = help: Replace with `condition2`

src/driada/network/net_base.py:1:1: F403 `from .graph_utils import *` used; unable to detect undefined names
  |
1 | from .graph_utils import *
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^ F403
2 | from .randomization import *
3 | from .drawing import *
  |

src/driada/network/net_base.py:2:1: F403 `from .randomization import *` used; unable to detect undefined names
  |
1 | from .graph_utils import *
2 | from .randomization import *
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F403
3 | from .drawing import *
4 | from .spectral import *
  |

src/driada/network/net_base.py:3:1: F403 `from .drawing import *` used; unable to detect undefined names
  |
1 | from .graph_utils import *
2 | from .randomization import *
3 | from .drawing import *
  | ^^^^^^^^^^^^^^^^^^^^^^ F403
4 | from .spectral import *
5 | from .quantum import *
  |

src/driada/network/net_base.py:4:1: F403 `from .spectral import *` used; unable to detect undefined names
  |
2 | from .randomization import *
3 | from .drawing import *
4 | from .spectral import *
  | ^^^^^^^^^^^^^^^^^^^^^^^ F403
5 | from .quantum import *
  |

src/driada/network/net_base.py:5:1: F403 `from .quantum import *` used; unable to detect undefined names
  |
3 | from .drawing import *
4 | from .spectral import *
5 | from .quantum import *
  | ^^^^^^^^^^^^^^^^^^^^^^ F403
6 |
7 | from scipy import linalg as la
  |

src/driada/network/net_base.py:17:26: F405 `nx` may be undefined, or defined from star imports
   |
15 | DIR_MATRIX_TYPES = ['adj', 'lap_out', 'lap_in']
16 | MATRIX_TYPES = UNDIR_MATRIX_TYPES + DIR_MATRIX_TYPES
17 | SUPPORTED_GRAPH_TYPES = [nx.Graph, nx.DiGraph]
   |                          ^^ F405
   |

src/driada/network/net_base.py:17:36: F405 `nx` may be undefined, or defined from star imports
   |
15 | DIR_MATRIX_TYPES = ['adj', 'lap_out', 'lap_in']
16 | MATRIX_TYPES = UNDIR_MATRIX_TYPES + DIR_MATRIX_TYPES
17 | SUPPORTED_GRAPH_TYPES = [nx.Graph, nx.DiGraph]
   |                                    ^^ F405
   |

src/driada/network/net_base.py:47:23: F405 `np` may be undefined, or defined from star imports
   |
46 | def check_weights_and_directions(a, weighted, directed):
47 |     is_directed = not np.allclose(a.toarray(), a.toarray().T)
   |                       ^^ F405
48 |     is_weighted = not np.allclose(a.toarray(), a.astype(bool).astype(int).toarray())
   |

src/driada/network/net_base.py:48:23: F405 `np` may be undefined, or defined from star imports
   |
46 | def check_weights_and_directions(a, weighted, directed):
47 |     is_directed = not np.allclose(a.toarray(), a.toarray().T)
48 |     is_weighted = not np.allclose(a.toarray(), a.astype(bool).astype(int).toarray())
   |                       ^^ F405
49 |
50 |     symm_text = 'asymmetric' if is_directed else 'symmetric'
   |

src/driada/network/net_base.py:67:20: F405 `np` may be undefined, or defined from star imports
   |
65 |             raise ValueError('Either "adj" or "graph" argument must be non-empty')
66 |         else:
67 |             if not np.any([isinstance(graph, gtype) for gtype in SUPPORTED_GRAPH_TYPES]):
   |                    ^^ F405
68 |                 raise TypeError(f'graph should have one of supported graph types: {SUPPORTED_GRAPH_TYPES}')
69 |             else:
   |

src/driada/network/net_base.py:109:37: F405 `np` may be undefined, or defined from star imports
    |
107 |         if self.directed is None:
108 |             if self.init_method == 'adj':
109 |                 self.directed = not np.allclose(adj.toarray(), adj.toarray().T)
    |                                     ^^ F405
110 |             elif self.init_method == 'graph':
111 |                 self.directed = nx.is_directed(graph)
    |

src/driada/network/net_base.py:111:33: F405 `nx` may be undefined, or defined from star imports
    |
109 |                 self.directed = not np.allclose(adj.toarray(), adj.toarray().T)
110 |             elif self.init_method == 'graph':
111 |                 self.directed = nx.is_directed(graph)
    |                                 ^^ F405
112 |
113 |         self.weighted = network_args.get('weighted')
    |

src/driada/network/net_base.py:116:37: F405 `np` may be undefined, or defined from star imports
    |
114 |         if self.weighted is None:
115 |             if self.init_method == 'adj':
116 |                 self.weighted = not np.allclose(adj.toarray(), adj.toarray().astype(bool).astype(int))
    |                                     ^^ F405
117 |             elif self.init_method == 'graph':
118 |                 self.weighted = nx.is_weighted(graph)
    |

src/driada/network/net_base.py:118:33: F405 `nx` may be undefined, or defined from star imports
    |
116 |                 self.weighted = not np.allclose(adj.toarray(), adj.toarray().astype(bool).astype(int))
117 |             elif self.init_method == 'graph':
118 |                 self.weighted = nx.is_weighted(graph)
    |                                 ^^ F405
119 |
120 |         self.real_world = network_args.get('real_world')
    |

src/driada/network/net_base.py:166:22: F405 `remove_selfloops_from_graph` may be undefined, or defined from star imports
    |
164 |             if self.verbose:
165 |                 print('No preprocessing specified, this may lead to unexpected errors in graph connectivity!')
166 |             fgraph = remove_selfloops_from_graph(graph)
    |                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^ F405
167 |
168 |         elif preprocessing == 'remove_isolates':
    |

src/driada/network/net_base.py:169:22: F405 `remove_isolates_and_selfloops_from_graph` may be undefined, or defined from star imports
    |
168 |         elif preprocessing == 'remove_isolates':
169 |             fgraph = remove_isolates_and_selfloops_from_graph(graph)
    |                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F405
170 |
171 |         elif preprocessing == 'giant_cc':
    |

src/driada/network/net_base.py:172:18: F405 `remove_selfloops_from_graph` may be undefined, or defined from star imports
    |
171 |         elif preprocessing == 'giant_cc':
172 |             g_ = remove_selfloops_from_graph(graph)
    |                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^ F405
173 |             fgraph = get_giant_cc_from_graph(g_)
174 |             self.n_cc = 1
    |

src/driada/network/net_base.py:173:22: F405 `get_giant_cc_from_graph` may be undefined, or defined from star imports
    |
171 |         elif preprocessing == 'giant_cc':
172 |             g_ = remove_selfloops_from_graph(graph)
173 |             fgraph = get_giant_cc_from_graph(g_)
    |                      ^^^^^^^^^^^^^^^^^^^^^^^ F405
174 |             self.n_cc = 1
    |

src/driada/network/net_base.py:177:18: F405 `remove_selfloops_from_graph` may be undefined, or defined from star imports
    |
176 |         elif preprocessing == 'giant_scc':
177 |             g_ = remove_selfloops_from_graph(graph)
    |                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^ F405
178 |             fgraph = get_giant_scc_from_graph(g_)
179 |             self.n_cc = 1
    |

src/driada/network/net_base.py:178:22: F405 `get_giant_scc_from_graph` may be undefined, or defined from star imports
    |
176 |         elif preprocessing == 'giant_scc':
177 |             g_ = remove_selfloops_from_graph(graph)
178 |             fgraph = get_giant_scc_from_graph(g_)
    |                      ^^^^^^^^^^^^^^^^^^^^^^^^ F405
179 |             self.n_cc = 1
180 |             self.n_scc = 1
    |

src/driada/network/net_base.py:202:20: F405 `nx` may be undefined, or defined from star imports
    |
201 |         self.graph = fgraph
202 |         self.adj = nx.adjacency_matrix(fgraph)
    |                    ^^ F405
203 |         self.n = nx.number_of_nodes(self.graph)
    |

src/driada/network/net_base.py:203:18: F405 `nx` may be undefined, or defined from star imports
    |
201 |         self.graph = fgraph
202 |         self.adj = nx.adjacency_matrix(fgraph)
203 |         self.n = nx.number_of_nodes(self.graph)
    |                  ^^ F405
204 |
205 |     def _preprocess_adj_and_data(self,
    |

src/driada/network/net_base.py:214:21: F405 `nx` may be undefined, or defined from star imports
    |
212 |         # if NetworkX graph should be created, we revert to graph-based initialization for simplicity
213 |         if create_graph:
214 |             gtype = nx.DiGraph if self.directed else nx.Graph
    |                     ^^ F405
215 |             graph = nx.from_scipy_sparse_array(a, create_using=gtype)
216 |             self._preprocess_graph_and_data(graph=graph,
    |

src/driada/network/net_base.py:214:54: F405 `nx` may be undefined, or defined from star imports
    |
212 |         # if NetworkX graph should be created, we revert to graph-based initialization for simplicity
213 |         if create_graph:
214 |             gtype = nx.DiGraph if self.directed else nx.Graph
    |                                                      ^^ F405
215 |             graph = nx.from_scipy_sparse_array(a, create_using=gtype)
216 |             self._preprocess_graph_and_data(graph=graph,
    |

src/driada/network/net_base.py:215:21: F405 `nx` may be undefined, or defined from star imports
    |
213 |         if create_graph:
214 |             gtype = nx.DiGraph if self.directed else nx.Graph
215 |             graph = nx.from_scipy_sparse_array(a, create_using=gtype)
    |                     ^^ F405
216 |             self._preprocess_graph_and_data(graph=graph,
217 |                                             pos=pos,
    |

src/driada/network/net_base.py:226:20: F405 `remove_selfloops_from_adj` may be undefined, or defined from star imports
    |
224 |             if self.verbose:
225 |                 print('No preprocessing specified, this may lead to unexpected errors in graph connectivity!')
226 |             fadj = remove_selfloops_from_adj(a)
    |                    ^^^^^^^^^^^^^^^^^^^^^^^^^ F405
227 |             nodes_range = range(fadj.shape[0])
228 |             node_mapping = dict(zip(nodes_range, nodes_range))  # no nodes have been deleted
    |

src/driada/network/net_base.py:231:18: F405 `remove_selfloops_from_adj` may be undefined, or defined from star imports
    |
230 |         elif preprocessing == 'remove_isolates':
231 |             a_ = remove_selfloops_from_adj(a)
    |                  ^^^^^^^^^^^^^^^^^^^^^^^^^ F405
232 |             fadj, node_mapping = remove_isolates_from_adj(a_)
    |

src/driada/network/net_base.py:232:34: F405 `remove_isolates_from_adj` may be undefined, or defined from star imports
    |
230 |         elif preprocessing == 'remove_isolates':
231 |             a_ = remove_selfloops_from_adj(a)
232 |             fadj, node_mapping = remove_isolates_from_adj(a_)
    |                                  ^^^^^^^^^^^^^^^^^^^^^^^^ F405
233 |
234 |         elif preprocessing == 'giant_cc':
    |

src/driada/network/net_base.py:235:18: F405 `remove_selfloops_from_adj` may be undefined, or defined from star imports
    |
234 |         elif preprocessing == 'giant_cc':
235 |             a_ = remove_selfloops_from_adj(a)
    |                  ^^^^^^^^^^^^^^^^^^^^^^^^^ F405
236 |             fadj, node_mapping = get_giant_cc_from_adj(a_)
237 |             self.n_cc = 1
    |

src/driada/network/net_base.py:236:34: F405 `get_giant_cc_from_adj` may be undefined, or defined from star imports
    |
234 |         elif preprocessing == 'giant_cc':
235 |             a_ = remove_selfloops_from_adj(a)
236 |             fadj, node_mapping = get_giant_cc_from_adj(a_)
    |                                  ^^^^^^^^^^^^^^^^^^^^^ F405
237 |             self.n_cc = 1
    |

src/driada/network/net_base.py:240:18: F405 `remove_selfloops_from_adj` may be undefined, or defined from star imports
    |
239 |         elif preprocessing == 'giant_scc':
240 |             a_ = remove_selfloops_from_adj(a)
    |                  ^^^^^^^^^^^^^^^^^^^^^^^^^ F405
241 |             fadj, node_mapping = get_giant_scc_from_adj(a_)
242 |             self.n_cc = 1
    |

src/driada/network/net_base.py:241:34: F405 `get_giant_scc_from_adj` may be undefined, or defined from star imports
    |
239 |         elif preprocessing == 'giant_scc':
240 |             a_ = remove_selfloops_from_adj(a)
241 |             fadj, node_mapping = get_giant_scc_from_adj(a_)
    |                                  ^^^^^^^^^^^^^^^^^^^^^^ F405
242 |             self.n_cc = 1
243 |             self.n_scc = 1
    |

src/driada/network/net_base.py:273:20: F405 `get_ccs_from_adj` may be undefined, or defined from star imports
    |
272 |     def is_connected(self):
273 |         ccs = list(get_ccs_from_adj(self.adj))
    |                    ^^^^^^^^^^^^^^^^ F405
274 |         return len(ccs) == 1
    |

src/driada/network/net_base.py:280:21: F405 `nx` may be undefined, or defined from star imports
    |
278 |         if rmode == 'graph_iom':
279 |             if self.directed:
280 |                 g = nx.DiGraph(self.graph)
    |                     ^^ F405
281 |             else:
282 |                 g = nx.Graph(self.graph)
    |

src/driada/network/net_base.py:282:21: F405 `nx` may be undefined, or defined from star imports
    |
280 |                 g = nx.DiGraph(self.graph)
281 |             else:
282 |                 g = nx.Graph(self.graph)
    |                     ^^ F405
283 |
284 |             new_graph = random_rewiring_IOM_preserving(g, r=2)
    |

src/driada/network/net_base.py:284:25: F405 `random_rewiring_IOM_preserving` may be undefined, or defined from star imports
    |
282 |                 g = nx.Graph(self.graph)
283 |
284 |             new_graph = random_rewiring_IOM_preserving(g, r=2)
    |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F405
285 |             rand_adj = nx.adjacency_matrix(new_graph)
    |

src/driada/network/net_base.py:285:24: F405 `nx` may be undefined, or defined from star imports
    |
284 |             new_graph = random_rewiring_IOM_preserving(g, r=2)
285 |             rand_adj = nx.adjacency_matrix(new_graph)
    |                        ^^ F405
286 |
287 |         elif rmode == 'adj_iom':
    |

src/driada/network/net_base.py:288:24: F405 `adj_random_rewiring_iom_preserving` may be undefined, or defined from star imports
    |
287 |         elif rmode == 'adj_iom':
288 |             rand_adj = adj_random_rewiring_iom_preserving(self.adj,
    |                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F405
289 |                                                           is_weighted=self.weighted,
290 |                                                           r=2,
    |

src/driada/network/net_base.py:294:24: F405 `random_rewiring_complete_graph` may be undefined, or defined from star imports
    |
293 |         elif rmode == 'complete':
294 |             rand_adj = random_rewiring_complete_graph(self.adj)
    |                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F405
295 |
296 |         elif rmode == 'shuffle':
    |

src/driada/network/net_base.py:297:24: F405 `random_rewiring_dense_graph` may be undefined, or defined from star imports
    |
296 |         elif rmode == 'shuffle':
297 |             rand_adj = random_rewiring_dense_graph(self.adj)
    |                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^ F405
298 |
299 |         else:
    |

src/driada/network/net_base.py:302:32: F405 `sp` may be undefined, or defined from star imports
    |
300 |             raise ValueError('Unknown randomization method')
301 |
302 |         rand_net = Network(adj=sp.csr_matrix(rand_adj),
    |                                ^^ F405
303 |                            name=self.name + f' {rmode} rand',
304 |                            pos=self.pos,
    |

src/driada/network/net_base.py:313:23: F405 `np` may be undefined, or defined from star imports
    |
311 |     def get_node_degrees(self):
312 |         # convert sparse matrix to 0-1 format and sum over specific axis
313 |         self.outdeg = np.array(self.adj.astype(bool).astype(int).sum(axis=0)).ravel()
    |                       ^^ F405
314 |         self.indeg = np.array(self.adj.astype(bool).astype(int).sum(axis=1)).ravel()
315 |         self.deg = np.array((self.adj + self.adj.T).astype(bool).astype(int).sum(axis=1)).ravel()
    |

src/driada/network/net_base.py:314:22: F405 `np` may be undefined, or defined from star imports
    |
312 |         # convert sparse matrix to 0-1 format and sum over specific axis
313 |         self.outdeg = np.array(self.adj.astype(bool).astype(int).sum(axis=0)).ravel()
314 |         self.indeg = np.array(self.adj.astype(bool).astype(int).sum(axis=1)).ravel()
    |                      ^^ F405
315 |         self.deg = np.array((self.adj + self.adj.T).astype(bool).astype(int).sum(axis=1)).ravel()
    |

src/driada/network/net_base.py:315:20: F405 `np` may be undefined, or defined from star imports
    |
313 |         self.outdeg = np.array(self.adj.astype(bool).astype(int).sum(axis=0)).ravel()
314 |         self.indeg = np.array(self.adj.astype(bool).astype(int).sum(axis=1)).ravel()
315 |         self.deg = np.array((self.adj + self.adj.T).astype(bool).astype(int).sum(axis=1)).ravel()
    |                    ^^ F405
316 |
317 |         min_out = min(self.outdeg)
    |

src/driada/network/net_base.py:323:34: F405 `np` may be undefined, or defined from star imports
    |
322 |         if max_out != min_out:
323 |             self.scaled_outdeg = np.array([1.0 * (deg - min_out) / (max_out - min_out) for deg in self.outdeg])
    |                                  ^^ F405
324 |         else:
325 |             self.scaled_outdeg = np.ones(len(self.outdeg))
    |

src/driada/network/net_base.py:325:34: F405 `np` may be undefined, or defined from star imports
    |
323 |             self.scaled_outdeg = np.array([1.0 * (deg - min_out) / (max_out - min_out) for deg in self.outdeg])
324 |         else:
325 |             self.scaled_outdeg = np.ones(len(self.outdeg))
    |                                  ^^ F405
326 |
327 |         if min_in != max_in:
    |

src/driada/network/net_base.py:328:33: F405 `np` may be undefined, or defined from star imports
    |
327 |         if min_in != max_in:
328 |             self.scaled_indeg = np.array([1.0 * (deg - min_in) / (max_in - min_in) for deg in self.indeg])
    |                                 ^^ F405
329 |         else:
330 |             self.scaled_indeg = np.ones(len(self.indeg))
    |

src/driada/network/net_base.py:330:33: F405 `np` may be undefined, or defined from star imports
    |
328 |             self.scaled_indeg = np.array([1.0 * (deg - min_in) / (max_in - min_in) for deg in self.indeg])
329 |         else:
330 |             self.scaled_indeg = np.ones(len(self.indeg))
    |                                 ^^ F405
331 |
332 |     def get_degree_distr(self, mode='all'):
    |

src/driada/network/net_base.py:344:20: F405 `np` may be undefined, or defined from star imports
    |
342 |         if max(deg) == min(deg):
343 |             # All nodes have same degree
344 |             return np.array([1.0])
    |                    ^^ F405
345 |         hist, bins = np.histogram(deg, bins=max(deg) - min(deg), density=True)
346 |         return hist
    |

src/driada/network/net_base.py:345:22: F405 `np` may be undefined, or defined from star imports
    |
343 |             # All nodes have same degree
344 |             return np.array([1.0])
345 |         hist, bins = np.histogram(deg, bins=max(deg) - min(deg), density=True)
    |                      ^^ F405
346 |         return hist
    |

src/driada/network/net_base.py:353:26: F405 `get_laplacian` may be undefined, or defined from star imports
    |
351 |         if matrix is None:
352 |             if mode == 'lap' or mode == 'lap_out':
353 |                 matrix = get_laplacian(self.adj)
    |                          ^^^^^^^^^^^^^ F405
354 |             elif mode == 'nlap':
355 |                 matrix = get_norm_laplacian(self.adj)
    |

src/driada/network/net_base.py:355:26: F405 `get_norm_laplacian` may be undefined, or defined from star imports
    |
353 |                 matrix = get_laplacian(self.adj)
354 |             elif mode == 'nlap':
355 |                 matrix = get_norm_laplacian(self.adj)
    |                          ^^^^^^^^^^^^^^^^^^ F405
356 |             elif mode == 'rwlap':
357 |                 matrix = get_rw_laplacian(self.adj)
    |

src/driada/network/net_base.py:357:26: F405 `get_rw_laplacian` may be undefined, or defined from star imports
    |
355 |                 matrix = get_norm_laplacian(self.adj)
356 |             elif mode == 'rwlap':
357 |                 matrix = get_rw_laplacian(self.adj)
    |                          ^^^^^^^^^^^^^^^^ F405
358 |             elif mode == 'trans':
359 |                 matrix = get_trans_matrix(self.adj)
    |

src/driada/network/net_base.py:359:26: F405 `get_trans_matrix` may be undefined, or defined from star imports
    |
357 |                 matrix = get_rw_laplacian(self.adj)
358 |             elif mode == 'trans':
359 |                 matrix = get_trans_matrix(self.adj)
    |                          ^^^^^^^^^^^^^^^^ F405
360 |             elif mode == 'adj':
361 |                 matrix = self.adj
    |

src/driada/network/net_base.py:433:9: F841 Local variable `A` is assigned to but never used
    |
431 |         deg = self.deg
432 |
433 |         A = self.adj.astype(float)
    |         ^ F841
434 |         n = self.n
    |
    = help: Remove assignment to unused variable `A`

src/driada/network/net_base.py:436:17: F405 `np` may be undefined, or defined from star imports
    |
434 |         n = self.n
435 |
436 |         if n != np.count_nonzero(outdeg) and verbose:
    |                 ^^ F405
437 |             self.logger.warning(f'{n - np.count_nonzero(outdeg)} nodes without out-edges')
438 |         if n != np.count_nonzero(indeg) and verbose:
    |

src/driada/network/net_base.py:437:40: F405 `np` may be undefined, or defined from star imports
    |
436 |         if n != np.count_nonzero(outdeg) and verbose:
437 |             self.logger.warning(f'{n - np.count_nonzero(outdeg)} nodes without out-edges')
    |                                        ^^ F405
438 |         if n != np.count_nonzero(indeg) and verbose:
439 |             self.logger.warning(f'{n - np.count_nonzero(indeg)} nodes without in-edges')
    |

src/driada/network/net_base.py:438:17: F405 `np` may be undefined, or defined from star imports
    |
436 |         if n != np.count_nonzero(outdeg) and verbose:
437 |             self.logger.warning(f'{n - np.count_nonzero(outdeg)} nodes without out-edges')
438 |         if n != np.count_nonzero(indeg) and verbose:
    |                 ^^ F405
439 |             self.logger.warning(f'{n - np.count_nonzero(indeg)} nodes without in-edges')
    |

src/driada/network/net_base.py:439:40: F405 `np` may be undefined, or defined from star imports
    |
437 |             self.logger.warning(f'{n - np.count_nonzero(outdeg)} nodes without out-edges')
438 |         if n != np.count_nonzero(indeg) and verbose:
439 |             self.logger.warning(f'{n - np.count_nonzero(indeg)} nodes without in-edges')
    |                                        ^^ F405
440 |
441 |         nz = np.count_nonzero(deg)
    |

src/driada/network/net_base.py:441:14: F405 `np` may be undefined, or defined from star imports
    |
439 |             self.logger.warning(f'{n - np.count_nonzero(indeg)} nodes without in-edges')
440 |
441 |         nz = np.count_nonzero(deg)
    |              ^^ F405
442 |         if nz != n and self.n_cc == 1:
443 |             self.logger.error(f'Graph has {n - nz} isolated nodes!')
    |

src/driada/network/net_base.py:446:60: F405 `np` may be undefined, or defined from star imports
    |
444 |             raise Exception(f'Graph has {n - nz} isolated nodes!')
445 |
446 |         if not self.weighted and not self.directed and not np.allclose(outdeg, indeg):
    |                                                            ^^ F405
447 |             raise Exception('out- and in- degrees do not coincide in boolean')
    |

src/driada/network/net_base.py:454:31: F405 `np` may be undefined, or defined from star imports
    |
452 |             print('Performing diagonalization...')
453 |
454 |         matrix_is_symmetric = np.allclose(matrix.data, matrix.T.data)
    |                               ^^ F405
455 |         if matrix_is_symmetric:
456 |             raw_eigs, right_eigvecs = la.eigh(matrix.todense())
    |

src/driada/network/net_base.py:460:20: F405 `np` may be undefined, or defined from star imports
    |
458 |             raw_eigs, right_eigvecs = la.eig(matrix.todense(), right=True)
459 |
460 |         raw_eigs = np.around(raw_eigs, decimals=12)
    |                    ^^ F405
461 |         sorted_eigs = np.sort(raw_eigs)
    |

src/driada/network/net_base.py:461:23: F405 `np` may be undefined, or defined from star imports
    |
460 |         raw_eigs = np.around(raw_eigs, decimals=12)
461 |         sorted_eigs = np.sort(raw_eigs)
    |                       ^^ F405
462 |
463 |         if 'lap' in mode:
    |

src/driada/network/net_base.py:464:35: F405 `np` may be undefined, or defined from star imports
    |
463 |         if 'lap' in mode:
464 |             n_comp = len(raw_eigs[np.abs(raw_eigs) == 0])
    |                                   ^^ F405
465 |             if n_comp != 1 and not self.weighted and self.n_cc == 1:
466 |                 print('eigenvalues:', sorted_eigs)
    |

src/driada/network/net_base.py:471:12: F405 `np` may be undefined, or defined from star imports
    |
469 |         setattr(self, mode, matrix)
470 |
471 |         if np.allclose(np.imag(sorted_eigs), np.zeros(len(sorted_eigs)), atol=1e-12):
    |            ^^ F405
472 |             sorted_eigs = np.real(sorted_eigs)
473 |         else:
    |

src/driada/network/net_base.py:471:24: F405 `np` may be undefined, or defined from star imports
    |
469 |         setattr(self, mode, matrix)
470 |
471 |         if np.allclose(np.imag(sorted_eigs), np.zeros(len(sorted_eigs)), atol=1e-12):
    |                        ^^ F405
472 |             sorted_eigs = np.real(sorted_eigs)
473 |         else:
    |

src/driada/network/net_base.py:471:46: F405 `np` may be undefined, or defined from star imports
    |
469 |         setattr(self, mode, matrix)
470 |
471 |         if np.allclose(np.imag(sorted_eigs), np.zeros(len(sorted_eigs)), atol=1e-12):
    |                                              ^^ F405
472 |             sorted_eigs = np.real(sorted_eigs)
473 |         else:
    |

src/driada/network/net_base.py:472:27: F405 `np` may be undefined, or defined from star imports
    |
471 |         if np.allclose(np.imag(sorted_eigs), np.zeros(len(sorted_eigs)), atol=1e-12):
472 |             sorted_eigs = np.real(sorted_eigs)
    |                           ^^ F405
473 |         else:
474 |             if not self.directed:
    |

src/driada/network/net_base.py:479:45: F405 `np` may be undefined, or defined from star imports
    |
477 |         setattr(self, mode + '_spectrum', sorted_eigs)
478 |
479 |         sorted_eigenvectors = right_eigvecs[np.ix_(range(len(sorted_eigs)), np.argsort(raw_eigs))]
    |                                             ^^ F405
480 |         if np.allclose(np.imag(sorted_eigenvectors), np.zeros(sorted_eigenvectors.shape), atol=1e-8):
481 |             sorted_eigenvectors = np.real(sorted_eigenvectors)
    |

src/driada/network/net_base.py:479:77: F405 `np` may be undefined, or defined from star imports
    |
477 |         setattr(self, mode + '_spectrum', sorted_eigs)
478 |
479 |         sorted_eigenvectors = right_eigvecs[np.ix_(range(len(sorted_eigs)), np.argsort(raw_eigs))]
    |                                                                             ^^ F405
480 |         if np.allclose(np.imag(sorted_eigenvectors), np.zeros(sorted_eigenvectors.shape), atol=1e-8):
481 |             sorted_eigenvectors = np.real(sorted_eigenvectors)
    |

src/driada/network/net_base.py:480:12: F405 `np` may be undefined, or defined from star imports
    |
479 |         sorted_eigenvectors = right_eigvecs[np.ix_(range(len(sorted_eigs)), np.argsort(raw_eigs))]
480 |         if np.allclose(np.imag(sorted_eigenvectors), np.zeros(sorted_eigenvectors.shape), atol=1e-8):
    |            ^^ F405
481 |             sorted_eigenvectors = np.real(sorted_eigenvectors)
482 |         else:
    |

src/driada/network/net_base.py:480:24: F405 `np` may be undefined, or defined from star imports
    |
479 |         sorted_eigenvectors = right_eigvecs[np.ix_(range(len(sorted_eigs)), np.argsort(raw_eigs))]
480 |         if np.allclose(np.imag(sorted_eigenvectors), np.zeros(sorted_eigenvectors.shape), atol=1e-8):
    |                        ^^ F405
481 |             sorted_eigenvectors = np.real(sorted_eigenvectors)
482 |         else:
    |

src/driada/network/net_base.py:480:54: F405 `np` may be undefined, or defined from star imports
    |
479 |         sorted_eigenvectors = right_eigvecs[np.ix_(range(len(sorted_eigs)), np.argsort(raw_eigs))]
480 |         if np.allclose(np.imag(sorted_eigenvectors), np.zeros(sorted_eigenvectors.shape), atol=1e-8):
    |                                                      ^^ F405
481 |             sorted_eigenvectors = np.real(sorted_eigenvectors)
482 |         else:
    |

src/driada/network/net_base.py:481:35: F405 `np` may be undefined, or defined from star imports
    |
479 |         sorted_eigenvectors = right_eigvecs[np.ix_(range(len(sorted_eigs)), np.argsort(raw_eigs))]
480 |         if np.allclose(np.imag(sorted_eigenvectors), np.zeros(sorted_eigenvectors.shape), atol=1e-8):
481 |             sorted_eigenvectors = np.real(sorted_eigenvectors)
    |                                   ^^ F405
482 |         else:
483 |             if not self.directed:
    |

src/driada/network/net_base.py:495:49: F405 `np` may be undefined, or defined from star imports
    |
493 |     def calculate_z_values(self, mode='lap'):
494 |         spectrum = self.get_spectrum(mode)
495 |         seigs = sorted(list(set(spectrum)), key=np.abs)
    |                                                 ^^ F405
496 |         if len(seigs) != len(spectrum) and self.verbose:
497 |             print('WARNING:', len(spectrum) - len(seigs), 'repeated eigenvalues discarded')
    |

src/driada/network/net_base.py:505:13: F405 `np` may be undefined, or defined from star imports
    |
503 |             print('Computing nearest neighbours...')
504 |
505 |         X = np.array([[np.real(x), np.imag(x)] for x in seigs])
    |             ^^ F405
506 |         nbrs = NearestNeighbors(n_neighbors=3, algorithm='ball_tree').fit(X)
507 |         distances, indices = nbrs.kneighbors(X)
    |

src/driada/network/net_base.py:505:24: F405 `np` may be undefined, or defined from star imports
    |
503 |             print('Computing nearest neighbours...')
504 |
505 |         X = np.array([[np.real(x), np.imag(x)] for x in seigs])
    |                        ^^ F405
506 |         nbrs = NearestNeighbors(n_neighbors=3, algorithm='ball_tree').fit(X)
507 |         distances, indices = nbrs.kneighbors(X)
    |

src/driada/network/net_base.py:505:36: F405 `np` may be undefined, or defined from star imports
    |
503 |             print('Computing nearest neighbours...')
504 |
505 |         X = np.array([[np.real(x), np.imag(x)] for x in seigs])
    |                                    ^^ F405
506 |         nbrs = NearestNeighbors(n_neighbors=3, algorithm='ball_tree').fit(X)
507 |         distances, indices = nbrs.kneighbors(X)
    |

src/driada/network/net_base.py:514:17: F405 `np` may be undefined, or defined from star imports
    |
512 |         nnndist = np.array([(nnnbs[i] - eigs[i]) for i in range(len(eigs))])
513 |         '''
514 |         zlist = np.array([(nnbs[i] - seigs[i]) / (nnnbs[i] - seigs[i]) for i in range(len(seigs))])
    |                 ^^ F405
515 |         zdict = dict(zip(seigs, zlist))
    |

src/driada/network/net_base.py:522:15: F405 `np` may be undefined, or defined from star imports
    |
520 |         eigenvectors = self.get_eigenvectors(mode)
521 |         nvecs = eigenvectors.shape[1]
522 |         ipr = np.zeros(nvecs)
    |               ^^ F405
523 |         eig_entropy = np.zeros(nvecs)
    |

src/driada/network/net_base.py:523:23: F405 `np` may be undefined, or defined from star imports
    |
521 |         nvecs = eigenvectors.shape[1]
522 |         ipr = np.zeros(nvecs)
523 |         eig_entropy = np.zeros(nvecs)
    |                       ^^ F405
524 |
525 |         for i in range(nvecs):
    |

src/driada/network/net_base.py:526:27: F405 `np` may be undefined, or defined from star imports
    |
525 |         for i in range(nvecs):
526 |             ipr[i] = sum([np.abs(v) ** 4 for v in eigenvectors[:, i]])
    |                           ^^ F405
527 |             # entropy[i] = -np.log(ipr[i]) # erdos entropy (deprecated)
528 |             eig_entropy[i] = entropy(np.array([np.abs(v) ** 2 for v in eigenvectors[:, i]]))
    |

src/driada/network/net_base.py:528:38: F405 `np` may be undefined, or defined from star imports
    |
526 |             ipr[i] = sum([np.abs(v) ** 4 for v in eigenvectors[:, i]])
527 |             # entropy[i] = -np.log(ipr[i]) # erdos entropy (deprecated)
528 |             eig_entropy[i] = entropy(np.array([np.abs(v) ** 2 for v in eigenvectors[:, i]]))
    |                                      ^^ F405
529 |
530 |         setattr(self, mode + '_ipr', ipr)
    |

src/driada/network/net_base.py:528:48: F405 `np` may be undefined, or defined from star imports
    |
526 |             ipr[i] = sum([np.abs(v) ** 4 for v in eigenvectors[:, i]])
527 |             # entropy[i] = -np.log(ipr[i]) # erdos entropy (deprecated)
528 |             eig_entropy[i] = entropy(np.array([np.abs(v) ** 2 for v in eigenvectors[:, i]]))
    |                                                ^^ F405
529 |
530 |         setattr(self, mode + '_ipr', ipr)
    |

src/driada/network/net_base.py:549:16: F405 `spectral_entropy` may be undefined, or defined from star imports
    |
547 |     def calculate_thermodynamic_entropy(self, tlist, verbose=False, norm=False):
548 |         spectrum = self._get_lap_spectrum(norm=norm)
549 |         res = [spectral_entropy(spectrum, t, verbose=verbose) for t in tlist]
    |                ^^^^^^^^^^^^^^^^ F405
550 |         return res
    |

src/driada/network/net_base.py:554:16: F405 `free_entropy` may be undefined, or defined from star imports
    |
552 |     def calculate_free_entropy(self, tlist, norm=False):
553 |         spectrum = self._get_lap_spectrum(norm=norm)
554 |         res = [free_entropy(spectrum, t) for t in tlist]
    |                ^^^^^^^^^^^^ F405
555 |         return res
    |

src/driada/network/net_base.py:559:16: F405 `q_entropy` may be undefined, or defined from star imports
    |
557 |     def calculate_q_entropy(self, q, tlist, norm=False):
558 |         spectrum = self._get_lap_spectrum(norm=norm)
559 |         res = [q_entropy(spectrum, t, q=q) for t in tlist]
    |                ^^^^^^^^^ F405
560 |         return res
    |

src/driada/network/net_base.py:564:45: F405 `np` may be undefined, or defined from star imports
    |
562 |     def calculate_estrada_communicability(self):
563 |         adj_spectrum = self.get_spectrum('adj')
564 |         self.estrada_communicability = sum([np.exp(e) for e in adj_spectrum])
    |                                             ^^ F405
565 |         return self.estrada_communicability
    |

src/driada/network/net_base.py:569:21: F405 `np` may be undefined, or defined from star imports
    |
567 |     def get_estrada_bipartivity_index(self):
568 |         adj_spectrum = self.get_spectrum('adj')
569 |         esi1 = sum([np.exp(-e) for e in adj_spectrum])
    |                     ^^ F405
570 |         esi2 = sum([np.exp(e) for e in adj_spectrum])
571 |         self.estrada_bipartivity = esi1 / esi2
    |

src/driada/network/net_base.py:570:21: F405 `np` may be undefined, or defined from star imports
    |
568 |         adj_spectrum = self.get_spectrum('adj')
569 |         esi1 = sum([np.exp(-e) for e in adj_spectrum])
570 |         esi2 = sum([np.exp(e) for e in adj_spectrum])
    |                     ^^ F405
571 |         self.estrada_bipartivity = esi1 / esi2
572 |         return self.estrada_bipartivity
    |

src/driada/network/net_base.py:577:24: F405 `np` may be undefined, or defined from star imports
    |
575 |         zvals = self.get_z_values(mode)
576 |
577 |         mean_cos_phi = np.mean(np.array([np.cos(np.angle(x)) for x in zvals]))
    |                        ^^ F405
578 |         rvals = [1. / (np.abs(z)) ** 2 for z in zvals]
579 |         mean_inv_r_sq = np.mean(np.array(rvals))
    |

src/driada/network/net_base.py:577:32: F405 `np` may be undefined, or defined from star imports
    |
575 |         zvals = self.get_z_values(mode)
576 |
577 |         mean_cos_phi = np.mean(np.array([np.cos(np.angle(x)) for x in zvals]))
    |                                ^^ F405
578 |         rvals = [1. / (np.abs(z)) ** 2 for z in zvals]
579 |         mean_inv_r_sq = np.mean(np.array(rvals))
    |

src/driada/network/net_base.py:577:42: F405 `np` may be undefined, or defined from star imports
    |
575 |         zvals = self.get_z_values(mode)
576 |
577 |         mean_cos_phi = np.mean(np.array([np.cos(np.angle(x)) for x in zvals]))
    |                                          ^^ F405
578 |         rvals = [1. / (np.abs(z)) ** 2 for z in zvals]
579 |         mean_inv_r_sq = np.mean(np.array(rvals))
    |

src/driada/network/net_base.py:577:49: F405 `np` may be undefined, or defined from star imports
    |
575 |         zvals = self.get_z_values(mode)
576 |
577 |         mean_cos_phi = np.mean(np.array([np.cos(np.angle(x)) for x in zvals]))
    |                                                 ^^ F405
578 |         rvals = [1. / (np.abs(z)) ** 2 for z in zvals]
579 |         mean_inv_r_sq = np.mean(np.array(rvals))
    |

src/driada/network/net_base.py:578:24: F405 `np` may be undefined, or defined from star imports
    |
577 |         mean_cos_phi = np.mean(np.array([np.cos(np.angle(x)) for x in zvals]))
578 |         rvals = [1. / (np.abs(z)) ** 2 for z in zvals]
    |                        ^^ F405
579 |         mean_inv_r_sq = np.mean(np.array(rvals))
    |

src/driada/network/net_base.py:579:25: F405 `np` may be undefined, or defined from star imports
    |
577 |         mean_cos_phi = np.mean(np.array([np.cos(np.angle(x)) for x in zvals]))
578 |         rvals = [1. / (np.abs(z)) ** 2 for z in zvals]
579 |         mean_inv_r_sq = np.mean(np.array(rvals))
    |                         ^^ F405
580 |
581 |         if self.verbose:
    |

src/driada/network/net_base.py:579:33: F405 `np` may be undefined, or defined from star imports
    |
577 |         mean_cos_phi = np.mean(np.array([np.cos(np.angle(x)) for x in zvals]))
578 |         rvals = [1. / (np.abs(z)) ** 2 for z in zvals]
579 |         mean_inv_r_sq = np.mean(np.array(rvals))
    |                                 ^^ F405
580 |
581 |         if self.verbose:
    |

src/driada/network/net_base.py:595:14: F405 `get_norm_laplacian` may be undefined, or defined from star imports
    |
593 |         self.logger.info('Performing spectral decomposition...')
594 |         K = A.shape[0]
595 |         NL = get_norm_laplacian(A)
    |              ^^^^^^^^^^^^^^^^^^ F405
596 |         DH = get_inv_sqrt_diag_matrix(A)
    |

src/driada/network/net_base.py:596:14: F405 `get_inv_sqrt_diag_matrix` may be undefined, or defined from star imports
    |
594 |         K = A.shape[0]
595 |         NL = get_norm_laplacian(A)
596 |         DH = get_inv_sqrt_diag_matrix(A)
    |              ^^^^^^^^^^^^^^^^^^^^^^^^ F405
597 |
598 |         start_v = np.ones(K)
    |

src/driada/network/net_base.py:598:19: F405 `np` may be undefined, or defined from star imports
    |
596 |         DH = get_inv_sqrt_diag_matrix(A)
597 |
598 |         start_v = np.ones(K)
    |                   ^^ F405
599 |         eigvals, eigvecs = eigs(NL, k=dim + 1, which='LR', v0=start_v, maxiter=K * 1000)
600 |         eigvals = np.asarray([np.round(np.real(x), 6) for x in eigvals])
    |

src/driada/network/net_base.py:600:19: F405 `np` may be undefined, or defined from star imports
    |
598 |         start_v = np.ones(K)
599 |         eigvals, eigvecs = eigs(NL, k=dim + 1, which='LR', v0=start_v, maxiter=K * 1000)
600 |         eigvals = np.asarray([np.round(np.real(x), 6) for x in eigvals])
    |                   ^^ F405
601 |
602 |         if np.count_nonzero(eigvals == 1.0) > 1:
    |

src/driada/network/net_base.py:600:31: F405 `np` may be undefined, or defined from star imports
    |
598 |         start_v = np.ones(K)
599 |         eigvals, eigvecs = eigs(NL, k=dim + 1, which='LR', v0=start_v, maxiter=K * 1000)
600 |         eigvals = np.asarray([np.round(np.real(x), 6) for x in eigvals])
    |                               ^^ F405
601 |
602 |         if np.count_nonzero(eigvals == 1.0) > 1:
    |

src/driada/network/net_base.py:600:40: F405 `np` may be undefined, or defined from star imports
    |
598 |         start_v = np.ones(K)
599 |         eigvals, eigvecs = eigs(NL, k=dim + 1, which='LR', v0=start_v, maxiter=K * 1000)
600 |         eigvals = np.asarray([np.round(np.real(x), 6) for x in eigvals])
    |                                        ^^ F405
601 |
602 |         if np.count_nonzero(eigvals == 1.0) > 1:
    |

src/driada/network/net_base.py:602:12: F405 `np` may be undefined, or defined from star imports
    |
600 |         eigvals = np.asarray([np.round(np.real(x), 6) for x in eigvals])
601 |
602 |         if np.count_nonzero(eigvals == 1.0) > 1:
    |            ^^ F405
603 |             raise Exception('Error while LEM embedding construction: graph is not connected!')
604 |         else:
    |

src/driada/network/net_base.py:608:25: F405 `np` may be undefined, or defined from star imports
    |
606 |             vecs = eigvecs[:, 1:dim+1]  # shape: (n_nodes, dim)
607 |             # Normalize eigenvectors
608 |             vec_norms = np.sqrt(np.sum(np.abs(vecs)**2, axis=0))
    |                         ^^ F405
609 |             vecs = vecs / vec_norms
610 |             # Apply D^{-1/2} transformation
    |

src/driada/network/net_base.py:608:33: F405 `np` may be undefined, or defined from star imports
    |
606 |             vecs = eigvecs[:, 1:dim+1]  # shape: (n_nodes, dim)
607 |             # Normalize eigenvectors
608 |             vec_norms = np.sqrt(np.sum(np.abs(vecs)**2, axis=0))
    |                                 ^^ F405
609 |             vecs = vecs / vec_norms
610 |             # Apply D^{-1/2} transformation
    |

src/driada/network/net_base.py:608:40: F405 `np` may be undefined, or defined from star imports
    |
606 |             vecs = eigvecs[:, 1:dim+1]  # shape: (n_nodes, dim)
607 |             # Normalize eigenvectors
608 |             vec_norms = np.sqrt(np.sum(np.abs(vecs)**2, axis=0))
    |                                        ^^ F405
609 |             vecs = vecs / vec_norms
610 |             # Apply D^{-1/2} transformation
    |

src/driada/network/quantum.py:1:1: F403 `from .matrix_utils import *` used; unable to detect undefined names
  |
1 | from .matrix_utils import *
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^ F403
2 | import scipy
3 | from scipy.linalg import expm
  |

src/driada/network/quantum.py:10:18: F405 `np` may be undefined, or defined from star imports
   |
 8 |         raise Exception('q must be >0')
 9 |     elif q == 1:
10 |         answer = np.trace(np.dot(A, (scipy.linalg.logm(A) - scipy.linalg.logm(B))/np.log(2.0)))
   |                  ^^ F405
11 |     else:
12 |         answer = (1/(q-1)) * np.log(np.trace(np.dot(scipy.linalg.fractional_matrix_power(A, q),
   |

src/driada/network/quantum.py:10:27: F405 `np` may be undefined, or defined from star imports
   |
 8 |         raise Exception('q must be >0')
 9 |     elif q == 1:
10 |         answer = np.trace(np.dot(A, (scipy.linalg.logm(A) - scipy.linalg.logm(B))/np.log(2.0)))
   |                           ^^ F405
11 |     else:
12 |         answer = (1/(q-1)) * np.log(np.trace(np.dot(scipy.linalg.fractional_matrix_power(A, q),
   |

src/driada/network/quantum.py:10:83: F405 `np` may be undefined, or defined from star imports
   |
 8 |         raise Exception('q must be >0')
 9 |     elif q == 1:
10 |         answer = np.trace(np.dot(A, (scipy.linalg.logm(A) - scipy.linalg.logm(B))/np.log(2.0)))
   |                                                                                   ^^ F405
11 |     else:
12 |         answer = (1/(q-1)) * np.log(np.trace(np.dot(scipy.linalg.fractional_matrix_power(A, q),
   |

src/driada/network/quantum.py:12:30: F405 `np` may be undefined, or defined from star imports
   |
10 |         answer = np.trace(np.dot(A, (scipy.linalg.logm(A) - scipy.linalg.logm(B))/np.log(2.0)))
11 |     else:
12 |         answer = (1/(q-1)) * np.log(np.trace(np.dot(scipy.linalg.fractional_matrix_power(A, q),
   |                              ^^ F405
13 |                                                     scipy.linalg.fractional_matrix_power(B, 1-q))))/np.log(2.0)
14 |     return answer
   |

src/driada/network/quantum.py:12:37: F405 `np` may be undefined, or defined from star imports
   |
10 |         answer = np.trace(np.dot(A, (scipy.linalg.logm(A) - scipy.linalg.logm(B))/np.log(2.0)))
11 |     else:
12 |         answer = (1/(q-1)) * np.log(np.trace(np.dot(scipy.linalg.fractional_matrix_power(A, q),
   |                                     ^^ F405
13 |                                                     scipy.linalg.fractional_matrix_power(B, 1-q))))/np.log(2.0)
14 |     return answer
   |

src/driada/network/quantum.py:12:46: F405 `np` may be undefined, or defined from star imports
   |
10 |         answer = np.trace(np.dot(A, (scipy.linalg.logm(A) - scipy.linalg.logm(B))/np.log(2.0)))
11 |     else:
12 |         answer = (1/(q-1)) * np.log(np.trace(np.dot(scipy.linalg.fractional_matrix_power(A, q),
   |                                              ^^ F405
13 |                                                     scipy.linalg.fractional_matrix_power(B, 1-q))))/np.log(2.0)
14 |     return answer
   |

src/driada/network/quantum.py:13:101: F405 `np` may be undefined, or defined from star imports
   |
11 |     else:
12 |         answer = (1/(q-1)) * np.log(np.trace(np.dot(scipy.linalg.fractional_matrix_power(A, q),
13 |                                                     scipy.linalg.fractional_matrix_power(B, 1-q))))/np.log(2.0)
   |                                                                                                     ^^ F405
14 |     return answer
   |

src/driada/network/quantum.py:20:13: F405 `get_norm_laplacian` may be undefined, or defined from star imports
   |
18 |     A = A.astype(float)
19 |     if norm:
20 |         X = get_norm_laplacian(A)
   |             ^^^^^^^^^^^^^^^^^^ F405
21 |     else:
22 |         X = get_laplacian(A)
   |

src/driada/network/quantum.py:22:13: F405 `get_laplacian` may be undefined, or defined from star imports
   |
20 |         X = get_norm_laplacian(A)
21 |     else:
22 |         X = get_laplacian(A)
   |             ^^^^^^^^^^^^^ F405
23 |
24 |     R = expm(-t * X)
   |

src/driada/network/quantum.py:25:11: F405 `np` may be undefined, or defined from star imports
   |
24 |     R = expm(-t * X)
25 |     R = R/np.trace(X)
   |           ^^ F405
26 |
27 |     return R
   |

src/driada/network/quantum.py:31:13: F405 `np` may be undefined, or defined from star imports
   |
30 | def manual_entropy(pr):
31 |     probs = np.trim_zeros(pr)
   |             ^^ F405
32 |     probs = probs[np.where(probs > 1e-15)]
33 |     return -np.real(np.sum(np.multiply(probs, np.log2(probs))))
   |

src/driada/network/quantum.py:32:19: F405 `np` may be undefined, or defined from star imports
   |
30 | def manual_entropy(pr):
31 |     probs = np.trim_zeros(pr)
32 |     probs = probs[np.where(probs > 1e-15)]
   |                   ^^ F405
33 |     return -np.real(np.sum(np.multiply(probs, np.log2(probs))))
   |

src/driada/network/quantum.py:33:13: F405 `np` may be undefined, or defined from star imports
   |
31 |     probs = np.trim_zeros(pr)
32 |     probs = probs[np.where(probs > 1e-15)]
33 |     return -np.real(np.sum(np.multiply(probs, np.log2(probs))))
   |             ^^ F405
   |

src/driada/network/quantum.py:33:21: F405 `np` may be undefined, or defined from star imports
   |
31 |     probs = np.trim_zeros(pr)
32 |     probs = probs[np.where(probs > 1e-15)]
33 |     return -np.real(np.sum(np.multiply(probs, np.log2(probs))))
   |                     ^^ F405
   |

src/driada/network/quantum.py:33:28: F405 `np` may be undefined, or defined from star imports
   |
31 |     probs = np.trim_zeros(pr)
32 |     probs = probs[np.where(probs > 1e-15)]
33 |     return -np.real(np.sum(np.multiply(probs, np.log2(probs))))
   |                            ^^ F405
   |

src/driada/network/quantum.py:33:47: F405 `np` may be undefined, or defined from star imports
   |
31 |     probs = np.trim_zeros(pr)
32 |     probs = probs[np.where(probs > 1e-15)]
33 |     return -np.real(np.sum(np.multiply(probs, np.log2(probs))))
   |                                               ^^ F405
   |

src/driada/network/quantum.py:40:13: F405 `np` may be undefined, or defined from star imports
   |
38 |     Y = get_density_matrix(B, t)
39 |
40 |     mixed = np.trim_zeros(np.linalg.eigvalsh((X + Y) / 2))
   |             ^^ F405
41 |     raw1 = np.trim_zeros(np.linalg.eigvalsh(X))
42 |     raw2 = np.trim_zeros(np.linalg.eigvalsh(Y))
   |

src/driada/network/quantum.py:40:27: F405 `np` may be undefined, or defined from star imports
   |
38 |     Y = get_density_matrix(B, t)
39 |
40 |     mixed = np.trim_zeros(np.linalg.eigvalsh((X + Y) / 2))
   |                           ^^ F405
41 |     raw1 = np.trim_zeros(np.linalg.eigvalsh(X))
42 |     raw2 = np.trim_zeros(np.linalg.eigvalsh(Y))
   |

src/driada/network/quantum.py:41:12: F405 `np` may be undefined, or defined from star imports
   |
40 |     mixed = np.trim_zeros(np.linalg.eigvalsh((X + Y) / 2))
41 |     raw1 = np.trim_zeros(np.linalg.eigvalsh(X))
   |            ^^ F405
42 |     raw2 = np.trim_zeros(np.linalg.eigvalsh(Y))
   |

src/driada/network/quantum.py:41:26: F405 `np` may be undefined, or defined from star imports
   |
40 |     mixed = np.trim_zeros(np.linalg.eigvalsh((X + Y) / 2))
41 |     raw1 = np.trim_zeros(np.linalg.eigvalsh(X))
   |                          ^^ F405
42 |     raw2 = np.trim_zeros(np.linalg.eigvalsh(Y))
   |

src/driada/network/quantum.py:42:12: F405 `np` may be undefined, or defined from star imports
   |
40 |     mixed = np.trim_zeros(np.linalg.eigvalsh((X + Y) / 2))
41 |     raw1 = np.trim_zeros(np.linalg.eigvalsh(X))
42 |     raw2 = np.trim_zeros(np.linalg.eigvalsh(Y))
   |            ^^ F405
43 |
44 |     first = manual_entropy(mixed)
   |

src/driada/network/quantum.py:42:26: F405 `np` may be undefined, or defined from star imports
   |
40 |     mixed = np.trim_zeros(np.linalg.eigvalsh((X + Y) / 2))
41 |     raw1 = np.trim_zeros(np.linalg.eigvalsh(X))
42 |     raw2 = np.trim_zeros(np.linalg.eigvalsh(Y))
   |                          ^^ F405
43 |
44 |     first = manual_entropy(mixed)
   |

src/driada/network/quantum.py:49:5: E722 Do not use bare `except`
   |
47 |     try:
48 |         JSD = math.sqrt(first - second)
49 |     except:
   |     ^^^^^^ E722
50 |         JSD = 0
   |

src/driada/network/randomization.py:19:1: F403 `from .graph_utils import *` used; unable to detect undefined names
   |
17 | import tqdm
18 |
19 | from .graph_utils import *
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^ F403
20 | from .matrix_utils import *
21 | from ..utils.jit import conditional_njit
   |

src/driada/network/randomization.py:20:1: F403 `from .matrix_utils import *` used; unable to detect undefined names
   |
19 | from .graph_utils import *
20 | from .matrix_utils import *
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^ F403
21 | from ..utils.jit import conditional_njit
   |

src/driada/network/randomization.py:21:25: F401 [*] `..utils.jit.conditional_njit` imported but unused
   |
19 | from .graph_utils import *
20 | from .matrix_utils import *
21 | from ..utils.jit import conditional_njit
   |                         ^^^^^^^^^^^^^^^^ F401
   |
   = help: Remove unused import: `..utils.jit.conditional_njit`

src/driada/network/randomization.py:106:9: F405 `symmetric_component` may be undefined, or defined from star imports
    |
105 |     # Process symmetric component (bidirectional edges)
106 |     s = symmetric_component(a, is_weighted)
    |         ^^^^^^^^^^^^^^^^^^^ F405
107 |     rs = turn_to_partially_directed(s, directed=1.0, weighted=is_weighted)
108 |     # rs is already dense matrix
    |

src/driada/network/randomization.py:107:10: F405 `turn_to_partially_directed` may be undefined, or defined from star imports
    |
105 |     # Process symmetric component (bidirectional edges)
106 |     s = symmetric_component(a, is_weighted)
107 |     rs = turn_to_partially_directed(s, directed=1.0, weighted=is_weighted)
    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^ F405
108 |     # rs is already dense matrix
109 |     rows, cols = rs.nonzero()
    |

src/driada/network/randomization.py:170:10: F405 `non_symmetric_component` may be undefined, or defined from star imports
    |
169 |     # Process non-symmetric component (unidirectional edges)
170 |     ns = non_symmetric_component(a, is_weighted)
    |          ^^^^^^^^^^^^^^^^^^^^^^^ F405
171 |     rows, cols = ns.nonzero()
172 |     edges = list(set(zip(rows, cols)))
    |

src/driada/network/randomization.py:462:5: F841 Local variable `count` is assigned to but never used
    |
460 |     # Number_of_rewired_2_edge_pairs = 20
461 |     i = 0
462 |     count = 0
    |     ^^^^^ F841
463 |     previous_text = ''
    |
    = help: Remove assignment to unused variable `count`

src/driada/network/randomization.py:489:13: E722 Do not use bare `except`
    |
487 |             try:
488 |                 w_ab = G.get_edge_data(Node_A, Node_B)['weight']
489 |             except:
    |             ^^^^^^ E722
490 |                 pass
491 |             G.remove_edge(Node_A, Node_B)
    |

src/driada/network/randomization.py:501:17: E722 Do not use bare `except`
    |
499 |                 try:
500 |                     w_cd = G.get_edge_data(Node_C, Node_D)['weight']
501 |                 except:
    |                 ^^^^^^ E722
502 |                     pass
503 |                 G.remove_edge(Node_C, Node_D)
    |

src/driada/network/randomization.py:512:13: E722 Do not use bare `except`
    |
510 |                 G.add_edge(Node_A, Node_D, weight=w_ab)
511 |                 G.add_edge(Node_D, Node_A, weight=w_ab)
512 |             except:
    |             ^^^^^^ E722
513 |                 G.add_edge(Node_A, Node_D)
514 |                 G.add_edge(Node_D, Node_A)
    |

src/driada/network/randomization.py:519:13: E722 Do not use bare `except`
    |
517 |                 G.add_edge(Node_C, Node_B, weight=w_cd)
518 |                 G.add_edge(Node_B, Node_C, weight=w_cd)
519 |             except:
    |             ^^^^^^ E722
520 |                 G.add_edge(Node_C, Node_B)
521 |                 G.add_edge(Node_B, Node_C)
    |

src/driada/network/randomization.py:561:17: E722 Do not use bare `except`
    |
559 |                 try:
560 |                     w_ab = G.get_edge_data(Node_A, Node_B)['weight']
561 |                 except:
    |                 ^^^^^^ E722
562 |                     pass
563 |                 G.remove_edge(Node_A, Node_B)
    |

src/driada/network/randomization.py:572:17: E722 Do not use bare `except`
    |
570 |                 try:
571 |                     w_cd = G.get_edge_data(Node_C, Node_D)['weight']
572 |                 except:
    |                 ^^^^^^ E722
573 |                     pass
574 |                 G.remove_edge(Node_C, Node_D)
    |

src/driada/network/randomization.py:581:13: E722 Do not use bare `except`
    |
579 |             try:
580 |                 G.add_edge(Node_A, Node_D, weight=w_ab)
581 |             except:
    |             ^^^^^^ E722
582 |                 G.add_edge(Node_A, Node_D)
    |

src/driada/network/randomization.py:586:13: E722 Do not use bare `except`
    |
584 |             try:
585 |                 G.add_edge(Node_C, Node_B, weight=w_cd)
586 |             except:
    |             ^^^^^^ E722
587 |                 G.add_edge(Node_C, Node_B)
    |

src/driada/rsa/core.py:7:20: F401 [*] `typing.List` imported but unused
  |
5 | import numpy as np
6 | import logging
7 | from typing import List, Dict, Tuple, Optional, Union
  |                    ^^^^ F401
8 | from scipy import stats
9 | from scipy.spatial.distance import pdist, squareform
  |
  = help: Remove unused import: `typing.List`

src/driada/rsa/core.py:12:26: F401 [*] `..utils.data.correlation_matrix` imported but unused
   |
11 | from ..dim_reduction.data import MVData
12 | from ..utils.data import correlation_matrix
   |                          ^^^^^^^^^^^^^^^^^^ F401
13 | from ..utils.jit import is_jit_enabled
14 | from .core_jit import (
   |
   = help: Remove unused import: `..utils.data.correlation_matrix`

src/driada/rsa/core.py:15:5: F401 [*] `.core_jit.fast_correlation_distance` imported but unused
   |
13 | from ..utils.jit import is_jit_enabled
14 | from .core_jit import (
15 |     fast_correlation_distance,
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^ F401
16 |     fast_euclidean_distance, 
17 |     fast_manhattan_distance,
   |
   = help: Remove unused import: `.core_jit.fast_correlation_distance`

src/driada/rsa/core.py:111:5: F841 Local variable `n_conditions` is assigned to but never used
    |
109 |     # Get unique labels (conditions)
110 |     unique_labels = np.unique(labels)
111 |     n_conditions = len(unique_labels)
    |     ^^^^^^^^^^^^ F841
112 |     
113 |     # Use JIT-compiled averaging if available and using mean
    |
    = help: Remove assignment to unused variable `n_conditions`

src/driada/rsa/core.py:212:48: E741 Ambiguous variable name: `l`
    |
210 |     for label in unique_labels:
211 |         # Find all patterns for this label
212 |         label_patterns = [pattern for pattern, l in zip(trial_patterns, trial_labels_list) if l == label]
    |                                                ^ E741
213 |         
214 |         # Average across repetitions of the same condition
    |

src/driada/rsa/core.py:371:38: F821 Undefined name `Experiment`
    |
369 | # Unified API function
370 | def compute_rdm_unified(
371 |     data: Union[np.ndarray, MVData, 'Experiment'],
    |                                      ^^^^^^^^^^ F821
372 |     items: Optional[Union[np.ndarray, str, Dict]] = None,
373 |     data_type: str = 'calcium',
    |

src/driada/rsa/core.py:495:39: F821 Undefined name `Experiment`
    |
493 | # Simplified high-level API for common use case
494 | def rsa_compare(
495 |     data1: Union[np.ndarray, MVData, 'Experiment'],
    |                                       ^^^^^^^^^^ F821
496 |     data2: Union[np.ndarray, MVData, 'Experiment'],
497 |     items: Optional[Union[str, Dict]] = None,
    |

src/driada/rsa/core.py:496:39: F821 Undefined name `Experiment`
    |
494 | def rsa_compare(
495 |     data1: Union[np.ndarray, MVData, 'Experiment'],
496 |     data2: Union[np.ndarray, MVData, 'Experiment'],
    |                                       ^^^^^^^^^^ F821
497 |     items: Optional[Union[str, Dict]] = None,
498 |     metric: str = 'correlation',
    |

src/driada/rsa/core_jit.py:8:43: F401 [*] `..utils.jit.prange` imported but unused
  |
7 | import numpy as np
8 | from ..utils.jit import conditional_njit, prange
  |                                           ^^^^^^ F401
  |
  = help: Remove unused import: `..utils.jit.prange`

src/driada/rsa/integration.py:6:26: F401 [*] `typing.List` imported but unused
  |
5 | import numpy as np
6 | from typing import Dict, List, Optional, Union, Tuple
  |                          ^^^^ F401
7 | from ..experiment import Experiment
8 | from ..dim_reduction.data import MVData
  |
  = help: Remove unused import

src/driada/rsa/integration.py:6:32: F401 [*] `typing.Optional` imported but unused
  |
5 | import numpy as np
6 | from typing import Dict, List, Optional, Union, Tuple
  |                                ^^^^^^^^ F401
7 | from ..experiment import Experiment
8 | from ..dim_reduction.data import MVData
  |
  = help: Remove unused import

src/driada/rsa/integration.py:10:5: F401 [*] `.core.compute_rdm` imported but unused
   |
 8 | from ..dim_reduction.data import MVData
 9 | from .core import (
10 |     compute_rdm, 
   |     ^^^^^^^^^^^ F401
11 |     compute_rdm_from_timeseries_labels,
12 |     compute_rdm_from_trials,
   |
   = help: Remove unused import: `.core.compute_rdm`

src/driada/rsa/visual.py:7:19: F401 [*] `seaborn` imported but unused
  |
5 | import numpy as np
6 | import matplotlib.pyplot as plt
7 | import seaborn as sns
  |                   ^^^ F401
8 | from typing import List, Optional, Tuple, Union, Dict, Any
9 | from scipy.cluster.hierarchy import dendrogram, linkage
  |
  = help: Remove unused import: `seaborn`

src/driada/rsa/visual.py:8:43: F401 [*] `typing.Union` imported but unused
   |
 6 | import matplotlib.pyplot as plt
 7 | import seaborn as sns
 8 | from typing import List, Optional, Tuple, Union, Dict, Any
   |                                           ^^^^^ F401
 9 | from scipy.cluster.hierarchy import dendrogram, linkage
10 | from matplotlib.colors import LinearSegmentedColormap
   |
   = help: Remove unused import

src/driada/rsa/visual.py:8:50: F401 [*] `typing.Dict` imported but unused
   |
 6 | import matplotlib.pyplot as plt
 7 | import seaborn as sns
 8 | from typing import List, Optional, Tuple, Union, Dict, Any
   |                                                  ^^^^ F401
 9 | from scipy.cluster.hierarchy import dendrogram, linkage
10 | from matplotlib.colors import LinearSegmentedColormap
   |
   = help: Remove unused import

src/driada/rsa/visual.py:8:56: F401 [*] `typing.Any` imported but unused
   |
 6 | import matplotlib.pyplot as plt
 7 | import seaborn as sns
 8 | from typing import List, Optional, Tuple, Union, Dict, Any
   |                                                        ^^^ F401
 9 | from scipy.cluster.hierarchy import dendrogram, linkage
10 | from matplotlib.colors import LinearSegmentedColormap
   |
   = help: Remove unused import

src/driada/rsa/visual.py:10:31: F401 [*] `matplotlib.colors.LinearSegmentedColormap` imported but unused
   |
 8 | from typing import List, Optional, Tuple, Union, Dict, Any
 9 | from scipy.cluster.hierarchy import dendrogram, linkage
10 | from matplotlib.colors import LinearSegmentedColormap
   |                               ^^^^^^^^^^^^^^^^^^^^^^^ F401
11 |
12 | from ..utils.plot import make_beautiful, create_default_figure
   |
   = help: Remove unused import: `matplotlib.colors.LinearSegmentedColormap`

src/driada/rsa/visual.py:82:13: F841 Local variable `dendro_left` is assigned to but never used
   |
80 |             dendro_top = dendrogram(linkage_matrix, ax=ax_dendro_top, 
81 |                                     orientation='top', no_labels=True)
82 |             dendro_left = dendrogram(linkage_matrix, ax=ax_dendro_left,
   |             ^^^^^^^^^^^ F841
83 |                                      orientation='left', no_labels=True)
   |
   = help: Remove assignment to unused variable `dendro_left`

src/driada/utils/__init__.py:29:5: F401 `.matrix.is_positive_definite` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
   |
27 | from .matrix import (
28 |     nearestPD,
29 |     is_positive_definite,
   |     ^^^^^^^^^^^^^^^^^^^^ F401
30 | )
   |
   = help: Add unused import `is_positive_definite` to __all__

src/driada/utils/data.py:8:19: F401 [*] `numba.njit` imported but unused
  |
6 | import numpy as np
7 | import scipy.stats as st
8 | from numba import njit
  |                   ^^^^ F401
  |
  = help: Remove unused import: `numba.njit`

src/driada/utils/gif.py:5:17: F401 [*] `numpy` imported but unused
  |
3 | import imageio
4 | import matplotlib.pyplot as plt
5 | import numpy as np
  |                 ^^ F401
6 | import os
7 | from os import listdir, remove
  |
  = help: Remove unused import: `numpy`

src/driada/utils/gif.py:8:45: F401 [*] `os.path.dirname` imported but unused
   |
 6 | import os
 7 | from os import listdir, remove
 8 | from os.path import isfile, join, splitext, dirname
   |                                             ^^^^^^^ F401
 9 |
10 | from .plot import *
   |
   = help: Remove unused import: `os.path.dirname`

src/driada/utils/gif.py:10:1: F403 `from .plot import *` used; unable to detect undefined names
   |
 8 | from os.path import isfile, join, splitext, dirname
 9 |
10 | from .plot import *
   | ^^^^^^^^^^^^^^^^^^^ F403
   |

src/driada/utils/jit.py:7:23: F401 [*] `functools.wraps` imported but unused
  |
6 | import os
7 | from functools import wraps
  |                       ^^^^^ F401
8 | from typing import Callable
  |
  = help: Remove unused import: `functools.wraps`

src/driada/utils/jit.py:8:20: F401 [*] `typing.Callable` imported but unused
   |
 6 | import os
 7 | from functools import wraps
 8 | from typing import Callable
   |                    ^^^^^^^^ F401
 9 |
10 | # Check if Numba should be disabled
   |
   = help: Remove unused import: `typing.Callable`

src/driada/utils/matrix.py:38:5: E741 Ambiguous variable name: `I`
   |
36 |     # `spacing` will, for Gaussian random matrixes of small dimension, be on
37 |     # the order of 1e-16.
38 |     I = np.eye(A.shape[0])
   |     ^ E741
39 |     k = 1
40 |     while not is_positive_definite(A3):
   |

src/driada/utils/plot.py:8:28: F401 [*] `matplotlib.pylab` imported but unused
   |
 7 | import matplotlib.pyplot as plt
 8 | import matplotlib.pylab as pylab
   |                            ^^^^^ F401
 9 | from typing import Optional, Tuple, Dict, Any
10 | import numpy as np
   |
   = help: Remove unused import: `matplotlib.pylab`

src/driada/utils/plot.py:9:37: F401 [*] `typing.Dict` imported but unused
   |
 7 | import matplotlib.pyplot as plt
 8 | import matplotlib.pylab as pylab
 9 | from typing import Optional, Tuple, Dict, Any
   |                                     ^^^^ F401
10 | import numpy as np
   |
   = help: Remove unused import: `typing.Dict`

src/driada/utils/plot.py:193:9: F841 Local variable `cbar` is assigned to but never used
    |
192 |     if with_cbar:
193 |         cbar = ax.figure.colorbar(im, ax=ax)
    |         ^^^^ F841
194 |     
195 |     return fig, ax
    |
    = help: Remove assignment to unused variable `cbar`

src/driada/utils/spatial.py:18:36: F401 [*] `scipy.stats` imported but unused
   |
17 | import numpy as np
18 | from scipy import ndimage, signal, stats
   |                                    ^^^^^ F401
19 | from scipy.spatial.distance import pdist, squareform
20 | from sklearn.model_selection import train_test_split
   |
   = help: Remove unused import: `scipy.stats`

src/driada/utils/spatial.py:19:36: F401 [*] `scipy.spatial.distance.pdist` imported but unused
   |
17 | import numpy as np
18 | from scipy import ndimage, signal, stats
19 | from scipy.spatial.distance import pdist, squareform
   |                                    ^^^^^ F401
20 | from sklearn.model_selection import train_test_split
21 | from sklearn.ensemble import RandomForestRegressor
   |
   = help: Remove unused import

src/driada/utils/spatial.py:19:43: F401 [*] `scipy.spatial.distance.squareform` imported but unused
   |
17 | import numpy as np
18 | from scipy import ndimage, signal, stats
19 | from scipy.spatial.distance import pdist, squareform
   |                                           ^^^^^^^^^^ F401
20 | from sklearn.model_selection import train_test_split
21 | from sklearn.ensemble import RandomForestRegressor
   |
   = help: Remove unused import

src/driada/utils/visual.py:12:19: F401 [*] `seaborn` imported but unused
   |
10 | import matplotlib.pyplot as plt
11 | import matplotlib.gridspec as gridspec
12 | import seaborn as sns
   |                   ^^^ F401
13 | from typing import Dict, List, Tuple, Optional, Union, Any, Callable
14 | from scipy.stats import gaussian_kde
   |
   = help: Remove unused import: `seaborn`

src/driada/utils/visual.py:13:56: F401 [*] `typing.Any` imported but unused
   |
11 | import matplotlib.gridspec as gridspec
12 | import seaborn as sns
13 | from typing import Dict, List, Tuple, Optional, Union, Any, Callable
   |                                                        ^^^ F401
14 | from scipy.stats import gaussian_kde
15 | import pandas as pd
   |
   = help: Remove unused import

src/driada/utils/visual.py:13:61: F401 [*] `typing.Callable` imported but unused
   |
11 | import matplotlib.gridspec as gridspec
12 | import seaborn as sns
13 | from typing import Dict, List, Tuple, Optional, Union, Any, Callable
   |                                                             ^^^^^^^^ F401
14 | from scipy.stats import gaussian_kde
15 | import pandas as pd
   |
   = help: Remove unused import

src/driada/utils/visual.py:15:18: F401 [*] `pandas` imported but unused
   |
13 | from typing import Dict, List, Tuple, Optional, Union, Any, Callable
14 | from scipy.stats import gaussian_kde
15 | import pandas as pd
   |                  ^^ F401
16 |
17 | # Default DPI for all plots
   |
   = help: Remove unused import: `pandas`

src/driada/utils/visual.py:137:17: E722 Do not use bare `except`
    |
135 |                     Z = np.reshape(kde(positions_grid).T, X.shape)
136 |                     ax1.contour(X, Y, Z, colors='gray', alpha=0.3, linewidths=0.5)
137 |                 except:
    |                 ^^^^^^ E722
138 |                     pass  # Skip contours if KDE fails
139 |         else:
    |

src/driada/utils/visual.py:469:9: F841 Local variable `cbar` is assigned to but never used
    |
468 |         # Add colorbar
469 |         cbar = plt.colorbar(im, ax=ax, label='Mean MI (bits)')
    |         ^^^^ F841
470 |         
471 |         # Add method-specific metrics if available
    |
    = help: Remove assignment to unused variable `cbar`

src/driada/utils/visual.py:591:9: F841 Local variable `scatter` is assigned to but never used
    |
590 |         # Create scatter plot
591 |         scatter = ax.scatter(
    |         ^^^^^^^ F841
592 |             embedding[:, 0], embedding[:, 1],
593 |             c=color_labels, cmap=colormap,
    |
    = help: Remove assignment to unused variable `scatter`

temp/test_timeseries_types.py:78:7: F541 [*] f-string without any placeholders
   |
76 | ts_timeline = TimeSeries(timeline_data[:100])
77 |
78 | print(f"Timeline data:")
   |       ^^^^^^^^^^^^^^^^^ F541
79 | print(f"  Primary type: {ts_timeline.type_info.primary_type}")
80 | print(f"  Subtype: {ts_timeline.type_info.subtype}")
   |
   = help: Remove extraneous `f` prefix

temp/visualize_ts_types.py:6:19: F401 [*] `scipy.stats` imported but unused
  |
4 | import numpy as np
5 | import matplotlib.pyplot as plt
6 | from scipy import stats
  |                   ^^^^^ F401
7 | import os
  |
  = help: Remove unused import: `scipy.stats`

tests/integration/conftest.py:22:17: F401 [*] `numpy` imported but unused
   |
21 | import pytest
22 | import numpy as np
   |                 ^^ F401
23 | from copy import deepcopy
24 | from driada.experiment.synthetic import (
   |
   = help: Remove unused import: `numpy`

tests/integration/test_integration.py:7:5: F401 [*] `driada.Experiment` imported but unused
  |
5 | import warnings
6 | from driada import (
7 |     Experiment, 
  |     ^^^^^^^^^^ F401
8 |     compute_cell_feat_significance
9 | )
  |
  = help: Remove unused import: `driada.Experiment`

tests/integration/test_integration.py:11:34: F401 [*] `driada.dim_reduction.MVData` imported but unused
   |
 9 | )
10 | from driada.dimensionality import nn_dimension, pca_dimension, effective_rank
11 | from driada.dim_reduction import MVData
   |                                  ^^^^^^ F401
12 | from sklearn.decomposition import PCA
13 | from sklearn.manifold import Isomap
   |
   = help: Remove unused import: `driada.dim_reduction.MVData`

tests/integration/test_integration.py:14:8: F401 [*] `umap` imported but unused
   |
12 | from sklearn.decomposition import PCA
13 | from sklearn.manifold import Isomap
14 | import umap
   |        ^^^^ F401
   |
   = help: Remove unused import: `umap`

tests/integration/test_integration.py:134:9: F841 Local variable `embedding` is assigned to but never used
    |
132 |         # Apply DR - exp.calcium is already a MultiTimeSeries which inherits from MVData
133 |         mvdata = exp.calcium
134 |         embedding = mvdata.get_embedding({
    |         ^^^^^^^^^ F841
135 |             'e_method_name': 'pca',
136 |             'dim': 10
    |
    = help: Remove assignment to unused variable `embedding`

tests/integration/test_selectivity_mapper.py:9:8: F401 [*] `driada` imported but unused
   |
 7 | import logging
 8 |
 9 | import driada
   |        ^^^^^^ F401
10 | from driada.experiment import Experiment
11 | from driada.integration import SelectivityManifoldMapper
   |
   = help: Remove unused import: `driada`

tests/integration/test_selectivity_mapper.py:10:31: F401 [*] `driada.experiment.Experiment` imported but unused
   |
 9 | import driada
10 | from driada.experiment import Experiment
   |                               ^^^^^^^^^^ F401
11 | from driada.integration import SelectivityManifoldMapper
12 | from driada.intense import compute_cell_feat_significance, compute_embedding_selectivity
   |
   = help: Remove unused import: `driada.experiment.Experiment`

tests/integration/test_selectivity_mapper.py:152:9: F841 Local variable `embedding` is assigned to but never used
    |
151 |         # Create embedding with significant neurons only
152 |         embedding = mapper.create_embedding(
    |         ^^^^^^^^^ F841
153 |             'pca', 
154 |             n_components=3,
    |
    = help: Remove assignment to unused variable `embedding`

tests/integration/test_selectivity_mapper.py:176:9: F841 Local variable `embedding` is assigned to but never used
    |
174 |         # Use specific neurons
175 |         neuron_indices = [0, 5, 10, 15, 19]
176 |         embedding = mapper.create_embedding(
    |         ^^^^^^^^^ F841
177 |             'pca',
178 |             n_components=2,
    |
    = help: Remove assignment to unused variable `embedding`

tests/integration/test_selectivity_mapper.py:239:13: F841 Local variable `embedding` is assigned to but never used
    |
237 |         try:
238 |             # Create embedding with significant neurons selection
239 |             embedding = mapper.create_embedding(
    |             ^^^^^^^^^ F841
240 |                 'pca',
241 |                 n_components=2,
    |
    = help: Remove assignment to unused variable `embedding`

tests/integration/test_selectivity_mapper.py:272:9: F841 Local variable `embedding` is assigned to but never used
    |
271 |         # Create UMAP embedding with specific parameters
272 |         embedding = mapper.create_embedding(
    |         ^^^^^^^^^ F841
273 |             'umap',
274 |             n_components=2,
    |
    = help: Remove assignment to unused variable `embedding`

tests/integration/test_selectivity_mapper.py:476:9: F841 Local variable `results` is assigned to but never used
    |
475 |         # Analyze selectivity
476 |         results = mapper.analyze_embedding_selectivity(
    |         ^^^^^^^ F841
477 |             'pca',
478 |             n_shuffles_stage1=10,
    |
    = help: Remove assignment to unused variable `results`

tests/performance/test_rsa_performance.py:11:5: F401 [*] `driada.rsa.core_jit.fast_manhattan_distance` imported but unused
   |
 9 |     fast_correlation_distance,
10 |     fast_euclidean_distance,
11 |     fast_manhattan_distance
   |     ^^^^^^^^^^^^^^^^^^^^^^^ F401
12 | )
13 | from driada.dim_reduction.data import MVData
   |
   = help: Remove unused import: `driada.rsa.core_jit.fast_manhattan_distance`

tests/unit/dim_reduction/test_ae_vae_advanced.py:22:5: F841 Local variable `nn_params` is assigned to but never used
   |
21 |     # Train VAE with moderate KL weight
22 |     nn_params = {
   |     ^^^^^^^^^ F841
23 |         'continue_learning': 0,
24 |         'epochs': 100,
   |
   = help: Remove assignment to unused variable `nn_params`

tests/unit/dim_reduction/test_ae_vae_advanced.py:67:5: F841 Local variable `nn_params` is assigned to but never used
   |
66 |     # Test with correlation loss
67 |     nn_params = {
   |     ^^^^^^^^^ F841
68 |         'continue_learning': 0,
69 |         'epochs': 100,
   |
   = help: Remove assignment to unused variable `nn_params`

tests/unit/dim_reduction/test_ae_vae_advanced.py:108:5: F841 Local variable `nn_params_base` is assigned to but never used
    |
106 |     D = MVData(data.T)
107 |     
108 |     nn_params_base = {
    |     ^^^^^^^^^^^^^^ F841
109 |         'continue_learning': 0,
110 |         'epochs': 100,
    |
    = help: Remove assignment to unused variable `nn_params_base`

tests/unit/dim_reduction/test_correct_cov_spectrum.py:3:8: F401 [*] `pytest` imported but unused
  |
1 | """Tests for correct_cov_spectrum function."""
2 | import numpy as np
3 | import pytest
  |        ^^^^^^ F401
4 | import warnings
5 | from driada.dimensionality.utils import correct_cov_spectrum
  |
  = help: Remove unused import: `pytest`

tests/unit/dim_reduction/test_correct_cov_spectrum.py:42:9: F841 Local variable `orig_eigs` is assigned to but never used
   |
41 |         # Check that original matrix might have negative eigenvalues
42 |         orig_eigs = eigh(cmat, eigvals_only=True)
   |         ^^^^^^^^^ F841
43 |         # This is expected in near-singular cases
   |
   = help: Remove assignment to unused variable `orig_eigs`

tests/unit/dim_reduction/test_correct_cov_spectrum.py:74:13: F841 Local variable `corrected_eigs` is assigned to but never used
   |
72 |         with warnings.catch_warnings(record=True) as w:
73 |             warnings.simplefilter("always")
74 |             corrected_eigs = correct_cov_spectrum(n, t, cmat, correction_iters=2)
   |             ^^^^^^^^^^^^^^ F841
75 |             
76 |             # Check if any warning about negative eigenvalues was issued
   |
   = help: Remove assignment to unused variable `corrected_eigs`

tests/unit/dim_reduction/test_correct_cov_spectrum.py:77:13: F841 Local variable `neg_eig_warnings` is assigned to but never used
   |
76 |             # Check if any warning about negative eigenvalues was issued
77 |             neg_eig_warnings = [warning for warning in w 
   |             ^^^^^^^^^^^^^^^^ F841
78 |                                if "negative eigenvalues" in str(warning.message)]
79 |             # This may or may not warn depending on the random seed
   |
   = help: Remove assignment to unused variable `neg_eig_warnings`

tests/unit/dim_reduction/test_dr.py:1:47: F401 [*] `sklearn.datasets.make_s_curve` imported but unused
  |
1 | from sklearn.datasets import make_swiss_roll, make_s_curve, make_circles
  |                                               ^^^^^^^^^^^^ F401
2 | import numpy as np
3 | import pytest
  |
  = help: Remove unused import

tests/unit/dim_reduction/test_dr.py:1:61: F401 [*] `sklearn.datasets.make_circles` imported but unused
  |
1 | from sklearn.datasets import make_swiss_roll, make_s_curve, make_circles
  |                                                             ^^^^^^^^^^^^ F401
2 | import numpy as np
3 | import pytest
  |
  = help: Remove unused import

tests/unit/dim_reduction/test_dr.py:4:8: F401 [*] `time` imported but unused
  |
2 | import numpy as np
3 | import pytest
4 | import time
  |        ^^^^ F401
5 | import scipy.sparse as sp
6 | from unittest.mock import patch
  |
  = help: Remove unused import: `time`

tests/unit/dim_reduction/test_dr.py:7:1: F403 `from driada.dim_reduction.data import *` used; unable to detect undefined names
  |
5 | import scipy.sparse as sp
6 | from unittest.mock import patch
7 | from driada.dim_reduction.data import *
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F403
8 | from driada.experiment import Experiment
9 | from driada.experiment.synthetic import (
  |

tests/unit/dim_reduction/test_dr.py:8:31: F401 [*] `driada.experiment.Experiment` imported but unused
   |
 6 | from unittest.mock import patch
 7 | from driada.dim_reduction.data import *
 8 | from driada.experiment import Experiment
   |                               ^^^^^^^^^^ F401
 9 | from driada.experiment.synthetic import (
10 |     generate_synthetic_exp, 
   |
   = help: Remove unused import: `driada.experiment.Experiment`

tests/unit/dim_reduction/test_dr.py:10:5: F401 [*] `driada.experiment.synthetic.generate_synthetic_exp` imported but unused
   |
 8 | from driada.experiment import Experiment
 9 | from driada.experiment.synthetic import (
10 |     generate_synthetic_exp, 
   |     ^^^^^^^^^^^^^^^^^^^^^^ F401
11 |     generate_circular_manifold_exp,
12 |     generate_2d_manifold_exp
   |
   = help: Remove unused import

tests/unit/dim_reduction/test_dr.py:11:5: F401 [*] `driada.experiment.synthetic.generate_circular_manifold_exp` imported but unused
   |
 9 | from driada.experiment.synthetic import (
10 |     generate_synthetic_exp, 
11 |     generate_circular_manifold_exp,
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F401
12 |     generate_2d_manifold_exp
13 | )
   |
   = help: Remove unused import

tests/unit/dim_reduction/test_dr.py:12:5: F401 [*] `driada.experiment.synthetic.generate_2d_manifold_exp` imported but unused
   |
10 |     generate_synthetic_exp, 
11 |     generate_circular_manifold_exp,
12 |     generate_2d_manifold_exp
   |     ^^^^^^^^^^^^^^^^^^^^^^^^ F401
13 | )
14 | from driada.utils.data import create_correlated_gaussian_data
   |
   = help: Remove unused import

tests/unit/dim_reduction/test_dr.py:31:12: F405 `MVData` may be undefined, or defined from star imports
   |
29 |         hole=False
30 |     )
31 |     return MVData(data.T)
   |            ^^^^^^ F405
   |

tests/unit/dim_reduction/test_dr.py:44:12: F405 `MVData` may be undefined, or defined from star imports
   |
42 |         seed=42
43 |     )
44 |     return MVData(data)
   |            ^^^^^^ F405
   |

tests/unit/dim_reduction/test_dr.py:68:5: F841 Local variable `G` is assigned to but never used
   |
66 |     }
67 |
68 |     G = small_swiss_roll_mvdata.get_proximity_graph(metric_params, graph_params)
   |     ^ F841
   |
   = help: Remove assignment to unused variable `G`

tests/unit/dim_reduction/test_dr.py:163:9: F405 `check_data_for_errors` may be undefined, or defined from star imports
    |
162 |     with pytest.raises(Exception, match="Data contains zero points\!"):
163 |         check_data_for_errors(data)
    |         ^^^^^^^^^^^^^^^^^^^^^ F405
    |

tests/unit/dim_reduction/test_dr.py:171:14: F405 `MVData` may be undefined, or defined from star imports
    |
170 |     # Test downsampling by factor of 4
171 |     mvdata = MVData(data, downsampling=4)
    |              ^^^^^^ F405
172 |     assert mvdata.ds == 4
173 |     assert mvdata.n_points == 25
    |

tests/unit/dim_reduction/test_dr.py:186:14: F405 `MVData` may be undefined, or defined from star imports
    |
184 |     ])
185 |     
186 |     mvdata = MVData(data.copy(), rescale_rows=True)
    |              ^^^^^^ F405
187 |     
188 |     # Each row should be rescaled to [0, 1]
    |

tests/unit/dim_reduction/test_dr.py:204:14: F405 `MVData` may be undefined, or defined from star imports
    |
202 |     ])
203 |     
204 |     mvdata = MVData(data.copy())
    |              ^^^^^^ F405
205 |     original_shape = mvdata.data.shape
206 |     mvdata.median_filter(window=3)
    |

tests/unit/dim_reduction/test_dr.py:250:14: F405 `MVData` may be undefined, or defined from star imports
    |
248 | def test_get_embedding_no_params_error():
249 |     """Test error when no parameters provided to get_embedding."""
250 |     mvdata = MVData(np.random.rand(5, 20))
    |              ^^^^^^ F405
251 |     
252 |     with pytest.raises(ValueError, match="Either 'method' or 'e_params' must be provided"):
    |

tests/unit/dim_reduction/test_dr.py:258:14: F405 `MVData` may be undefined, or defined from star imports
    |
256 | def test_get_embedding_unknown_method_error():
257 |     """Test error for unknown embedding method."""
258 |     mvdata = MVData(np.random.rand(5, 20))
    |              ^^^^^^ F405
259 |     
260 |     e_params = {
    |

tests/unit/dim_reduction/test_dr.py:272:14: F405 `MVData` may be undefined, or defined from star imports
    |
270 | def test_get_proximity_graph_unknown_method():
271 |     """Test error for unknown graph construction method."""
272 |     mvdata = MVData(np.random.rand(5, 20))
    |              ^^^^^^ F405
273 |     
274 |     m_params = {'metric_name': 'euclidean'}
    |

tests/unit/dim_reduction/test_dr.py:284:14: F405 `MVData` may be undefined, or defined from star imports
    |
282 | def test_draw_vector(mock_matshow):
283 |     """Test draw_vector visualization."""
284 |     mvdata = MVData(np.random.rand(10, 20))
    |              ^^^^^^ F405
285 |     mvdata.draw_vector(5)
    |

tests/unit/dim_reduction/test_dr.py:295:14: F405 `MVData` may be undefined, or defined from star imports
    |
293 | def test_draw_row(mock_plot, mock_figure):
294 |     """Test draw_row visualization."""
295 |     mvdata = MVData(np.random.rand(10, 20))
    |              ^^^^^^ F405
296 |     mvdata.draw_row(3)
    |

tests/unit/dim_reduction/test_dr_extended.py:9:61: F401 [*] `sklearn.datasets.make_circles` imported but unused
   |
 7 | import pytest
 8 | import time
 9 | from sklearn.datasets import make_swiss_roll, make_s_curve, make_circles
   |                                                             ^^^^^^^^^^^^ F401
10 | from driada.dim_reduction.data import MVData
11 | from driada.experiment import Experiment
   |
   = help: Remove unused import: `sklearn.datasets.make_circles`

tests/unit/dim_reduction/test_dr_extended.py:11:31: F401 [*] `driada.experiment.Experiment` imported but unused
   |
 9 | from sklearn.datasets import make_swiss_roll, make_s_curve, make_circles
10 | from driada.dim_reduction.data import MVData
11 | from driada.experiment import Experiment
   |                               ^^^^^^^^^^ F401
12 | from driada.experiment.synthetic import (
13 |     generate_synthetic_exp, 
   |
   = help: Remove unused import: `driada.experiment.Experiment`

tests/unit/dim_reduction/test_dr_extended.py:89:5: F841 Local variable `metric_params` is assigned to but never used
   |
87 |     D = MVData(data)
88 |     
89 |     metric_params = {
   |     ^^^^^^^^^^^^^ F841
90 |         'metric_name': 'l2',
91 |         'sigma': 1,
   |
   = help: Remove assignment to unused variable `metric_params`

tests/unit/dim_reduction/test_dr_extended.py:160:9: F841 Local variable `emb` is assigned to but never used
    |
158 |     # Use new simplified API
159 |     with pytest.raises(Exception) as excinfo:
160 |         emb = D.get_embedding(
    |         ^^^ F841
161 |             method='dmaps',
162 |             dim=2,
    |
    = help: Remove assignment to unused variable `emb`

tests/unit/dim_reduction/test_dr_extended.py:292:5: F841 Local variable `metric_params` is assigned to but never used
    |
290 |     D = MVData(data.T)
291 |     
292 |     metric_params = {'metric_name': 'l2', 'sigma': 1, 'p': 2}
    |     ^^^^^^^^^^^^^ F841
293 |     graph_params = {
294 |         'g_method_name': 'knn',
    |
    = help: Remove assignment to unused variable `metric_params`

tests/unit/dim_reduction/test_dr_extended.py:293:5: F841 Local variable `graph_params` is assigned to but never used
    |
292 |     metric_params = {'metric_name': 'l2', 'sigma': 1, 'p': 2}
293 |     graph_params = {
    |     ^^^^^^^^^^^^ F841
294 |         'g_method_name': 'knn',
295 |         'weighted': 0,
    |
    = help: Remove assignment to unused variable `graph_params`

tests/unit/dim_reduction/test_dr_extended.py:351:5: F841 Local variable `metric_params` is assigned to but never used
    |
349 |     D = MVData(data.T)
350 |     
351 |     metric_params = {'metric_name': 'l2', 'sigma': 1, 'p': 2}
    |     ^^^^^^^^^^^^^ F841
352 |     graph_params = {
353 |         'g_method_name': 'knn',
    |
    = help: Remove assignment to unused variable `metric_params`

tests/unit/dim_reduction/test_dr_extended.py:352:5: F841 Local variable `graph_params` is assigned to but never used
    |
351 |     metric_params = {'metric_name': 'l2', 'sigma': 1, 'p': 2}
352 |     graph_params = {
    |     ^^^^^^^^^^^^ F841
353 |         'g_method_name': 'knn',
354 |         'weighted': 0,
    |
    = help: Remove assignment to unused variable `graph_params`

tests/unit/dim_reduction/test_embedding_to_mvdata.py:130:20: F401 `torch` imported but unused; consider using `importlib.util.find_spec` to test for availability
    |
128 |         """Test to_mvdata with neural network methods if torch available."""
129 |         try:
130 |             import torch
    |                    ^^^^^ F401
131 |             
132 |             # Test with autoencoder
    |
    = help: Remove unused import: `torch`

tests/unit/dim_reduction/test_eps_graph.py:113:9: F841 Local variable `graph` is assigned to but never used
    |
111 |         }
112 |         
113 |         graph = ProximityGraph(data, m_params, g_params, create_nx_graph=False)
    |         ^^^^^ F841
114 |         captured = capsys.readouterr()
    |
    = help: Remove assignment to unused variable `graph`

tests/unit/dim_reduction/test_graph_construction.py:6:27: F401 [*] `unittest.mock.patch` imported but unused
  |
4 | import numpy as np
5 | import scipy.sparse as sp
6 | from unittest.mock import patch, MagicMock
  |                           ^^^^^ F401
7 | from driada.dim_reduction.graph import ProximityGraph
8 | from driada.dim_reduction.data import MVData
  |
  = help: Remove unused import

tests/unit/dim_reduction/test_graph_construction.py:6:34: F401 [*] `unittest.mock.MagicMock` imported but unused
  |
4 | import numpy as np
5 | import scipy.sparse as sp
6 | from unittest.mock import patch, MagicMock
  |                                  ^^^^^^^^^ F401
7 | from driada.dim_reduction.graph import ProximityGraph
8 | from driada.dim_reduction.data import MVData
  |
  = help: Remove unused import

tests/unit/dim_reduction/test_graph_construction.py:8:39: F401 [*] `driada.dim_reduction.data.MVData` imported but unused
  |
6 | from unittest.mock import patch, MagicMock
7 | from driada.dim_reduction.graph import ProximityGraph
8 | from driada.dim_reduction.data import MVData
  |                                       ^^^^^^ F401
  |
  = help: Remove unused import: `driada.dim_reduction.data.MVData`

tests/unit/dim_reduction/test_intrinsic.py:213:20: F401 `pynndescent` imported but unused; consider using `importlib.util.find_spec` to test for availability
    |
211 |         # Only test if pynndescent is available
212 |         try:
213 |             import pynndescent
    |                    ^^^^^^^^^^^ F401
214 |         except ImportError:
215 |             if graph_method == "pynndescent":
    |
    = help: Remove unused import: `pynndescent`

tests/unit/dim_reduction/test_intrinsic.py:622:32: F401 [*] `scipy.sparse` imported but unused
    |
620 |     def test_graph_with_sparse_matrix(self):
621 |         """Test with different sparse matrix formats."""
622 |         import scipy.sparse as sp
    |                                ^^ F401
623 |         from sklearn.neighbors import kneighbors_graph
    |
    = help: Remove unused import: `scipy.sparse`

tests/unit/dim_reduction/test_linear.py:35:8: F401 [*] `pytest` imported but unused
   |
34 | import numpy as np
35 | import pytest
   |        ^^^^^^ F401
36 | from sklearn.datasets import make_swiss_roll, make_s_curve, make_blobs
37 | from driada.dimensionality import (
   |
   = help: Remove unused import: `pytest`

tests/unit/dim_reduction/test_manifold_metrics.py:930:12: E712 Avoid equality comparisons to `True`; use `metrics_all['is_reflected']:` for truth checks
    |
928 |     assert metrics_all['correlation'] > 0.95
929 |     assert metrics_all['error'] < 0.1
930 |     assert metrics_all['is_reflected'] == True
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
931 |     # The rotation offset will be different due to reflection
932 |     # Just check it's in valid range [0, 2π]
    |
    = help: Replace with `metrics_all['is_reflected']`

tests/unit/dim_reduction/test_manifold_metrics.py:955:12: E712 Avoid equality comparisons to `False`; use `not metrics_no_refl['is_reflected']:` for false checks
    |
953 |     # Should be worse without reflection
954 |     assert metrics_no_refl['error'] > metrics_all['error']
955 |     assert metrics_no_refl['is_reflected'] == False
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
    |
    = help: Replace with `not metrics_no_refl['is_reflected']`

tests/unit/experiment/synthetic/test_circular_manifold.py:7:19: F401 [*] `scipy.stats` imported but unused
  |
5 | import pytest
6 | import numpy as np
7 | from scipy import stats
  |                   ^^^^^ F401
8 |
9 | from driada.experiment.synthetic import (
  |
  = help: Remove unused import: `scipy.stats`

tests/unit/experiment/synthetic/test_circular_manifold.py:16:59: F401 [*] `driada.information.info_base.TimeSeries` imported but unused
   |
14 |     generate_circular_manifold_exp
15 | )
16 | from driada.information.info_base import MultiTimeSeries, TimeSeries
   |                                                           ^^^^^^^^^^ F401
   |
   = help: Remove unused import: `driada.information.info_base.TimeSeries`

tests/unit/experiment/synthetic/test_circular_manifold.py:238:5: F811 Redefinition of unused `stats` from line 7
    |
236 |     # Test that circular selectivity can be detected using INTENSE
237 |     # Use the circular_angle multifeature which properly represents circular variables
238 |     stats, significance, info_intense, results = compute_cell_feat_significance(
    |     ^^^^^ F811
239 |         exp,
240 |         feat_bunch=['circular_angle'],  # Test circular multifeature approach
    |
    = help: Remove definition: `stats`

tests/unit/experiment/synthetic/test_circular_manifold.py:456:5: F811 Redefinition of unused `stats` from line 7
    |
455 |     # Run INTENSE analysis
456 |     stats, significance, _, _ = compute_cell_feat_significance(
    |     ^^^^^ F811
457 |         exp,
458 |         find_optimal_delays=False,  # Disable delays for MultiTimeSeries (current limitation)
    |
    = help: Remove definition: `stats`

tests/unit/experiment/synthetic/test_mixed_population_optimized.py:14:42: F401 [*] `driada.information.info_base.TimeSeries` imported but unused
   |
12 |     Experiment
13 | )
14 | from driada.information.info_base import TimeSeries, MultiTimeSeries
   |                                          ^^^^^^^^^^ F401
   |
   = help: Remove unused import

tests/unit/experiment/synthetic/test_mixed_population_optimized.py:14:54: F401 [*] `driada.information.info_base.MultiTimeSeries` imported but unused
   |
12 |     Experiment
13 | )
14 | from driada.information.info_base import TimeSeries, MultiTimeSeries
   |                                                      ^^^^^^^^^^^^^^^ F401
   |
   = help: Remove unused import

tests/unit/experiment/synthetic/test_mixed_population_optimized.py:303:13: F841 Local variable `exp` is assigned to but never used
    |
301 |         start = time.time()
302 |         for _ in range(5):
303 |             exp = generate_mixed_population_exp(
    |             ^^^ F841
304 |                 n_neurons=8,
305 |                 manifold_fraction=0.5,
    |
    = help: Remove assignment to unused variable `exp`

tests/unit/experiment/synthetic/test_mixed_selectivity.py:9:8: F401 [*] `pytest` imported but unused
   |
 7 | """
 8 |
 9 | import pytest
   |        ^^^^^^ F401
10 | import numpy as np
11 | from driada.experiment.synthetic import (
   |
   = help: Remove unused import: `pytest`

tests/unit/experiment/synthetic/test_mixed_selectivity.py:18:44: F401 [*] `driada.intense.disentanglement.disentangle_all_selectivities` imported but unused
   |
16 | )
17 | from driada.intense.pipelines import compute_cell_feat_significance
18 | from driada.intense.disentanglement import disentangle_all_selectivities
   |                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F401
19 | from driada.information.info_base import TimeSeries
   |
   = help: Remove unused import: `driada.intense.disentanglement.disentangle_all_selectivities`

tests/unit/experiment/synthetic/test_mixed_selectivity.py:19:42: F401 [*] `driada.information.info_base.TimeSeries` imported but unused
   |
17 | from driada.intense.pipelines import compute_cell_feat_significance
18 | from driada.intense.disentanglement import disentangle_all_selectivities
19 | from driada.information.info_base import TimeSeries
   |                                          ^^^^^^^^^^ F401
   |
   = help: Remove unused import: `driada.information.info_base.TimeSeries`

tests/unit/experiment/synthetic/test_mixed_selectivity.py:179:9: F841 Local variable `n_features` is assigned to but never used
    |
177 |         """Test data generation with a known selectivity pattern."""
178 |         n_neurons = 5
179 |         n_features = 3
    |         ^^^^^^^^^^ F841
180 |         duration = 20
181 |         fps = 10
    |
    = help: Remove assignment to unused variable `n_features`

tests/unit/experiment/synthetic/test_mixed_selectivity.py:316:23: F541 [*] f-string without any placeholders
    |
315 |             if not detected_selective:
316 |                 print(f"  WARNING: No significant selectivity detected!")
    |                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
317 |         
318 |         # Check that neurons show significant selectivity to multiple features
    |
    = help: Remove extraneous `f` prefix

tests/unit/experiment/synthetic/test_mixed_selectivity.py:329:13: F541 [*] f-string without any placeholders
    |
327 |         # At least some neurons should show mixed selectivity
328 |         assert neurons_with_mixed_detected > 0, \
329 |             f"No neurons with detected mixed selectivity! Need neurons selective to 2+ features."
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
330 |         
331 |         # Check disentanglement results
    |
    = help: Remove extraneous `f` prefix

tests/unit/experiment/test_calcium_dynamics.py:13:5: F401 [*] `driada.experiment.synthetic.generate_circular_manifold_data` imported but unused
   |
11 |     generate_2d_manifold_neurons,
12 |     generate_3d_manifold_neurons,
13 |     generate_circular_manifold_data,
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F401
14 |     generate_mixed_population_exp
15 | )
   |
   = help: Remove unused import: `driada.experiment.synthetic.generate_circular_manifold_data`

tests/unit/experiment/test_calcium_dynamics.py:186:45: F811 [*] Redefinition of unused `generate_circular_manifold_data` from line 13
    |
184 | def test_calcium_saturation_effect():
185 |     """Test that high firing rates actually cause saturation in calcium signals."""
186 |     from driada.experiment.synthetic import generate_circular_manifold_data
    |                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F811
187 |     
188 |     # Generate data with low peak rate
    |
    = help: Remove definition: `generate_circular_manifold_data`

tests/unit/experiment/test_calcium_dynamics.py:242:9: F811 [*] Redefinition of unused `generate_circular_manifold_data` from line 13
    |
240 |         generate_2d_manifold_neurons, 
241 |         generate_3d_manifold_neurons,
242 |         generate_circular_manifold_data,
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F811
243 |         generate_2d_manifold_data,
244 |         generate_3d_manifold_data,
    |
    = help: Remove definition: `generate_circular_manifold_data`

tests/unit/experiment/test_duplicate_behavior.py:12:41: F401 [*] `driada.experiment.synthetic.generate_synthetic_exp` imported but unused
   |
10 | )
11 | from driada.information.info_base import TimeSeries
12 | from driada.experiment.synthetic import generate_synthetic_exp
   |                                         ^^^^^^^^^^^^^^^^^^^^^^ F401
   |
   = help: Remove unused import: `driada.experiment.synthetic.generate_synthetic_exp`

tests/unit/experiment/test_exp.py:1:41: F401 [*] `driada.intense.intense_base.compute_me_stats` imported but unused
  |
1 | from driada.intense.intense_base import compute_me_stats
  |                                         ^^^^^^^^^^^^^^^^ F401
2 | from driada.experiment.exp_base import *
3 | from driada.experiment.synthetic import *
  |
  = help: Remove unused import: `driada.intense.intense_base.compute_me_stats`

tests/unit/experiment/test_exp.py:2:1: F403 `from driada.experiment.exp_base import *` used; unable to detect undefined names
  |
1 | from driada.intense.intense_base import compute_me_stats
2 | from driada.experiment.exp_base import *
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F403
3 | from driada.experiment.synthetic import *
4 | from driada.intense.pipelines import compute_cell_feat_significance
  |

tests/unit/experiment/test_exp.py:3:1: F403 `from driada.experiment.synthetic import *` used; unable to detect undefined names
  |
1 | from driada.intense.intense_base import compute_me_stats
2 | from driada.experiment.exp_base import *
3 | from driada.experiment.synthetic import *
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F403
4 | from driada.intense.pipelines import compute_cell_feat_significance
5 | from driada.information.info_base import TimeSeries, MultiTimeSeries
  |

tests/unit/experiment/test_exp.py:5:42: F401 [*] `driada.information.info_base.TimeSeries` imported but unused
  |
3 | from driada.experiment.synthetic import *
4 | from driada.intense.pipelines import compute_cell_feat_significance
5 | from driada.information.info_base import TimeSeries, MultiTimeSeries
  |                                          ^^^^^^^^^^ F401
  |
  = help: Remove unused import

tests/unit/experiment/test_exp.py:5:54: F401 [*] `driada.information.info_base.MultiTimeSeries` imported but unused
  |
3 | from driada.experiment.synthetic import *
4 | from driada.intense.pipelines import compute_cell_feat_significance
5 | from driada.information.info_base import TimeSeries, MultiTimeSeries
  |                                                      ^^^^^^^^^^^^^^^ F401
  |
  = help: Remove unused import

tests/unit/experiment/test_exp.py:9:5: F841 Local variable `exp` is assigned to but never used
  |
8 | def test_creation(medium_experiment):
9 |     exp = medium_experiment
  |     ^^^ F841
  |
  = help: Remove assignment to unused variable `exp`

tests/unit/experiment/test_exp.py:14:5: F841 Local variable `res_` is assigned to but never used
   |
12 | def test_intense_exp(medium_experiment):
13 |     exp = medium_experiment
14 |     res_ = compute_cell_feat_significance(exp,
   |     ^^^^ F841
15 |                                           cell_bunch=None,
16 |                                           feat_bunch=None,
   |
   = help: Remove assignment to unused variable `res_`

tests/unit/experiment/test_exp_base.py:6:34: F401 [*] `unittest.mock.MagicMock` imported but unused
  |
4 | import numpy as np
5 | import warnings
6 | from unittest.mock import patch, MagicMock
  |                                  ^^^^^^^^^ F401
7 |
8 | from driada.experiment.exp_base import (
  |
  = help: Remove unused import: `unittest.mock.MagicMock`

tests/unit/experiment/test_exp_base.py:10:5: F401 [*] `driada.experiment.exp_base.DEFAULT_STATS` imported but unused
   |
 8 | from driada.experiment.exp_base import (
 9 |     Experiment, check_dynamic_features, STATS_VARS, SIGNIFICANCE_VARS,
10 |     DEFAULT_STATS, DEFAULT_SIGNIFICANCE
   |     ^^^^^^^^^^^^^ F401
11 | )
12 | from driada.information.info_base import TimeSeries, MultiTimeSeries
   |
   = help: Remove unused import

tests/unit/experiment/test_exp_base.py:10:20: F401 [*] `driada.experiment.exp_base.DEFAULT_SIGNIFICANCE` imported but unused
   |
 8 | from driada.experiment.exp_base import (
 9 |     Experiment, check_dynamic_features, STATS_VARS, SIGNIFICANCE_VARS,
10 |     DEFAULT_STATS, DEFAULT_SIGNIFICANCE
   |                    ^^^^^^^^^^^^^^^^^^^^ F401
11 | )
12 | from driada.information.info_base import TimeSeries, MultiTimeSeries
   |
   = help: Remove unused import

tests/unit/experiment/test_exp_base.py:154:58: F841 Local variable `w` is assigned to but never used
    |
152 |             mock_reconstruct.return_value = mock_spikes
153 |             
154 |             with warnings.catch_warnings(record=True) as w:
    |                                                          ^ F841
155 |                 exp = Experiment(
156 |                     signature="test",
    |
    = help: Remove assignment to unused variable `w`

tests/unit/experiment/test_exp_base.py:189:16: E712 Avoid equality comparisons to `True`; use `exp.filtered_flag:` for truth checks
    |
188 |         assert exp.n_frames == 490  # 500 - 10 bad frames
189 |         assert exp.filtered_flag == True
    |                ^^^^^^^^^^^^^^^^^^^^^^^^^ E712
190 |         assert hasattr(exp, 'bad_frames_mask')
191 |         assert np.array_equal(exp.bad_frames_mask, bad_mask)
    |
    = help: Replace with `exp.filtered_flag`

tests/unit/experiment/test_exp_base.py:465:16: E712 Avoid equality comparisons to `False`; use `not basic_experiment.selectivity_tables_initialized:` for false checks
    |
463 |         # Initially empty until _set_selectivity_tables is called
464 |         assert len(basic_experiment.stats_tables) == 0
465 |         assert basic_experiment.selectivity_tables_initialized == False
    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
466 |     
467 |     def test_hash_methods(self, basic_experiment):
    |
    = help: Replace with `not basic_experiment.selectivity_tables_initialized`

tests/unit/experiment/test_exp_base.py:598:16: E712 Avoid equality comparisons to `True`; use `basic_experiment.selectivity_tables_initialized:` for truth checks
    |
596 |         assert 'calcium' in basic_experiment.stats_tables
597 |         assert 'calcium' in basic_experiment.significance_tables
598 |         assert basic_experiment.selectivity_tables_initialized == True
    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
599 |         
600 |         # Check structure
    |
    = help: Replace with `basic_experiment.selectivity_tables_initialized`

tests/unit/experiment/test_exp_base.py:773:16: E712 Avoid equality comparisons to `True`; use `sig_slice['feat1'][0]['stage1']:` for truth checks
    |
771 |         )
772 |         
773 |         assert sig_slice['feat1'][0]['stage1'] == True
    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
774 |         assert sig_slice['feat1'][0]['stage2'] == True
    |
    = help: Replace with `sig_slice['feat1'][0]['stage1']`

tests/unit/experiment/test_exp_base.py:774:16: E712 Avoid equality comparisons to `True`; use `sig_slice['feat1'][0]['stage2']:` for truth checks
    |
773 |         assert sig_slice['feat1'][0]['stage1'] == True
774 |         assert sig_slice['feat1'][0]['stage2'] == True
    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
775 |     
776 |     def test_update_neuron_feature_pair_significance(self, basic_experiment):
    |
    = help: Replace with `sig_slice['feat1'][0]['stage2']`

tests/unit/experiment/test_exp_base.py:799:16: E712 Avoid equality comparisons to `True`; use `stored_sig['stage1']:` for truth checks
    |
797 |         # Verify
798 |         stored_sig = basic_experiment.significance_tables['calcium'][feat_id][cell_id]
799 |         assert stored_sig['stage1'] == True
    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
800 |         assert stored_sig['stage2'] == False
801 |         assert stored_sig['shuffles1'] == 1000
    |
    = help: Replace with `stored_sig['stage1']`

tests/unit/experiment/test_exp_base.py:800:16: E712 Avoid equality comparisons to `False`; use `not stored_sig['stage2']:` for false checks
    |
798 |         stored_sig = basic_experiment.significance_tables['calcium'][feat_id][cell_id]
799 |         assert stored_sig['stage1'] == True
800 |         assert stored_sig['stage2'] == False
    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
801 |         assert stored_sig['shuffles1'] == 1000
    |
    = help: Replace with `not stored_sig['stage2']`

tests/unit/experiment/test_exp_base.py:899:16: E712 Avoid equality comparisons to `True`; use `...:` for truth checks
    |
898 |         # Check relevance - should pass
899 |         assert basic_experiment._check_stats_relevance(cell_id, multifeature) == True
    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
900 |     
901 |     def test_update_stats_force_update(self, basic_experiment):
    |
    = help: Replace comparison

tests/unit/experiment/test_exp_build.py:16:34: F401 [*] `unittest.mock.MagicMock` imported but unused
   |
14 | import tempfile
15 | import shutil
16 | from unittest.mock import patch, MagicMock, mock_open
   |                                  ^^^^^^^^^ F401
17 | import pickle
   |
   = help: Remove unused import

tests/unit/experiment/test_exp_build.py:16:45: F401 [*] `unittest.mock.mock_open` imported but unused
   |
14 | import tempfile
15 | import shutil
16 | from unittest.mock import patch, MagicMock, mock_open
   |                                             ^^^^^^^^^ F401
17 | import pickle
   |
   = help: Remove unused import

tests/unit/experiment/test_exp_build.py:26:42: F401 [*] `driada.information.info_base.TimeSeries` imported but unused
   |
24 | )
25 | from driada.experiment.exp_base import Experiment
26 | from driada.information.info_base import TimeSeries, MultiTimeSeries
   |                                          ^^^^^^^^^^ F401
   |
   = help: Remove unused import

tests/unit/experiment/test_exp_build.py:26:54: F401 [*] `driada.information.info_base.MultiTimeSeries` imported but unused
   |
24 | )
25 | from driada.experiment.exp_base import Experiment
26 | from driada.information.info_base import TimeSeries, MultiTimeSeries
   |                                                      ^^^^^^^^^^^^^^^ F401
   |
   = help: Remove unused import

tests/unit/experiment/test_exp_build.py:421:17: E722 Do not use bare `except`
    |
419 |                 try:
420 |                     load_experiment('IABS', {}, root=new_root, verbose=False)
421 |                 except:
    |                 ^^^^^^ E722
422 |                     pass  # We expect it to fail later, but directory should be created
    |

tests/unit/experiment/test_neuron.py:4:46: F401 [*] `driada.experiment.neuron.DEFAULT_T_RISE` imported but unused
  |
2 | import pytest
3 | from unittest.mock import patch
4 | from driada.experiment.neuron import Neuron, DEFAULT_T_RISE, DEFAULT_T_OFF, DEFAULT_FPS, MIN_CA_SHIFT
  |                                              ^^^^^^^^^^^^^^ F401
5 | from driada.information.info_base import TimeSeries
6 | from driada.utils.neural import generate_pseudo_calcium_multisignal
  |
  = help: Remove unused import

tests/unit/experiment/test_neuron.py:4:62: F401 [*] `driada.experiment.neuron.DEFAULT_T_OFF` imported but unused
  |
2 | import pytest
3 | from unittest.mock import patch
4 | from driada.experiment.neuron import Neuron, DEFAULT_T_RISE, DEFAULT_T_OFF, DEFAULT_FPS, MIN_CA_SHIFT
  |                                                              ^^^^^^^^^^^^^ F401
5 | from driada.information.info_base import TimeSeries
6 | from driada.utils.neural import generate_pseudo_calcium_multisignal
  |
  = help: Remove unused import

tests/unit/experiment/test_neuron.py:4:77: F401 [*] `driada.experiment.neuron.DEFAULT_FPS` imported but unused
  |
2 | import pytest
3 | from unittest.mock import patch
4 | from driada.experiment.neuron import Neuron, DEFAULT_T_RISE, DEFAULT_T_OFF, DEFAULT_FPS, MIN_CA_SHIFT
  |                                                                             ^^^^^^^^^^^ F401
5 | from driada.information.info_base import TimeSeries
6 | from driada.utils.neural import generate_pseudo_calcium_multisignal
  |
  = help: Remove unused import

tests/unit/experiment/test_neuron.py:8:78: F401 [*] `driada.experiment.wavelet_event_detection.ridges_to_containers` imported but unused
  |
6 | from driada.utils.neural import generate_pseudo_calcium_multisignal
7 | from driada.experiment.wavelet_event_detection import (WVT_EVENT_DETECTION_PARAMS,
8 |                                      extract_wvt_events, events_to_ts_array, ridges_to_containers)
  |                                                                              ^^^^^^^^^^^^^^^^^^^^ F401
  |
  = help: Remove unused import: `driada.experiment.wavelet_event_detection.ridges_to_containers`

tests/unit/experiment/test_spike_reconstruction.py:6:40: F401 [*] `driada.experiment.exp_base.Experiment` imported but unused
  |
4 | import numpy as np
5 | from driada.experiment.synthetic import generate_synthetic_exp
6 | from driada.experiment.exp_base import Experiment, WVT_EVENT_DETECTION_PARAMS
  |                                        ^^^^^^^^^^ F401
7 | from driada.experiment.wavelet_event_detection import extract_wvt_events, events_to_ts_array
8 | from driada.information.info_base import TimeSeries
  |
  = help: Remove unused import: `driada.experiment.exp_base.Experiment`

tests/unit/experiment/test_spike_reconstruction.py:127:16: E712 Avoid equality comparisons to `True`; use `neuron.sp.discrete:` for truth checks
    |
125 |         assert neuron.sp is not None
126 |         assert isinstance(neuron.sp, TimeSeries)
127 |         assert neuron.sp.discrete == True
    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
128 |         
129 |     # Check that spikes are not all zero
    |
    = help: Replace with `neuron.sp.discrete`

tests/unit/experiment/test_spike_reconstruction_refactor.py:7:5: F401 [*] `driada.experiment.spike_reconstruction.wavelet_reconstruction` imported but unused
  |
5 | from driada.experiment.spike_reconstruction import (
6 |     reconstruct_spikes,
7 |     wavelet_reconstruction,
  |     ^^^^^^^^^^^^^^^^^^^^^^ F401
8 |     threshold_reconstruction
9 | )
  |
  = help: Remove unused import

tests/unit/experiment/test_spike_reconstruction_refactor.py:8:5: F401 [*] `driada.experiment.spike_reconstruction.threshold_reconstruction` imported but unused
   |
 6 |     reconstruct_spikes,
 7 |     wavelet_reconstruction,
 8 |     threshold_reconstruction
   |     ^^^^^^^^^^^^^^^^^^^^^^^^ F401
 9 | )
10 | from driada.information.info_base import TimeSeries, MultiTimeSeries
   |
   = help: Remove unused import

tests/unit/experiment/test_spike_reconstruction_refactor.py:38:12: E712 Avoid equality comparisons to `True`; use `spikes.discrete:` for truth checks
   |
37 |     # Check that spikes are discrete
38 |     assert spikes.discrete == True
   |            ^^^^^^^^^^^^^^^^^^^^^^^ E712
   |
   = help: Replace with `spikes.discrete`

tests/unit/experiment/test_wavelet_imports.py:3:8: F401 [*] `pytest` imported but unused
  |
1 | """Import tests for wavelet-related modules in experiment package."""
2 |
3 | import pytest
  |        ^^^^^^ F401
  |
  = help: Remove unused import: `pytest`

tests/unit/gdrive/test_download.py:3:1: F403 `from driada.gdrive.download import *` used; unable to detect undefined names
  |
1 | import os
2 | import pytest
3 | from driada.gdrive.download import *
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F403
4 | import shutil
5 | import requests
  |

tests/unit/gdrive/test_download.py:50:40: F405 `download_part_of_folder` may be undefined, or defined from star imports
   |
48 |     print(TEST_DIR)
49 |
50 |     return_code, filenames, load_log = download_part_of_folder(
   |                                        ^^^^^^^^^^^^^^^^^^^^^^^ F405
51 |                                                 TEST_DIR,  # path for downloaded data
52 |                                                 TEST_LINK,  # share link to google drive folder
   |

tests/unit/gdrive/test_download.py:66:40: F405 `download_part_of_folder` may be undefined, or defined from star imports
   |
64 |     print(TEST_DIR)
65 |
66 |     return_code, filenames, load_log = download_part_of_folder(
   |                                        ^^^^^^^^^^^^^^^^^^^^^^^ F405
67 |                                                 TEST_DIR,  # path for downloaded data
68 |                                                 TEST_LINK,  # share link to google drive folder
   |

tests/unit/gdrive/test_download.py:82:40: F405 `download_part_of_folder` may be undefined, or defined from star imports
   |
80 |     print(TEST_DIR)
81 |
82 |     return_code, filenames, load_log = download_part_of_folder(
   |                                        ^^^^^^^^^^^^^^^^^^^^^^^ F405
83 |                                                 TEST_DIR,  # path for downloaded data
84 |                                                 TEST_LINK,  # share link to google drive folder
   |

tests/unit/gdrive/test_download.py:98:40: F405 `download_part_of_folder` may be undefined, or defined from star imports
    |
 96 |     print(TEST_DIR)
 97 |
 98 |     return_code, filenames, load_log = download_part_of_folder(
    |                                        ^^^^^^^^^^^^^^^^^^^^^^^ F405
 99 |                                                 TEST_DIR,  # path for downloaded data
100 |                                                 TEST_LINK,  # share link to google drive folder
    |

tests/unit/information/test_entropy.py:244:5: F841 Local variable `z` is assigned to but never used
    |
242 |     x = np.array([1, 2, 3])
243 |     y = np.array([1, 2])
244 |     z = np.array([1.0, 2.0, 3.0])
    |     ^ F841
245 |     
246 |     with pytest.raises((ValueError, IndexError)):
    |
    = help: Remove assignment to unused variable `z`

tests/unit/information/test_entropy.py:251:5: F841 Local variable `z_single` is assigned to but never used
    |
249 |     # Test single element arrays
250 |     x_single = np.array([1])
251 |     z_single = np.array([1.5])
    |     ^^^^^^^^ F841
252 |     
253 |     H_x = entropy_d(x_single)
    |
    = help: Remove assignment to unused variable `z_single`

tests/unit/information/test_entropy.py:259:5: F841 Local variable `z_same` is assigned to but never used
    |
257 |     x_same = np.ones(100, dtype=int)
258 |     y_same = np.zeros(100, dtype=int)
259 |     z_same = np.ones(100) * 3.14
    |     ^^^^^^ F841
260 |     
261 |     H_x = entropy_d(x_same)
    |
    = help: Remove assignment to unused variable `z_same`

tests/unit/information/test_entropy.py:305:5: F841 Local variable `z_ind` is assigned to but never used
    |
303 |     x_ind = np.random.randint(0, 2, n)
304 |     y_ind = np.random.randint(0, 2, n)
305 |     z_ind = np.random.randn(n)
    |     ^^^^^ F841
306 |     
307 |     H_x_ind = entropy_d(x_ind)
    |
    = help: Remove assignment to unused variable `z_ind`

tests/unit/information/test_entropy_jit.py:4:8: F401 [*] `pytest` imported but unused
  |
3 | import numpy as np
4 | import pytest
  |        ^^^^^^ F401
5 | from driada.information.entropy_jit import (
6 |     entropy_d_jit,
  |
  = help: Remove unused import: `pytest`

tests/unit/information/test_entropy_jit.py:66:9: F841 Local variable `n` is assigned to but never used
   |
64 |     def test_joint_entropy_dd_jit_independent(self):
65 |         """Test JIT joint entropy with independent variables."""
66 |         n = 100
   |         ^ F841
67 |         x = np.array([0, 1] * 50, dtype=np.float64)
68 |         y = np.array([0, 0, 1, 1] * 25, dtype=np.float64)
   |
   = help: Remove assignment to unused variable `n`

tests/unit/information/test_gcmi.py:51:28: F401 [*] `scipy.stats` imported but unused
   |
49 | )
50 | from driada.information.info_base import TimeSeries, get_mi, conditional_mi, interaction_information
51 | from scipy import stats as scipy_stats
   |                            ^^^^^^^^^^^ F401
   |
   = help: Remove unused import: `scipy.stats`

tests/unit/information/test_gcmi.py:519:13: F841 Local variable `cmi` is assigned to but never used
    |
518 |         with pytest.warns(UserWarning, match="more than 10% repeated values"):
519 |             cmi = gccmi_ccd(x, y, z, 2)
    |             ^^^ F841
520 |
521 |     def test_gccmi_ccd_input_validation(self):
    |
    = help: Remove assignment to unused variable `cmi`

tests/unit/information/test_gcmi.py:916:12: E712 Avoid equality comparisons to `True`; use `gcmi._JIT_AVAILABLE:` for truth checks
    |
914 |     from driada.information import gcmi
915 |     assert hasattr(gcmi, '_JIT_AVAILABLE')
916 |     assert gcmi._JIT_AVAILABLE == True  # Should be available in test environment
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
    |
    = help: Replace with `gcmi._JIT_AVAILABLE`

tests/unit/information/test_info_base_functions.py:690:7: F811 Redefinition of unused `TestGetMultiMI` from line 446
    |
690 | class TestGetMultiMI:
    |       ^^^^^^^^^^^^^^ F811
691 |     """Test get_multi_mi function."""
    |
    = help: Remove definition: `TestGetMultiMI`

tests/unit/information/test_info_base_functions.py:772:7: F811 Redefinition of unused `TestGetTDMI` from line 411
    |
772 | class TestGetTDMI:
    |       ^^^^^^^^^^^ F811
773 |     """Test time-delayed mutual information."""
    |
    = help: Remove definition: `TestGetTDMI`

tests/unit/information/test_info_base_multitimeseries.py:19:16: E712 Avoid equality comparisons to `False`; use `not mts.discrete:` for false checks
   |
18 |         assert mts.data.shape == (5, 100)
19 |         assert mts.discrete == False
   |                ^^^^^^^^^^^^^^^^^^^^^ E712
20 |         assert mts.shape == (5, 100)
21 |         assert mts.n_points == 100  # From MVData
   |
   = help: Replace with `not mts.discrete`

tests/unit/information/test_info_base_multitimeseries.py:36:16: E712 Avoid equality comparisons to `False`; use `not mts.discrete:` for false checks
   |
34 |         assert mts.data.shape == (3, 100)
35 |         assert mts.n_dim == 3
36 |         assert mts.discrete == False
   |                ^^^^^^^^^^^^^^^^^^^^^ E712
37 |     
38 |     def test_init_discrete_data(self):
   |
   = help: Replace with `not mts.discrete`

tests/unit/information/test_info_base_multitimeseries.py:44:16: E712 Avoid equality comparisons to `True`; use `mts.discrete:` for truth checks
   |
42 |         mts = MultiTimeSeries(data, discrete=True)
43 |         
44 |         assert mts.discrete == True
   |                ^^^^^^^^^^^^^^^^^^^^ E712
45 |         assert hasattr(mts, 'int_data')
46 |         assert mts.int_data.shape == (4, 80)
   |
   = help: Replace with `mts.discrete`

tests/unit/information/test_info_base_multitimeseries.py:155:9: F841 Local variable `mts` is assigned to but never used
    |
153 |         # Create binary data
154 |         data = np.random.randint(0, 2, size=(4, 100))
155 |         mts = MultiTimeSeries(data, discrete=True)
    |         ^^^ F841
156 |         
157 |         # Check if components are binary
    |
    = help: Remove assignment to unused variable `mts`

tests/unit/information/test_info_base_multitimeseries.py:162:24: E712 Avoid equality comparisons to `True`; use `ts.is_binary:` for truth checks
    |
160 |             assert hasattr(ts, 'is_binary')
161 |             if len(set(ts.int_data)) == 2:
162 |                 assert ts.is_binary == True
    |                        ^^^^^^^^^^^^^^^^^^^^ E712
163 |     
164 |     def test_continuous_scaling(self):
    |
    = help: Replace with `ts.is_binary`

tests/unit/information/test_info_base_multitimeseries.py:234:13: F841 Local variable `h3` is assigned to but never used
    |
233 |         with pytest.raises(NotImplementedError, match="Joint entropy for 3 discrete variables"):
234 |             h3 = mts3.get_entropy()
    |             ^^ F841
    |
    = help: Remove assignment to unused variable `h3`

tests/unit/information/test_info_base_multitimeseries.py:296:16: E712 Avoid equality comparisons to `False`; use `not filtered.discrete:` for false checks
    |
294 |         assert np.array_equal(filtered.labels, labels)
295 |         assert filtered.data_name == 'test_data'
296 |         assert filtered.discrete == False
    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
297 |         assert filtered.shape == mts.shape
    |
    = help: Replace with `not filtered.discrete`

tests/unit/information/test_info_base_timeseries.py:7:36: F401 [*] `driada.information.ksg.build_tree` imported but unused
  |
5 | import warnings
6 | from driada.information.info_base import TimeSeries
7 | from driada.information.ksg import build_tree
  |                                    ^^^^^^^^^^ F401
8 | from driada.information.gcmi import copnorm
  |
  = help: Remove unused import: `driada.information.ksg.build_tree`

tests/unit/information/test_info_base_timeseries.py:8:37: F401 [*] `driada.information.gcmi.copnorm` imported but unused
  |
6 | from driada.information.info_base import TimeSeries
7 | from driada.information.ksg import build_tree
8 | from driada.information.gcmi import copnorm
  |                                     ^^^^^^^ F401
  |
  = help: Remove unused import: `driada.information.gcmi.copnorm`

tests/unit/information/test_info_base_timeseries.py:21:20: E712 Avoid equality comparisons to `True`; use `TimeSeries.define_ts_type(ts_binary):` for truth checks
   |
19 |             # Binary data
20 |             ts_binary = np.array([0, 1, 0, 1, 1, 0, 0, 1] * 20)
21 |             assert TimeSeries.define_ts_type(ts_binary) == True
   |                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
22 |             
23 |             # Small number of unique values with repetition
   |
   = help: Replace with `TimeSeries.define_ts_type(ts_binary)`

tests/unit/information/test_info_base_timeseries.py:25:20: E712 Avoid equality comparisons to `True`; use `TimeSeries.define_ts_type(ts_discrete):` for truth checks
   |
23 |             # Small number of unique values with repetition
24 |             ts_discrete = np.array([1, 1, 1, 2, 2, 2, 3, 3, 3] * 20)
25 |             assert TimeSeries.define_ts_type(ts_discrete) == True
   |                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
26 |             
27 |             # Integer categorical data with heavy repetition
   |
   = help: Replace with `TimeSeries.define_ts_type(ts_discrete)`

tests/unit/information/test_info_base_timeseries.py:30:20: E712 Avoid equality comparisons to `True`; use `TimeSeries.define_ts_type(ts_categorical):` for truth checks
   |
28 |             np.random.seed(42)
29 |             ts_categorical = np.random.choice([0, 1, 2], size=200, p=[0.5, 0.3, 0.2])
30 |             assert TimeSeries.define_ts_type(ts_categorical) == True
   |                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
31 |     
32 |     def test_define_ts_type_continuous(self):
   |
   = help: Replace with `TimeSeries.define_ts_type(ts_categorical)`

tests/unit/information/test_info_base_timeseries.py:40:20: E712 Avoid equality comparisons to `False`; use `not TimeSeries.define_ts_type(ts_gaussian):` for false checks
   |
38 |             # Gaussian data
39 |             ts_gaussian = np.random.randn(200)
40 |             assert TimeSeries.define_ts_type(ts_gaussian) == False
   |                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
41 |             
42 |             # Uniform continuous
   |
   = help: Replace with `not TimeSeries.define_ts_type(ts_gaussian)`

tests/unit/information/test_info_base_timeseries.py:44:20: E712 Avoid equality comparisons to `False`; use `not TimeSeries.define_ts_type(ts_uniform):` for false checks
   |
42 |             # Uniform continuous
43 |             ts_uniform = np.random.uniform(0, 1, 200)
44 |             assert TimeSeries.define_ts_type(ts_uniform) == False
   |                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
45 |             
46 |             # Use truly continuous data (not linspace which creates timeline)
   |
   = help: Replace with `not TimeSeries.define_ts_type(ts_uniform)`

tests/unit/information/test_info_base_timeseries.py:48:20: E712 Avoid equality comparisons to `False`; use `not TimeSeries.define_ts_type(ts_continuous):` for false checks
   |
46 |             # Use truly continuous data (not linspace which creates timeline)
47 |             ts_continuous = np.random.exponential(2, 200)
48 |             assert TimeSeries.define_ts_type(ts_continuous) == False
   |                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
49 |     
50 |     def test_define_ts_type_short_series_warning(self):
   |
   = help: Replace with `not TimeSeries.define_ts_type(ts_continuous)`

tests/unit/information/test_info_base_timeseries.py:79:20: E712 Avoid equality comparisons to `True`; use `result:` for truth checks
   |
77 |             # This should return True (discrete) because it's timeline-like data
78 |             result = TimeSeries.define_ts_type(ts_timeline_like)
79 |             assert result == True  # Timeline data is discrete
   |                    ^^^^^^^^^^^^^^ E712
80 |         
81 |         # Test with truly ambiguous data (mix of continuous and discrete characteristics)
   |
   = help: Replace with `result`

tests/unit/information/test_info_base_timeseries.py:103:16: E712 Avoid equality comparisons to `False`; use `not ts.discrete:` for false checks
    |
101 |         ts = TimeSeries(data)
102 |         
103 |         assert ts.discrete == False
    |                ^^^^^^^^^^^^^^^^^^^^ E712
104 |         assert ts.data.shape == (200,)
105 |         assert ts.scdata.shape == (200,)
    |
    = help: Replace with `not ts.discrete`

tests/unit/information/test_info_base_timeseries.py:117:16: E712 Avoid equality comparisons to `True`; use `ts.discrete:` for truth checks
    |
115 |         ts = TimeSeries(data)
116 |         
117 |         assert ts.discrete == True
    |                ^^^^^^^^^^^^^^^^^^^ E712
118 |         assert hasattr(ts, 'int_data')
119 |         assert ts.int_data.dtype == np.int64
    |
    = help: Replace with `ts.discrete`

tests/unit/information/test_info_base_timeseries.py:120:16: E712 Avoid equality comparisons to `False`; use `not ts.is_binary:` for false checks
    |
118 |         assert hasattr(ts, 'int_data')
119 |         assert ts.int_data.dtype == np.int64
120 |         assert ts.is_binary == False
    |                ^^^^^^^^^^^^^^^^^^^^^ E712
121 |     
122 |     def test_init_binary_data(self):
    |
    = help: Replace with `not ts.is_binary`

tests/unit/information/test_info_base_timeseries.py:127:16: E712 Avoid equality comparisons to `True`; use `ts.discrete:` for truth checks
    |
125 |         ts = TimeSeries(data, discrete=True)
126 |         
127 |         assert ts.discrete == True
    |                ^^^^^^^^^^^^^^^^^^^ E712
128 |         assert ts.is_binary == True
129 |         assert hasattr(ts, 'bool_data')
    |
    = help: Replace with `ts.discrete`

tests/unit/information/test_info_base_timeseries.py:128:16: E712 Avoid equality comparisons to `True`; use `ts.is_binary:` for truth checks
    |
127 |         assert ts.discrete == True
128 |         assert ts.is_binary == True
    |                ^^^^^^^^^^^^^^^^^^^^ E712
129 |         assert hasattr(ts, 'bool_data')
130 |         assert ts.bool_data.dtype == bool
    |
    = help: Replace with `ts.is_binary`

tests/unit/information/test_info_base_timeseries.py:138:16: E712 Avoid equality comparisons to `False`; use `not ts.discrete:` for false checks
    |
136 |         ts = TimeSeries(data, discrete=False)
137 |         
138 |         assert ts.discrete == False
    |                ^^^^^^^^^^^^^^^^^^^^ E712
139 |         assert ts.copula_normal_data is not None
    |
    = help: Replace with `not ts.discrete`

tests/unit/information/test_info_base_timeseries.py:334:16: E712 Avoid equality comparisons to `True`; use `ts.discrete:` for truth checks
    |
332 |         ts = TimeSeries(data, discrete=True)
333 |         
334 |         assert ts.discrete == True
    |                ^^^^^^^^^^^^^^^^^^^ E712
335 |         assert ts.is_binary == False
336 |         assert hasattr(ts, 'int_data')
    |
    = help: Replace with `ts.discrete`

tests/unit/information/test_info_base_timeseries.py:335:16: E712 Avoid equality comparisons to `False`; use `not ts.is_binary:` for false checks
    |
334 |         assert ts.discrete == True
335 |         assert ts.is_binary == False
    |                ^^^^^^^^^^^^^^^^^^^^^ E712
336 |         assert hasattr(ts, 'int_data')
337 |         assert not hasattr(ts, 'bool_data')
    |
    = help: Replace with `not ts.is_binary`

tests/unit/information/test_info_base_timeseries.py:345:16: E712 Avoid equality comparisons to `True`; use `ts.discrete:` for truth checks
    |
343 |         # Should be detected as discrete
344 |         ts = TimeSeries(data)
345 |         assert ts.discrete == True
    |                ^^^^^^^^^^^^^^^^^^^ E712
346 |         
347 |         # Scaled data should handle constant
    |
    = help: Replace with `ts.discrete`

tests/unit/information/test_info_utils.py:4:8: F401 [*] `pytest` imported but unused
  |
3 | import numpy as np
4 | import pytest
  |        ^^^^^^ F401
5 | from scipy.special import digamma
6 | from driada.information.info_utils import (
  |
  = help: Remove unused import: `pytest`

tests/unit/information/test_ksg.py:189:13: F841 Local variable `tree` is assigned to but never used
    |
187 |         points = np.array([]).reshape(0, 2)
188 |         with pytest.raises((ValueError, IndexError)):
189 |             tree = build_tree(points)
    |             ^^^^ F841
190 |     
191 |     def test_single_point(self):
    |
    = help: Remove assignment to unused variable `tree`

tests/unit/information/test_ksg.py:198:13: F841 Local variable `distances` is assigned to but never used
    |
196 |         # Query neighbors might behave differently
197 |         with pytest.raises((ValueError, IndexError)):
198 |             distances = query_neighbors(tree, points, k=2)
    |             ^^^^^^^^^ F841
199 |     
200 |     def test_duplicate_points(self):
    |
    = help: Remove assignment to unused variable `distances`

tests/unit/information/test_ksg_estimators.py:10:5: F401 [*] `driada.information.ksg._count_neighbors_single` imported but unused
   |
 8 |     nonparam_mi_cc,
 9 |     lnc_correction,
10 |     _count_neighbors_single,
   |     ^^^^^^^^^^^^^^^^^^^^^^^ F401
11 |     build_tree,
12 |     DEFAULT_NN,
   |
   = help: Remove unused import

tests/unit/information/test_ksg_estimators.py:12:5: F401 [*] `driada.information.ksg.DEFAULT_NN` imported but unused
   |
10 |     _count_neighbors_single,
11 |     build_tree,
12 |     DEFAULT_NN,
   |     ^^^^^^^^^^ F401
13 | )
14 | from driada.information.info_utils import py_fast_digamma
   |
   = help: Remove unused import

tests/unit/information/test_time_series_types.py:14:19: F401 [*] `scipy.stats` imported but unused
   |
12 | import numpy as np
13 | import pytest
14 | from scipy import stats
   |                   ^^^^^ F401
15 |
16 | from driada.information.time_series_types import (
   |
   = help: Remove unused import: `scipy.stats`

tests/unit/information/test_time_series_types.py:19:5: F401 [*] `driada.information.time_series_types.TimeSeriesType` imported but unused
   |
17 |     analyze_time_series_type,
18 |     is_discrete_time_series,
19 |     TimeSeriesType,
   |     ^^^^^^^^^^^^^^ F401
20 |     _extract_statistical_properties,
21 |     _detect_circular,
   |
   = help: Remove unused import

tests/unit/information/test_time_series_types.py:23:5: F401 [*] `driada.information.time_series_types._detect_primary_type` imported but unused
   |
21 |     _detect_circular,
22 |     _detect_periodicity,
23 |     _detect_primary_type,
   |     ^^^^^^^^^^^^^^^^^^^^ F401
24 |     _detect_discrete_subtype,
25 |     _detect_continuous_subtype
   |
   = help: Remove unused import

tests/unit/information/test_time_series_types.py:65:9: F841 Local variable `result_small_noise` is assigned to but never used
   |
63 |         # Binary with very small noise (should still be detected as discrete if noise is negligible)
64 |         data_small_noise = data + np.random.normal(0, 0.001, len(data))
65 |         result_small_noise = analyze_time_series_type(data_small_noise)
   |         ^^^^^^^^^^^^^^^^^^ F841
66 |         # With tiny noise, might still detect as discrete
   |
   = help: Remove assignment to unused variable `result_small_noise`

tests/unit/integration/test_selectivity_mapper_coverage.py:9:40: F401 [*] `unittest.mock.MagicMock` imported but unused
  |
7 | import numpy as np
8 | import logging
9 | from unittest.mock import Mock, patch, MagicMock
  |                                        ^^^^^^^^^ F401
  |
  = help: Remove unused import: `unittest.mock.MagicMock`

tests/unit/integration/test_selectivity_mapper_coverage.py:105:13: F841 Local variable `embedding` is assigned to but never used
    |
104 |             # Create embedding with spikes
105 |             embedding = mock_mapper.create_embedding(
    |             ^^^^^^^^^ F841
106 |                 'pca',
107 |                 n_components=3,
    |
    = help: Remove assignment to unused variable `embedding`

tests/unit/integration/test_selectivity_mapper_coverage.py:138:13: F841 Local variable `embedding` is assigned to but never used
    |
137 |             # Create embedding with downsampling
138 |             embedding = mock_mapper.create_embedding(
    |             ^^^^^^^^^ F841
139 |                 'pca',
140 |                 n_components=2,
    |
    = help: Remove assignment to unused variable `embedding`

tests/unit/integration/test_selectivity_mapper_coverage.py:168:13: F841 Local variable `embedding` is assigned to but never used
    |
167 |             # Create embedding with significant neurons selection
168 |             embedding = mock_mapper.create_embedding(
    |             ^^^^^^^^^ F841
169 |                 'pca',
170 |                 n_components=2,
    |
    = help: Remove assignment to unused variable `embedding`

tests/unit/integration/test_selectivity_mapper_coverage.py:205:13: F841 Local variable `embedding` is assigned to but never used
    |
204 |             # Create embedding with various parameters
205 |             embedding = mock_mapper.create_embedding(
    |             ^^^^^^^^^ F841
206 |                 'umap',
207 |                 n_components=2,
    |
    = help: Remove assignment to unused variable `embedding`

tests/unit/intense/conftest.py:15:18: F401 [*] `copy.deepcopy` imported but unused
   |
13 | import pytest
14 | import numpy as np
15 | from copy import deepcopy
   |                  ^^^^^^^^ F401
16 | from driada.information.info_base import TimeSeries, MultiTimeSeries
17 | from driada.utils.data import create_correlated_gaussian_data
   |
   = help: Remove unused import: `copy.deepcopy`

tests/unit/intense/test_disentanglement.py:12:54: F401 [*] `driada.information.info_base.MultiTimeSeries` imported but unused
   |
10 |     DEFAULT_MULTIFEATURE_MAP
11 | )
12 | from driada.information.info_base import TimeSeries, MultiTimeSeries
   |                                                      ^^^^^^^^^^^^^^^ F401
13 | from driada.experiment.synthetic import generate_synthetic_exp
   |
   = help: Remove unused import: `driada.information.info_base.MultiTimeSeries`

tests/unit/intense/test_disentanglement.py:13:41: F401 [*] `driada.experiment.synthetic.generate_synthetic_exp` imported but unused
   |
11 | )
12 | from driada.information.info_base import TimeSeries, MultiTimeSeries
13 | from driada.experiment.synthetic import generate_synthetic_exp
   |                                         ^^^^^^^^^^^^^^^^^^^^^^ F401
   |
   = help: Remove unused import: `driada.experiment.synthetic.generate_synthetic_exp`

tests/unit/intense/test_intense.py:76:5: F841 Local variable `k` is assigned to but never used
   |
74 |     """Test stage1 mode of compute_me_stats."""
75 |     tslist1, tslist2, n = correlated_ts_medium
76 |     k = n // 2
   |     ^ F841
77 |     
78 |     computed_stats, computed_significance, info = compute_me_stats(
   |
   = help: Remove assignment to unused variable `k`

tests/unit/intense/test_intense.py:290:5: F841 Local variable `k` is assigned to but never used
    |
288 |     """Test two-stage mode with average signal metric."""
289 |     tslist1, tslist2, n = correlated_ts_binarized
290 |     k = n // 2  # num of ts in one block
    |     ^ F841
291 |     
292 |     computed_stats, computed_significance, info = compute_me_stats(
    |
    = help: Remove assignment to unused variable `k`

tests/unit/intense/test_intense.py:324:1: E402 Module level import not at top of file
    |
323 | # Additional unit tests for better coverage
324 | import pytest
    | ^^^^^^^^^^^^^ E402
325 | import scipy.stats
326 | from driada.experiment.synthetic import generate_synthetic_exp
    |

tests/unit/intense/test_intense.py:324:8: F811 [*] Redefinition of unused `pytest` from line 7
    |
323 | # Additional unit tests for better coverage
324 | import pytest
    |        ^^^^^^ F811
325 | import scipy.stats
326 | from driada.experiment.synthetic import generate_synthetic_exp
    |
    = help: Remove definition: `pytest`

tests/unit/intense/test_intense.py:325:1: E402 Module level import not at top of file
    |
323 | # Additional unit tests for better coverage
324 | import pytest
325 | import scipy.stats
    | ^^^^^^^^^^^^^^^^^^ E402
326 | from driada.experiment.synthetic import generate_synthetic_exp
327 | from driada.intense.intense_base import (
    |

tests/unit/intense/test_intense.py:326:1: E402 Module level import not at top of file
    |
324 | import pytest
325 | import scipy.stats
326 | from driada.experiment.synthetic import generate_synthetic_exp
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
327 | from driada.intense.intense_base import (
328 |     validate_time_series_bunches,
    |

tests/unit/intense/test_intense.py:326:41: F401 [*] `driada.experiment.synthetic.generate_synthetic_exp` imported but unused
    |
324 | import pytest
325 | import scipy.stats
326 | from driada.experiment.synthetic import generate_synthetic_exp
    |                                         ^^^^^^^^^^^^^^^^^^^^^^ F401
327 | from driada.intense.intense_base import (
328 |     validate_time_series_bunches,
    |
    = help: Remove unused import: `driada.experiment.synthetic.generate_synthetic_exp`

tests/unit/intense/test_intense.py:327:1: E402 Module level import not at top of file
    |
325 |   import scipy.stats
326 |   from driada.experiment.synthetic import generate_synthetic_exp
327 | / from driada.intense.intense_base import (
328 | |     validate_time_series_bunches,
329 | |     validate_metric,
330 | |     validate_common_parameters,
331 | |     get_multicomp_correction_thr,
332 | |     IntenseResults,
333 | |     calculate_optimal_delays,
334 | |     scan_pairs,
335 | |     scan_pairs_router,
336 | | )
    | |_^ E402
337 |   from driada.intense.stats import (
338 |       chebyshev_ineq,
    |

tests/unit/intense/test_intense.py:337:1: E402 Module level import not at top of file
    |
335 |       scan_pairs_router,
336 |   )
337 | / from driada.intense.stats import (
338 | |     chebyshev_ineq,
339 | |     get_lognormal_p,
340 | |     get_gamma_p,
341 | |     get_distribution_function,
342 | |     get_mi_distr_pvalue,
343 | |     get_mask,
344 | |     stats_not_empty,
345 | |     criterion1,
346 | |     criterion2,
347 | |     get_all_nonempty_pvals,
348 | |     get_table_of_stats,
349 | |     merge_stage_stats,
350 | |     merge_stage_significance,
351 | | )
    | |_^ E402
    |

tests/unit/intense/test_intense.py:473:12: E712 Avoid equality comparisons to `True`; use `results.significance['cell1']['feat1']:` for truth checks
    |
471 |     assert 'cell1' in results.stats
472 |     assert results.stats['cell1']['feat1']['pval'] == 0.01
473 |     assert results.significance['cell1']['feat1'] == True
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
    |
    = help: Replace with `results.significance['cell1']['feat1']`

tests/unit/intense/test_intense.py:551:29: F401 [*] `scipy.stats.rankdata` imported but unused
    |
549 | def test_get_table_of_stats():
550 |     """Test conversion of metric table to statistics."""
551 |     from scipy.stats import rankdata
    |                             ^^^^^^^^ F401
552 |     # Create synthetic metric table (3 pairs, 2x2 matrix, 100 shuffles)
553 |     n1, n2, nsh = 2, 2, 100
    |
    = help: Remove unused import: `scipy.stats.rankdata`

tests/unit/intense/test_intense.py:622:12: E712 Avoid equality comparisons to `True`; use `merged[0][0]['stage1']:` for truth checks
    |
620 |     merged = merge_stage_significance(stage1_sig, stage2_sig)
621 |     
622 |     assert merged[0][0]['stage1'] == True
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
623 |     assert merged[0][0]['stage2'] == True
624 |     assert merged[1][0]['stage1'] == False
    |
    = help: Replace with `merged[0][0]['stage1']`

tests/unit/intense/test_intense.py:623:12: E712 Avoid equality comparisons to `True`; use `merged[0][0]['stage2']:` for truth checks
    |
622 |     assert merged[0][0]['stage1'] == True
623 |     assert merged[0][0]['stage2'] == True
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
624 |     assert merged[1][0]['stage1'] == False
625 |     assert merged[1][0]['stage2'] == False
    |
    = help: Replace with `merged[0][0]['stage2']`

tests/unit/intense/test_intense.py:624:12: E712 Avoid equality comparisons to `False`; use `not merged[1][0]['stage1']:` for false checks
    |
622 |     assert merged[0][0]['stage1'] == True
623 |     assert merged[0][0]['stage2'] == True
624 |     assert merged[1][0]['stage1'] == False
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
625 |     assert merged[1][0]['stage2'] == False
    |
    = help: Replace with `not merged[1][0]['stage1']`

tests/unit/intense/test_intense.py:625:12: E712 Avoid equality comparisons to `False`; use `not merged[1][0]['stage2']:` for false checks
    |
623 |     assert merged[0][0]['stage2'] == True
624 |     assert merged[1][0]['stage1'] == False
625 |     assert merged[1][0]['stage2'] == False
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
    |
    = help: Replace with `not merged[1][0]['stage2']`

tests/unit/intense/test_intense.py:787:1: E402 Module level import not at top of file
    |
786 | # Integration tests for pipelines
787 | from driada.intense.pipelines import compute_cell_feat_significance
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
    |

tests/unit/intense/test_intense.py:787:38: F811 [*] Redefinition of unused `compute_cell_feat_significance` from line 4
    |
786 | # Integration tests for pipelines
787 | from driada.intense.pipelines import compute_cell_feat_significance
    |                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F811
    |
    = help: Remove definition: `compute_cell_feat_significance`

tests/unit/intense/test_intense.py:1074:16: E712 Avoid equality comparisons to `True`; use `computed_significance[i][j]['stage1']:` for truth checks
     |
1072 |     for pair in sig_pairs:
1073 |         i, j = pair
1074 |         assert computed_significance[i][j]['stage1'] == True
     |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
     |
     = help: Replace with `computed_significance[i][j]['stage1']`

tests/unit/intense/test_intense_pipelines_optimized.py:23:5: F401 [*] `driada.experiment.synthetic.generate_synthetic_exp_with_mixed_selectivity` imported but unused
   |
21 | from driada.experiment.synthetic import (
22 |     generate_synthetic_exp,
23 |     generate_synthetic_exp_with_mixed_selectivity,
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F401
24 |     generate_multiselectivity_patterns,
25 |     discretize_via_roi
   |
   = help: Remove unused import

tests/unit/intense/test_intense_pipelines_optimized.py:24:5: F401 [*] `driada.experiment.synthetic.generate_multiselectivity_patterns` imported but unused
   |
22 |     generate_synthetic_exp,
23 |     generate_synthetic_exp_with_mixed_selectivity,
24 |     generate_multiselectivity_patterns,
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F401
25 |     discretize_via_roi
26 | )
   |
   = help: Remove unused import

tests/unit/intense/test_intense_pipelines_optimized.py:25:5: F401 [*] `driada.experiment.synthetic.discretize_via_roi` imported but unused
   |
23 |     generate_synthetic_exp_with_mixed_selectivity,
24 |     generate_multiselectivity_patterns,
25 |     discretize_via_roi
   |     ^^^^^^^^^^^^^^^^^^ F401
26 | )
   |
   = help: Remove unused import

tests/unit/intense/test_intense_pipelines_optimized.py:42:45: F811 [*] Redefinition of unused `generate_synthetic_exp_with_mixed_selectivity` from line 23
   |
40 |     """Fast test for cell-feat significance with disentanglement."""
41 |     # Use the proper mixed selectivity generator instead of small_experiment
42 |     from driada.experiment.synthetic import generate_synthetic_exp_with_mixed_selectivity
   |                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F811
43 |     
44 |     # Generate experiment with guaranteed mixed selectivity
   |
   = help: Remove definition: `generate_synthetic_exp_with_mixed_selectivity`

tests/unit/intense/test_intense_pipelines_optimized.py:108:15: F541 [*] f-string without any placeholders
    |
106 |     # For debugging - print what we got
107 |     if not summary.get('overall_stats'):
108 |         print(f"WARNING: No mixed selectivity pairs found!")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
109 |         print(f"Used neurons: {cell_bunch}")
110 |         print(f"Selectivity matrix shape: {selectivity_matrix.shape}")
    |
    = help: Remove extraneous `f` prefix

tests/unit/intense/test_intense_pipelines_optimized.py:189:45: F811 [*] Redefinition of unused `generate_synthetic_exp_with_mixed_selectivity` from line 23
    |
187 |     """Fast test for mixed selectivity pattern generation."""
188 |     # Minimal generation - check the actual API
189 |     from driada.experiment.synthetic import generate_synthetic_exp_with_mixed_selectivity
    |                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F811
190 |     
191 |     # Generate minimal mixed selectivity experiment
    |
    = help: Remove definition: `generate_synthetic_exp_with_mixed_selectivity`

tests/unit/intense/test_intense_pipelines_optimized.py:560:45: F811 [*] Redefinition of unused `generate_synthetic_exp_with_mixed_selectivity` from line 23
    |
558 | def test_disentanglement_with_asymmetric_features():
559 |     """Test disentanglement with asymmetric feature relationships (discrete from continuous)."""
560 |     from driada.experiment.synthetic import generate_synthetic_exp_with_mixed_selectivity
    |                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F811
561 |     
562 |     # Generate experiment with continuous features and their discrete versions
    |
    = help: Remove definition: `generate_synthetic_exp_with_mixed_selectivity`

tests/unit/intense/test_stats.py:201:12: E712 Avoid equality comparisons to `True`; use `stats_not_empty(pair_stats, 'abc123', stage=1):` for truth checks
    |
199 |         'me': 0.5
200 |     }
201 |     assert stats_not_empty(pair_stats, 'abc123', stage=1) == True
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
202 |     
203 |     # Test 2: Invalid hash
    |
    = help: Replace with `stats_not_empty(pair_stats, 'abc123', stage=1)`

tests/unit/intense/test_stats.py:204:12: E712 Avoid equality comparisons to `False`; use `not stats_not_empty(pair_stats, 'wrong_hash', stage=1):` for false checks
    |
203 |     # Test 2: Invalid hash
204 |     assert stats_not_empty(pair_stats, 'wrong_hash', stage=1) == False
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
205 |     
206 |     # Test 3: Missing stage 1 stats
    |
    = help: Replace with `not stats_not_empty(pair_stats, 'wrong_hash', stage=1)`

tests/unit/intense/test_stats.py:212:12: E712 Avoid equality comparisons to `False`; use `not ...:` for false checks
    |
210 |         'pre_pval': 0.01
211 |     }
212 |     assert stats_not_empty(pair_stats_incomplete, 'abc123', stage=1) == False
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
213 |     
214 |     # Test 4: Valid stage 2 stats
    |
    = help: Replace comparison

tests/unit/intense/test_stats.py:221:12: E712 Avoid equality comparisons to `True`; use `...:` for truth checks
    |
219 |         'me': 0.7
220 |     }
221 |     assert stats_not_empty(pair_stats_stage2, 'abc123', stage=2) == True
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
222 |     
223 |     # Test 5: Invalid stage
    |
    = help: Replace comparison

tests/unit/intense/test_stats.py:232:12: E712 Avoid equality comparisons to `True`; use `criterion1(pair_stats, nsh1=100, topk=1):` for truth checks
    |
230 |     # Test 1: Passes criterion (top-1)
231 |     pair_stats = {'pre_rval': 1.0}
232 |     assert criterion1(pair_stats, nsh1=100, topk=1) == True
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
233 |     
234 |     # Test 2: Passes with topk=5
    |
    = help: Replace with `criterion1(pair_stats, nsh1=100, topk=1)`

tests/unit/intense/test_stats.py:236:12: E712 Avoid equality comparisons to `True`; use `criterion1(pair_stats, nsh1=100, topk=5):` for truth checks
    |
234 |     # Test 2: Passes with topk=5
235 |     pair_stats = {'pre_rval': 0.96}  # In top 5 of 100
236 |     assert criterion1(pair_stats, nsh1=100, topk=5) == True
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
237 |     
238 |     # Test 3: Fails criterion
    |
    = help: Replace with `criterion1(pair_stats, nsh1=100, topk=5)`

tests/unit/intense/test_stats.py:240:12: E712 Avoid equality comparisons to `False`; use `not criterion1(pair_stats, nsh1=100, topk=1):` for false checks
    |
238 |     # Test 3: Fails criterion
239 |     pair_stats = {'pre_rval': 0.9}
240 |     assert criterion1(pair_stats, nsh1=100, topk=1) == False
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
241 |     
242 |     # Test 4: Missing pre_rval
    |
    = help: Replace with `not criterion1(pair_stats, nsh1=100, topk=1)`

tests/unit/intense/test_stats.py:244:12: E712 Avoid equality comparisons to `False`; use `not criterion1(pair_stats, nsh1=100):` for false checks
    |
242 |     # Test 4: Missing pre_rval
243 |     pair_stats = {}
244 |     assert criterion1(pair_stats, nsh1=100) == False
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
245 |     
246 |     # Test 5: None pre_rval
    |
    = help: Replace with `not criterion1(pair_stats, nsh1=100)`

tests/unit/intense/test_stats.py:248:12: E712 Avoid equality comparisons to `False`; use `not criterion1(pair_stats, nsh1=100):` for false checks
    |
246 |     # Test 5: None pre_rval
247 |     pair_stats = {'pre_rval': None}
248 |     assert criterion1(pair_stats, nsh1=100) == False
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
    |
    = help: Replace with `not criterion1(pair_stats, nsh1=100)`

tests/unit/intense/test_stats.py:258:12: E712 Avoid equality comparisons to `True`; use `...:` for truth checks
    |
256 |         'pval': 0.0001  # < 0.01
257 |     }
258 |     assert criterion2(pair_stats, nsh2=1000, pval_thr=0.01, topk=5) == True
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
259 |     
260 |     # Test 2: Fails rank criterion
    |
    = help: Replace comparison

tests/unit/intense/test_stats.py:265:12: E712 Avoid equality comparisons to `False`; use `not ...:` for false checks
    |
263 |         'pval': 0.0001
264 |     }
265 |     assert criterion2(pair_stats, nsh2=1000, pval_thr=0.01, topk=5) == False
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
266 |     
267 |     # Test 3: Fails p-value criterion
    |
    = help: Replace comparison

tests/unit/intense/test_stats.py:272:12: E712 Avoid equality comparisons to `False`; use `not ...:` for false checks
    |
270 |         'pval': 0.02  # > 0.01
271 |     }
272 |     assert criterion2(pair_stats, nsh2=1000, pval_thr=0.01, topk=5) == False
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
273 |     
274 |     # Test 4: Missing values
    |
    = help: Replace comparison

tests/unit/intense/test_stats.py:276:12: E712 Avoid equality comparisons to `False`; use `not criterion2(pair_stats, nsh2=1000, pval_thr=0.01):` for false checks
    |
274 |     # Test 4: Missing values
275 |     pair_stats = {'rval': 0.999}  # Missing pval
276 |     assert criterion2(pair_stats, nsh2=1000, pval_thr=0.01) == False
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
277 |     
278 |     # Test 5: None values
    |
    = help: Replace with `not criterion2(pair_stats, nsh2=1000, pval_thr=0.01)`

tests/unit/intense/test_stats.py:280:12: E712 Avoid equality comparisons to `False`; use `not criterion2(pair_stats, nsh2=1000, pval_thr=0.01):` for false checks
    |
278 |     # Test 5: None values
279 |     pair_stats = {'rval': None, 'pval': None}
280 |     assert criterion2(pair_stats, nsh2=1000, pval_thr=0.01) == False
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
    |
    = help: Replace with `not criterion2(pair_stats, nsh2=1000, pval_thr=0.01)`

tests/unit/intense/test_stats.py:456:12: E712 Avoid equality comparisons to `True`; use `merged[0][0]['stage1_passed']:` for truth checks
    |
455 |     # Check merge
456 |     assert merged[0][0]['stage1_passed'] == True
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
457 |     assert merged[0][0]['stage2_passed'] == True
458 |     assert merged[0][0]['stage1_pval'] == 0.01
    |
    = help: Replace with `merged[0][0]['stage1_passed']`

tests/unit/intense/test_stats.py:457:12: E712 Avoid equality comparisons to `True`; use `merged[0][0]['stage2_passed']:` for truth checks
    |
455 |     # Check merge
456 |     assert merged[0][0]['stage1_passed'] == True
457 |     assert merged[0][0]['stage2_passed'] == True
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
458 |     assert merged[0][0]['stage1_pval'] == 0.01
459 |     assert merged[0][0]['final_pval'] == 0.001
    |
    = help: Replace with `merged[0][0]['stage2_passed']`

tests/unit/intense/test_stats.py:468:12: E712 Avoid equality comparisons to `True`; use `merged[0][0]['stage2_passed']:` for truth checks
    |
466 |     merged = merge_stage_significance(stage1_empty, stage2_sig)
467 |     
468 |     assert merged[0][0]['stage2_passed'] == True
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
469 |     assert merged[0][0]['final_pval'] == 0.001
    |
    = help: Replace with `merged[0][0]['stage2_passed']`

tests/unit/network/test_network.py:16:5: F401 [*] `driada.network.net_base.MATRIX_TYPES` imported but unused
   |
14 |     UNDIR_MATRIX_TYPES,
15 |     DIR_MATRIX_TYPES,
16 |     MATRIX_TYPES
   |     ^^^^^^^^^^^^ F401
17 | )
18 | from driada.network.graph_utils import get_giant_scc_from_graph
   |
   = help: Remove unused import: `driada.network.net_base.MATRIX_TYPES`

tests/unit/network/test_network.py:387:13: F841 Local variable `net` is assigned to but never used
    |
385 |         A = sp.csr_matrix([[0, 1, 1], [1, 0, 1], [1, 1, 0]])
386 |         with patch('builtins.print') as mock_print:
387 |             net = Network(adj=A, preprocessing=None, verbose=True, create_nx_graph=False)
    |             ^^^ F841
388 |             mock_print.assert_called_with('No preprocessing specified, this may lead to unexpected errors in graph connectivity!')
    |
    = help: Remove assignment to unused variable `net`

tests/unit/network/test_network.py:401:16: E712 Avoid equality comparisons to `False`; use `not net_undir.directed:` for false checks
    |
399 |         A_sym = sp.csr_matrix([[0, 1, 1], [1, 0, 1], [1, 1, 0]])
400 |         net_undir = Network(adj=A_sym)
401 |         assert net_undir.directed == False
    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
402 |         
403 |         # Asymmetric matrix -> directed
    |
    = help: Replace with `not net_undir.directed`

tests/unit/network/test_network.py:410:16: E712 Avoid equality comparisons to `True`; use `net_dir.directed:` for truth checks
    |
408 |                                 [0, 0, 0, 0]])
409 |         net_dir = Network(adj=A_asym)
410 |         assert net_dir.directed == True
    |                ^^^^^^^^^^^^^^^^^^^^^^^^ E712
411 |     
412 |     def test_weighted_detection(self):
    |
    = help: Replace with `net_dir.directed`

tests/unit/network/test_network.py:417:16: E712 Avoid equality comparisons to `False`; use `not net_unweighted.weighted:` for false checks
    |
415 |         A_binary = sp.csr_matrix([[0, 1, 1], [1, 0, 1], [1, 1, 0]])
416 |         net_unweighted = Network(adj=A_binary)
417 |         assert net_unweighted.weighted == False
    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
418 |         
419 |         # Non-binary matrix -> weighted
    |
    = help: Replace with `not net_unweighted.weighted`

tests/unit/network/test_network.py:422:16: E712 Avoid equality comparisons to `True`; use `net_weighted.weighted:` for truth checks
    |
420 |         A_weighted = sp.csr_matrix([[0, 2.5, 1.5], [2.5, 0, 3.0], [1.5, 3.0, 0]])
421 |         net_weighted = Network(adj=A_weighted)
422 |         assert net_weighted.weighted == True
    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
    |
    = help: Replace with `net_weighted.weighted`

tests/unit/network/test_network.py:496:16: E712 Avoid equality comparisons to `False`; use `not rand_shuffle.real_world:` for false checks
    |
494 |         assert isinstance(rand_shuffle, Network)
495 |         assert rand_shuffle.n == simple_network.n
496 |         assert rand_shuffle.real_world == False
    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
497 |         
498 |         # Test complete mode - skip if not complete graph
    |
    = help: Replace with `not rand_shuffle.real_world`

tests/unit/network/test_network.py:583:41: F841 Local variable `mock_print` is assigned to but never used
    |
582 |         # Test with repeated eigenvalues warning
583 |         with patch('builtins.print') as mock_print:
    |                                         ^^^^^^^^^^ F841
584 |             simple_network.verbose = True
585 |             simple_network.lap_zvalues = None  # Clear cache
    |
    = help: Remove assignment to unused variable `mock_print`

tests/unit/network/test_network.py:822:16: E712 Avoid equality comparisons to `True`; use `net.directed:` for truth checks
    |
821 |         net = Network(graph=G)
822 |         assert net.directed == True
    |                ^^^^^^^^^^^^^^^^^^^^ E712
823 |         assert net.n == 4
    |
    = help: Replace with `net.directed`

tests/unit/network/test_network.py:831:16: E712 Avoid equality comparisons to `True`; use `net.weighted:` for truth checks
    |
830 |         net = Network(graph=G)
831 |         assert net.weighted == True
    |                ^^^^^^^^^^^^^^^^^^^^ E712
832 |         assert net.n == 3
    |
    = help: Replace with `net.weighted`

tests/unit/network/test_network.py:859:13: F841 Local variable `net` is assigned to but never used
    |
858 |         with patch('builtins.print') as mock_print:
859 |             net = Network(graph=G, preprocessing='remove_isolates', verbose=True)
    |             ^^^ F841
860 |             
861 |             # Check that verbose message about removed nodes/edges was printed
    |
    = help: Remove assignment to unused variable `net`

tests/unit/network/test_randomization.py:23:41: F401 [*] `driada.network.matrix_utils.symmetric_component` imported but unused
   |
21 |     random_rewiring_IOM_preserving  # Testing deprecation
22 | )
23 | from driada.network.matrix_utils import symmetric_component, non_symmetric_component
   |                                         ^^^^^^^^^^^^^^^^^^^ F401
24 | from .graph_fixtures import (
25 |     create_standard_graph,
   |
   = help: Remove unused import

tests/unit/network/test_randomization.py:23:62: F401 [*] `driada.network.matrix_utils.non_symmetric_component` imported but unused
   |
21 |     random_rewiring_IOM_preserving  # Testing deprecation
22 | )
23 | from driada.network.matrix_utils import symmetric_component, non_symmetric_component
   |                                                              ^^^^^^^^^^^^^^^^^^^^^^^ F401
24 | from .graph_fixtures import (
25 |     create_standard_graph,
   |
   = help: Remove unused import

tests/unit/network/test_randomization.py:28:5: F401 [*] `.graph_fixtures.create_bipartite_graph` imported but unused
   |
26 |     create_complete_graph,
27 |     create_dense_graph,
28 |     create_bipartite_graph,
   |     ^^^^^^^^^^^^^^^^^^^^^^ F401
29 |     create_small_test_graph,
30 |     create_networkx_graph
   |
   = help: Remove unused import

tests/unit/network/test_randomization.py:29:5: F401 [*] `.graph_fixtures.create_small_test_graph` imported but unused
   |
27 |     create_dense_graph,
28 |     create_bipartite_graph,
29 |     create_small_test_graph,
   |     ^^^^^^^^^^^^^^^^^^^^^^^ F401
30 |     create_networkx_graph
31 | )
   |
   = help: Remove unused import

tests/unit/network/test_randomization.py:320:13: F841 Local variable `result` is assigned to but never used
    |
319 |         with caplog.at_level(logging.DEBUG):
320 |             result = random_rewiring_dense_graph(
    |             ^^^^^^ F841
321 |                 dense_graph,
322 |                 logger=logger,
    |
    = help: Remove assignment to unused variable `result`

tests/unit/test_api_imports.py:3:8: F401 [*] `pytest` imported but unused
  |
1 | """Test public API imports for DRIADA package."""
2 |
3 | import pytest
  |        ^^^^^^ F401
  |
  = help: Remove unused import: `pytest`

tests/unit/test_api_imports.py:121:12: F401 [*] `driada.dimensionality` imported but unused
    |
119 |     """Test dimensionality reduction module imports."""
120 |     import driada.dim_reduction
121 |     import driada.dimensionality
    |            ^^^^^^^^^^^^^^^^^^^^^ F401
122 |     
123 |     # Check DR methods are available
    |
    = help: Remove unused import: `driada.dimensionality`

tests/unit/test_api_imports.py:149:12: F401 [*] `driada.integration` imported but unused
    |
147 | def test_integration_module_imports():
148 |     """Test integration module imports."""
149 |     import driada.integration
    |            ^^^^^^^^^^^^^^^^^^ F401
150 |     
151 |     # Check SelectivityManifoldMapper
    |
    = help: Remove unused import: `driada.integration`

tests/unit/utils/test_correlation_matrix.py:3:8: F401 [*] `pytest` imported but unused
  |
1 | """Tests for correlation_matrix function."""
2 |
3 | import pytest
  |        ^^^^^^ F401
4 | import numpy as np
5 | from driada.utils.data import correlation_matrix
  |
  = help: Remove unused import: `pytest`

tests/unit/utils/test_gif.py:5:8: F401 [*] `shutil` imported but unused
  |
3 | import os
4 | import tempfile
5 | import shutil
  |        ^^^^^^ F401
6 | import pytest
7 | import matplotlib.pyplot as plt
  |
  = help: Remove unused import: `shutil`

tests/unit/utils/test_gif.py:6:8: F401 [*] `pytest` imported but unused
  |
4 | import tempfile
5 | import shutil
6 | import pytest
  |        ^^^^^^ F401
7 | import matplotlib.pyplot as plt
8 | import numpy as np
  |
  = help: Remove unused import: `pytest`

tests/unit/utils/test_gif.py:241:13: F841 Local variable `gif_path` is assigned to but never used
    |
239 |         with tempfile.TemporaryDirectory() as tmpdir:
240 |             # Create GIF with no matching images
241 |             gif_path = create_gif_from_image_series(
    |             ^^^^^^^^ F841
242 |                 tmpdir,
243 |                 signature='nonexistent',
    |
    = help: Remove assignment to unused variable `gif_path`

tests/unit/utils/test_matrix.py:4:8: F401 [*] `pytest` imported but unused
  |
3 | import numpy as np
4 | import pytest
  |        ^^^^^^ F401
5 | from numpy import linalg as la
6 | from driada.utils.matrix import nearestPD, is_positive_definite
  |
  = help: Remove unused import: `pytest`

tests/unit/utils/test_matrix.py:22:9: E741 Ambiguous variable name: `I`
   |
20 |     def test_identity_matrix(self):
21 |         """Test with identity matrix (always positive definite)."""
22 |         I = np.eye(5)
   |         ^ E741
23 |         assert is_positive_definite(I) is True
   |

tests/unit/utils/test_output.py:3:8: F401 [*] `pytest` imported but unused
  |
1 | """Tests for output utilities."""
2 |
3 | import pytest
  |        ^^^^^^ F401
4 | import sys
5 | from io import StringIO
  |
  = help: Remove unused import: `pytest`

tests/unit/utils/test_output.py:5:16: F401 [*] `io.StringIO` imported but unused
  |
3 | import pytest
4 | import sys
5 | from io import StringIO
  |                ^^^^^^^^ F401
6 | from driada.utils.output import Capturing, show_output
  |
  = help: Remove unused import: `io.StringIO`

tests/unit/utils/test_output.py:46:29: F841 Local variable `output` is assigned to but never used
   |
44 |         original_stdout = sys.stdout
45 |         
46 |         with Capturing() as output:
   |                             ^^^^^^ F841
47 |             print("Captured")
   |
   = help: Remove assignment to unused variable `output`

tests/unit/utils/test_plot.py:3:8: F401 [*] `pytest` imported but unused
  |
1 | """Tests for plotting utilities."""
2 |
3 | import pytest
  |        ^^^^^^ F401
4 | import numpy as np
5 | import matplotlib.pyplot as plt
  |
  = help: Remove unused import: `pytest`

tests/unit/utils/test_plot.py:25:16: E712 Avoid equality comparisons to `True`; use `tick_params['tick1On']:` for truth checks
   |
23 |         # Check tick parameters
24 |         tick_params = ax.xaxis._major_tick_kw
25 |         assert tick_params['tick1On'] == True  # 'in' direction
   |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
26 |         
27 |         # Check that same axis is returned
   |
   = help: Replace with `tick_params['tick1On']`

tests/unit/utils/test_plot.py:81:9: F841 Local variable `original_dpi` is assigned to but never used
   |
79 |         """Test DPI setting."""
80 |         fig, ax = plt.subplots()
81 |         original_dpi = fig.get_dpi()
   |         ^^^^^^^^^^^^ F841
82 |         
83 |         make_beautiful(ax, dpi=150)
   |
   = help: Remove assignment to unused variable `original_dpi`

tests/unit/utils/test_spatial.py:7:34: F401 [*] `unittest.mock.MagicMock` imported but unused
  |
5 | import pytest
6 | import numpy as np
7 | from unittest.mock import patch, MagicMock
  |                                  ^^^^^^^^^ F401
8 |
9 | from driada.utils.spatial import (
  |
  = help: Remove unused import: `unittest.mock.MagicMock`

tests/unit/utils/test_spatial.py:370:13: F841 Local variable `metrics` is assigned to but never used
    |
369 |         with patch.object(logger, 'info') as mock_info:
370 |             metrics = compute_spatial_decoding_accuracy(
    |             ^^^^^^^ F841
371 |                 neural_activity,
372 |                 positions,
    |
    = help: Remove assignment to unused variable `metrics`

tests/unit/utils/test_spatial.py:674:13: F841 Local variable `results` is assigned to but never used
    |
673 |         with patch.object(logger, 'info') as mock_info:
674 |             results = analyze_spatial_coding(
    |             ^^^^^^^ F841
675 |                 neural_activity,
676 |                 positions,
    |
    = help: Remove assignment to unused variable `results`

tests/unit/visualization/conftest.py:8:27: F401 [*] `unittest.mock.Mock` imported but unused
   |
 6 | matplotlib.use('Agg')  # Non-interactive backend
 7 | import matplotlib.pyplot as plt
 8 | from unittest.mock import Mock, MagicMock, patch
   |                           ^^^^ F401
 9 |
10 | # Disable interactive mode globally
   |
   = help: Remove unused import: `unittest.mock.Mock`

tests/unit/visualization/conftest.py:18:45: F841 Local variable `mock_show` is assigned to but never used
   |
16 |     with patch('matplotlib.pyplot.figure') as mock_figure, \
17 |          patch('matplotlib.pyplot.subplots') as mock_subplots, \
18 |          patch('matplotlib.pyplot.show') as mock_show, \
   |                                             ^^^^^^^^^ F841
19 |          patch('matplotlib.pyplot.savefig') as mock_savefig:
   |
   = help: Remove assignment to unused variable `mock_show`

tests/unit/visualization/conftest.py:19:48: F841 Local variable `mock_savefig` is assigned to but never used
   |
17 |          patch('matplotlib.pyplot.subplots') as mock_subplots, \
18 |          patch('matplotlib.pyplot.show') as mock_show, \
19 |          patch('matplotlib.pyplot.savefig') as mock_savefig:
   |                                                ^^^^^^^^^^^^ F841
20 |         
21 |         # Create mock figure and axes
   |
   = help: Remove assignment to unused variable `mock_savefig`

tests/unit/visualization/test_visual_complete_mocked.py:5:27: F401 [*] `unittest.mock.Mock` imported but unused
  |
3 | import numpy as np
4 | import pytest
5 | from unittest.mock import Mock, patch, MagicMock, call
  |                           ^^^^ F401
6 | from types import SimpleNamespace
  |
  = help: Remove unused import

tests/unit/visualization/test_visual_complete_mocked.py:5:51: F401 [*] `unittest.mock.call` imported but unused
  |
3 | import numpy as np
4 | import pytest
5 | from unittest.mock import Mock, patch, MagicMock, call
  |                                                   ^^^^ F401
6 | from types import SimpleNamespace
  |
  = help: Remove unused import

tests/unit/visualization/test_visual_utils.py:21:18: F401 [*] `pandas` imported but unused
   |
19 |     DEFAULT_DPI
20 | )
21 | import pandas as pd
   |                  ^^ F401
22 | import tempfile
23 | import os
   |
   = help: Remove unused import: `pandas`

tests/unit/visualization/test_visual_utils.py:99:13: F841 Local variable `fig3` is assigned to but never used
    |
 97 |         # Test with save path
 98 |         with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp:
 99 |             fig3 = plot_embedding_comparison(
    |             ^^^^ F841
100 |                 embeddings=embeddings,
101 |                 features=features,
    |
    = help: Remove assignment to unused variable `fig3`

tools/batch_coverage_runner.py:22:32: F401 [*] `typing.Tuple` imported but unused
   |
20 | import re
21 | from pathlib import Path
22 | from typing import Dict, List, Tuple, Optional
   |                                ^^^^^ F401
23 | import tempfile
24 | import shutil
   |
   = help: Remove unused import: `typing.Tuple`

tools/batch_coverage_runner.py:24:8: F401 [*] `shutil` imported but unused
   |
22 | from typing import Dict, List, Tuple, Optional
23 | import tempfile
24 | import shutil
   |        ^^^^^^ F401
25 | from collections import defaultdict
   |
   = help: Remove unused import: `shutil`

tools/batch_coverage_runner.py:25:25: F401 [*] `collections.defaultdict` imported but unused
   |
23 | import tempfile
24 | import shutil
25 | from collections import defaultdict
   |                         ^^^^^^^^^^^ F401
   |
   = help: Remove unused import: `collections.defaultdict`

tools/compare_mi_testing_approaches.py:10:8: F401 [*] `os` imported but unused
   |
 9 | import sys
10 | import os
   |        ^^ F401
11 | import numpy as np
12 | import matplotlib.pyplot as plt
   |
   = help: Remove unused import: `os`

tools/compare_mi_testing_approaches.py:22:5: F401 [*] `driada.intense.improved_mi_testing.empirical_p_value` imported but unused
   |
20 |     compare_testing_methods, 
21 |     ImprovedMITesting,
22 |     empirical_p_value
   |     ^^^^^^^^^^^^^^^^^ F401
23 | )
24 | from driada.intense.stats import get_mi_distr_pvalue
   |
   = help: Remove unused import: `driada.intense.improved_mi_testing.empirical_p_value`

tools/compare_mi_testing_approaches.py:24:34: F401 [*] `driada.intense.stats.get_mi_distr_pvalue` imported but unused
   |
22 |     empirical_p_value
23 | )
24 | from driada.intense.stats import get_mi_distr_pvalue
   |                                  ^^^^^^^^^^^^^^^^^^^ F401
   |
   = help: Remove unused import: `driada.intense.stats.get_mi_distr_pvalue`

tools/compare_mi_testing_approaches.py:78:11: F541 [*] f-string without any placeholders
   |
76 |     disagreements = analyze_disagreements(comparison_results, alpha=0.05)
77 |     
78 |     print(f"\nDisagreement analysis (alpha=0.05):")
   |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
79 |     for method1, method2, count, total in disagreements:
80 |         if count > 0:
   |
   = help: Remove extraneous `f` prefix

tools/compare_mi_testing_approaches.py:293:5: F841 Local variable `im` is assigned to but never used
    |
291 |                 corr_matrix[i, j] = np.nan
292 |     
293 |     im = ax3.imshow(corr_matrix, cmap='RdBu_r', vmin=-1, vmax=1)
    |     ^^ F841
294 |     ax3.set_xticks(range(len(method_subset)))
295 |     ax3.set_yticks(range(len(method_subset)))
    |
    = help: Remove assignment to unused variable `im`

tools/compare_mi_testing_approaches.py:304:17: F841 Local variable `text` is assigned to but never used
    |
302 |         for j in range(len(method_subset)):
303 |             if not np.isnan(corr_matrix[i, j]):
304 |                 text = ax3.text(j, i, f'{corr_matrix[i, j]:.2f}',
    |                 ^^^^ F841
305 |                                ha='center', va='center', color='black' if abs(corr_matrix[i, j]) < 0.5 else 'white')
    |
    = help: Remove assignment to unused variable `text`

tools/isolated_coverage_runner.py:15:32: F401 [*] `typing.Tuple` imported but unused
   |
13 | import os
14 | from pathlib import Path
15 | from typing import Dict, List, Tuple, Optional
   |                                ^^^^^ F401
16 | import tempfile
17 | import shutil
   |
   = help: Remove unused import: `typing.Tuple`

tools/isolated_coverage_runner.py:17:8: F401 [*] `shutil` imported but unused
   |
15 | from typing import Dict, List, Tuple, Optional
16 | import tempfile
17 | import shutil
   |        ^^^^^^ F401
   |
   = help: Remove unused import: `shutil`

tools/isolated_coverage_runner.py:57:13: F841 Local variable `cov_file` is assigned to but never used
   |
55 |         # Create a temporary directory for this test's coverage data
56 |         with tempfile.TemporaryDirectory() as tmpdir:
57 |             cov_file = Path(tmpdir) / "coverage.json"
   |             ^^^^^^^^ F841
58 |             env = os.environ.copy()
59 |             env['COVERAGE_FILE'] = str(Path(tmpdir) / ".coverage")
   |
   = help: Remove assignment to unused variable `cov_file`

tools/run_isolated_test.py:6:8: F401 [*] `subprocess` imported but unused
  |
4 | import sys
5 | import os
6 | import subprocess
  |        ^^^^^^^^^^ F401
7 | import json
  |
  = help: Remove unused import: `subprocess`

tools/run_isolated_test.py:7:8: F401 [*] `json` imported but unused
  |
5 | import os
6 | import subprocess
7 | import json
  |        ^^^^ F401
8 |
9 | def main():
  |
  = help: Remove unused import: `json`

tools/run_isolated_test.py:25:16: F401 `numba` imported but unused; consider using `importlib.util.find_spec` to test for availability
   |
23 |     # 1. Import numba first to avoid duplicate registration
24 |     try:
25 |         import numba
   |                ^^^^^ F401
26 |     except ImportError:
27 |         pass
   |
   = help: Remove unused import: `numba`

tools/run_isolated_test.py:34:16: F401 `pynndescent` imported but unused; consider using `importlib.util.find_spec` to test for availability
   |
32 |     # 2. Import pynndescent which uses numba
33 |     try:
34 |         import pynndescent
   |                ^^^^^^^^^^^ F401
35 |     except ImportError:
36 |         pass
   |
   = help: Remove unused import: `pynndescent`

tools/run_isolated_test.py:53:16: F401 `ssqueezepy` imported but unused; consider using `importlib.util.find_spec` to test for availability
   |
51 |     # 4. Import ssqueezepy if available to handle its torch import
52 |     try:
53 |         import ssqueezepy
   |                ^^^^^^^^^^ F401
54 |     except ImportError:
55 |         pass
   |
   = help: Remove unused import: `ssqueezepy`

tools/test_flakiness_checker.py:43:19: F541 [*] f-string without any placeholders
   |
41 |         print(f"  Success rate: {success_rate:.1f}% ({sum(results)}/{len(results)})")
42 |         if success_rate < 100:
43 |             print(f"  Status: FLAKY TEST")
   |                   ^^^^^^^^^^^^^^^^^^^^^^^ F541
44 |         else:
45 |             print(f"  Status: STABLE")
   |
   = help: Remove extraneous `f` prefix

tools/test_flakiness_checker.py:45:19: F541 [*] f-string without any placeholders
   |
43 |             print(f"  Status: FLAKY TEST")
44 |         else:
45 |             print(f"  Status: STABLE")
   |                   ^^^^^^^^^^^^^^^^^^^ F541
46 |     
47 |     # Run full pipeline test suite once
   |
   = help: Remove extraneous `f` prefix

tools/test_timing_report.py:17:5: F841 Local variable `lines` is assigned to but never used
   |
16 |     # Parse results
17 |     lines = result.stdout.split('\n')
   |     ^^^^^ F841
18 |     passed = result.stdout.count('PASSED')
19 |     failed = result.stdout.count('FAILED')
   |
   = help: Remove assignment to unused variable `lines`

Found 873 errors.
[*] 286 fixable with the `--fix` option (174 hidden fixes can be enabled with the `--unsafe-fixes` option).
