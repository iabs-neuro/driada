{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Real Neural Data\n",
    "\n",
    "This notebook demonstrates how to use INTENSE with your own neural recordings. We'll cover:\n",
    "- Data preparation and formatting\n",
    "- Creating Experiment objects from various data sources\n",
    "- Handling common data issues\n",
    "- Advanced analysis workflows\n",
    "- Integration with other analysis pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
    "\n",
    "import driada\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "import h5py\n",
    "\n",
    "print(\"Setup complete! ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Formats and Requirements\n",
    "\n",
    "INTENSE requires:\n",
    "1. **Neural signals**: Calcium traces or spike trains\n",
    "2. **Behavioral variables**: Time-aligned features\n",
    "3. **Metadata**: Sampling rate, calcium dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Simulating realistic data structure\n",
    "# In practice, you would load this from your files\n",
    "\n",
    "# Simulate realistic calcium imaging data\n",
    "n_neurons = 100\n",
    "n_timepoints = 36000  # 30 minutes at 20 Hz\n",
    "fps = 20.0\n",
    "\n",
    "# Generate base calcium traces with realistic properties\n",
    "time = np.arange(n_timepoints) / fps\n",
    "calcium_traces = np.zeros((n_neurons, n_timepoints))\n",
    "\n",
    "# Add realistic calcium dynamics\n",
    "for i in range(n_neurons):\n",
    "    # Baseline fluorescence\n",
    "    baseline = 100 + np.random.randn() * 10\n",
    "    \n",
    "    # Add calcium transients\n",
    "    n_events = np.random.poisson(0.1 * n_timepoints / fps)  # ~0.1 Hz firing rate\n",
    "    event_times = np.random.choice(n_timepoints - 100, n_events, replace=False)\n",
    "    \n",
    "    trace = np.ones(n_timepoints) * baseline\n",
    "    for event_time in event_times:\n",
    "        # Calcium transient with rise and decay\n",
    "        t_event = np.arange(100)\n",
    "        rise_time = 0.5 * fps  # 0.5 seconds rise\n",
    "        decay_time = 2.0 * fps  # 2 seconds decay\n",
    "        transient = 20 * (1 - np.exp(-t_event/rise_time)) * np.exp(-t_event/decay_time)\n",
    "        trace[event_time:event_time+100] += transient\n",
    "    \n",
    "    # Add noise\n",
    "    trace += np.random.randn(n_timepoints) * 2\n",
    "    calcium_traces[i] = trace\n",
    "\n",
    "print(f\"Generated calcium traces: {calcium_traces.shape}\")\n",
    "print(f\"Duration: {n_timepoints/fps/60:.1f} minutes at {fps} Hz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate realistic behavioral data\n",
    "\n",
    "# Continuous variables: Animal position in a 2D arena\n",
    "# Simulate exploration with realistic movement patterns\n",
    "velocity = 5.0  # cm/s average\n",
    "dt = 1/fps\n",
    "\n",
    "# Random walk with momentum\n",
    "x_pos = np.zeros(n_timepoints)\n",
    "y_pos = np.zeros(n_timepoints)\n",
    "vx, vy = 0, 0\n",
    "\n",
    "for t in range(1, n_timepoints):\n",
    "    # Update velocity with small random changes\n",
    "    vx += (np.random.randn() * 2 - 0.1 * vx) * dt\n",
    "    vy += (np.random.randn() * 2 - 0.1 * vy) * dt\n",
    "    \n",
    "    # Limit velocity\n",
    "    speed = np.sqrt(vx**2 + vy**2)\n",
    "    if speed > velocity * 2:\n",
    "        vx *= velocity * 2 / speed\n",
    "        vy *= velocity * 2 / speed\n",
    "    \n",
    "    # Update position\n",
    "    x_pos[t] = x_pos[t-1] + vx * dt\n",
    "    y_pos[t] = y_pos[t-1] + vy * dt\n",
    "    \n",
    "    # Boundary conditions (50x50 cm arena)\n",
    "    if abs(x_pos[t]) > 25:\n",
    "        vx *= -1\n",
    "        x_pos[t] = np.clip(x_pos[t], -25, 25)\n",
    "    if abs(y_pos[t]) > 25:\n",
    "        vy *= -1\n",
    "        y_pos[t] = np.clip(y_pos[t], -25, 25)\n",
    "\n",
    "# Calculate derived features\n",
    "speed = np.sqrt(np.gradient(x_pos)**2 + np.gradient(y_pos)**2) * fps\n",
    "head_direction = np.arctan2(np.gradient(y_pos), np.gradient(x_pos))\n",
    "\n",
    "# Discrete variables: Trial types and rewards\n",
    "# Simulate task structure with trials\n",
    "trial_duration = int(30 * fps)  # 30 second trials\n",
    "n_trials = n_timepoints // trial_duration\n",
    "\n",
    "trial_type = np.zeros(n_timepoints, dtype=int)\n",
    "reward = np.zeros(n_timepoints, dtype=int)\n",
    "\n",
    "for trial in range(n_trials):\n",
    "    start = trial * trial_duration\n",
    "    end = (trial + 1) * trial_duration\n",
    "    \n",
    "    # Randomly assign trial type (0: left, 1: right)\n",
    "    ttype = np.random.choice([0, 1])\n",
    "    trial_type[start:end] = ttype\n",
    "    \n",
    "    # Reward at end of trial (80% correct)\n",
    "    if np.random.rand() < 0.8:\n",
    "        reward[end-int(2*fps):end] = 1  # 2 second reward period\n",
    "\n",
    "print(f\"Generated behavioral variables:\")\n",
    "print(f\"  - Position (x, y): continuous, {x_pos.shape[0]} samples\")\n",
    "print(f\"  - Speed: continuous, range {speed.min():.1f} to {speed.max():.1f} cm/s\")\n",
    "print(f\"  - Head direction: continuous, -π to π\")\n",
    "print(f\"  - Trial type: discrete, {len(np.unique(trial_type))} types\")\n",
    "print(f\"  - Reward: discrete, {reward.sum()/fps:.1f} seconds total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Creating an Experiment Object\n",
    "\n",
    "Now let's create a proper Experiment object with this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Basic Experiment creation\n",
    "exp = driada.Experiment(\n",
    "    signature='RealDataExample',\n",
    "    calcium=calcium_traces,\n",
    "    spikes=None,  # Will be inferred from calcium\n",
    "    exp_identificators={\n",
    "        'animal_id': 'mouse_001',\n",
    "        'session': 'session_001',\n",
    "        'date': '2024-01-15',\n",
    "        'experiment_type': 'navigation_task'\n",
    "    },\n",
    "    static_features={\n",
    "        'fps': fps,\n",
    "        't_rise_sec': 0.5,    # GCaMP6f rise time\n",
    "        't_off_sec': 2.0,     # GCaMP6f decay time\n",
    "        'imaging_depth': 150,  # microns\n",
    "        'objective': '16x',\n",
    "        'indicator': 'GCaMP6f'\n",
    "    },\n",
    "    dynamic_features={\n",
    "        'x_position': x_pos,\n",
    "        'y_position': y_pos,\n",
    "        'speed': speed,\n",
    "        'head_direction': head_direction,\n",
    "        'trial_type': trial_type,\n",
    "        'reward': reward\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Created Experiment:\")\n",
    "print(f\"  - Neurons: {exp.n_cells}\")\n",
    "print(f\"  - Duration: {exp.n_frames / exp.fps / 60:.1f} minutes\")\n",
    "print(f\"  - Features: {list(exp.dynamic_features.keys())}\")\n",
    "print(f\"  - Memory usage: ~{exp.calcium.data.nbytes / 1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Data Quality Checks\n",
    "\n",
    "Before running INTENSE, let's check data quality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check 1: Visualize calcium traces\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 8), sharex=True)\n",
    "\n",
    "# Plot a few example neurons\n",
    "time_slice = slice(0, int(60 * fps))  # First minute\n",
    "time_axis = np.arange(len(calcium_traces[0, time_slice])) / fps\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    neuron_idx = i * 10  # Sample neurons\n",
    "    trace = calcium_traces[neuron_idx, time_slice]\n",
    "    \n",
    "    ax.plot(time_axis, trace, 'k-', linewidth=0.5)\n",
    "    ax.set_ylabel(f'Neuron {neuron_idx}\\nΔF')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Mark detected spikes if available\n",
    "    if hasattr(exp.neurons[neuron_idx], 'sp') and exp.neurons[neuron_idx].sp is not None:\n",
    "        spike_times = np.where(exp.neurons[neuron_idx].sp.data[time_slice] > 0)[0] / fps\n",
    "        ax.scatter(spike_times, \n",
    "                  trace[exp.neurons[neuron_idx].sp.data[time_slice] > 0], \n",
    "                  color='red', s=20, zorder=5)\n",
    "\n",
    "axes[-1].set_xlabel('Time (seconds)')\n",
    "axes[0].set_title('Example Calcium Traces')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check 2: Behavioral data coverage\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Spatial coverage\n",
    "axes[0, 0].plot(x_pos[::10], y_pos[::10], 'k-', alpha=0.3, linewidth=0.5)\n",
    "axes[0, 0].scatter(x_pos[::100], y_pos[::100], c=time[::100], \n",
    "                   cmap='viridis', s=2, alpha=0.5)\n",
    "axes[0, 0].set_xlabel('X position (cm)')\n",
    "axes[0, 0].set_ylabel('Y position (cm)')\n",
    "axes[0, 0].set_title('Spatial Coverage')\n",
    "axes[0, 0].set_aspect('equal')\n",
    "\n",
    "# Speed distribution\n",
    "axes[0, 1].hist(speed, bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[0, 1].set_xlabel('Speed (cm/s)')\n",
    "axes[0, 1].set_ylabel('Count')\n",
    "axes[0, 1].set_title('Speed Distribution')\n",
    "axes[0, 1].axvline(speed.mean(), color='red', linestyle='--', \n",
    "                   label=f'Mean: {speed.mean():.1f} cm/s')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Head direction coverage\n",
    "axes[1, 0].hist(head_direction, bins=36, alpha=0.7, edgecolor='black')\n",
    "axes[1, 0].set_xlabel('Head Direction (radians)')\n",
    "axes[1, 0].set_ylabel('Count')\n",
    "axes[1, 0].set_title('Head Direction Distribution')\n",
    "axes[1, 0].set_xlim(-np.pi, np.pi)\n",
    "\n",
    "# Trial structure\n",
    "trial_starts = np.where(np.diff(trial_type) != 0)[0]\n",
    "reward_times = np.where(reward > 0)[0] / fps / 60  # Convert to minutes\n",
    "\n",
    "axes[1, 1].plot(time / 60, trial_type, 'k-', linewidth=1)\n",
    "axes[1, 1].scatter(reward_times, np.ones_like(reward_times) * 0.5, \n",
    "                   color='green', s=20, marker='o', label='Rewards')\n",
    "axes[1, 1].set_xlabel('Time (minutes)')\n",
    "axes[1, 1].set_ylabel('Trial Type')\n",
    "axes[1, 1].set_title('Task Structure')\n",
    "axes[1, 1].set_ylim(-0.5, 1.5)\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Data Quality Summary:\")\n",
    "print(f\"  - Spatial coverage: {(len(np.unique(x_pos.astype(int))) * len(np.unique(y_pos.astype(int)))) / (50*50) * 100:.1f}% of arena\")\n",
    "print(f\"  - Mean firing rate: {np.mean([len(np.where(exp.neurons[i].sp.data > 0)[0]) / (n_timepoints/fps) for i in range(10)]):.2f} Hz\")\n",
    "print(f\"  - Number of trials: {len(trial_starts)}\")\n",
    "print(f\"  - Reward rate: {len(reward_times) / len(trial_starts) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Running INTENSE with Real Data Considerations\n",
    "\n",
    "When working with real data, consider:\n",
    "1. Appropriate shuffle numbers\n",
    "2. Feature selection\n",
    "3. Computational resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for analysis\n",
    "# For spatial analysis\n",
    "spatial_features = ['x_position', 'y_position', 'speed', 'head_direction']\n",
    "\n",
    "# For task analysis  \n",
    "task_features = ['trial_type', 'reward']\n",
    "\n",
    "# Run INTENSE on spatial features\n",
    "print(\"Analyzing spatial selectivity...\")\n",
    "stats_spatial, sig_spatial, info_spatial, results_spatial = driada.compute_cell_feat_significance(\n",
    "    exp,\n",
    "    cell_bunch=None,  # Analyze all neurons\n",
    "    feat_bunch=spatial_features,\n",
    "    metric='mi',\n",
    "    mode='two_stage',\n",
    "    n_shuffles_stage1=100,\n",
    "    n_shuffles_stage2=2000,  # Increase for publication\n",
    "    pval_thr=0.01,\n",
    "    find_optimal_delays=True,\n",
    "    shift_window=2,  # ±2 seconds for calcium dynamics\n",
    "    parallelize=True,  # Use multiple cores\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\nAnalyzing task selectivity...\")\n",
    "stats_task, sig_task, info_task, results_task = driada.compute_cell_feat_significance(\n",
    "    exp,\n",
    "    feat_bunch=task_features,\n",
    "    metric='mi',\n",
    "    mode='two_stage',\n",
    "    n_shuffles_stage1=100,\n",
    "    n_shuffles_stage2=2000,\n",
    "    pval_thr=0.01,\n",
    "    find_optimal_delays=True,\n",
    "    shift_window=5,  # Longer window for task events\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Interpreting Results in Context\n",
    "\n",
    "Let's analyze results with domain knowledge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize neurons by selectivity type\n",
    "spatial_neurons = exp.get_significant_neurons()\n",
    "\n",
    "# Identify different cell types\n",
    "place_cells = []  # Selective to x AND y\n",
    "speed_cells = []  # Selective to speed\n",
    "head_direction_cells = []  # Selective to head direction\n",
    "task_cells = []  # Selective to trial type or reward\n",
    "mixed_cells = []  # Selective to multiple categories\n",
    "\n",
    "for neuron_id, features in spatial_neurons.items():\n",
    "    spatial_sel = [f for f in features if f in spatial_features]\n",
    "    task_sel = [f for f in features if f in task_features]\n",
    "    \n",
    "    if 'x_position' in features and 'y_position' in features:\n",
    "        place_cells.append(neuron_id)\n",
    "    if 'speed' in features:\n",
    "        speed_cells.append(neuron_id)\n",
    "    if 'head_direction' in features:\n",
    "        head_direction_cells.append(neuron_id)\n",
    "    if len(task_sel) > 0:\n",
    "        task_cells.append(neuron_id)\n",
    "    if len(spatial_sel) > 0 and len(task_sel) > 0:\n",
    "        mixed_cells.append(neuron_id)\n",
    "\n",
    "print(\"Cell Type Classification:\")\n",
    "print(f\"  - Place cells: {len(place_cells)} ({len(place_cells)/exp.n_cells*100:.1f}%)\")\n",
    "print(f\"  - Speed cells: {len(speed_cells)} ({len(speed_cells)/exp.n_cells*100:.1f}%)\")\n",
    "print(f\"  - Head direction cells: {len(head_direction_cells)} ({len(head_direction_cells)/exp.n_cells*100:.1f}%)\")\n",
    "print(f\"  - Task-modulated cells: {len(task_cells)} ({len(task_cells)/exp.n_cells*100:.1f}%)\")\n",
    "print(f\"  - Mixed selectivity: {len(mixed_cells)} ({len(mixed_cells)/exp.n_cells*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize place cell example\n",
    "if place_cells:\n",
    "    # Pick a place cell\n",
    "    pc_id = place_cells[0]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Trajectory with neural activity\n",
    "    neural_activity = exp.neurons[pc_id].ca.data\n",
    "    scatter = axes[0].scatter(x_pos[::10], y_pos[::10], \n",
    "                             c=neural_activity[::10], \n",
    "                             cmap='hot', s=2, alpha=0.7)\n",
    "    axes[0].set_xlabel('X position (cm)')\n",
    "    axes[0].set_ylabel('Y position (cm)')\n",
    "    axes[0].set_title(f'Place Cell {pc_id} Activity')\n",
    "    plt.colorbar(scatter, ax=axes[0], label='Activity')\n",
    "    \n",
    "    # Place field (2D histogram)\n",
    "    occupancy, xedges, yedges = np.histogram2d(x_pos, y_pos, bins=20)\n",
    "    activity_map, _, _ = np.histogram2d(x_pos, y_pos, bins=20, \n",
    "                                       weights=neural_activity)\n",
    "    \n",
    "    # Normalize by occupancy\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        place_field = activity_map / occupancy\n",
    "        place_field[occupancy < 10] = np.nan  # Mask unvisited bins\n",
    "    \n",
    "    im = axes[1].imshow(place_field.T, origin='lower', \n",
    "                       extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]],\n",
    "                       cmap='jet', interpolation='gaussian')\n",
    "    axes[1].set_xlabel('X position (cm)')\n",
    "    axes[1].set_ylabel('Y position (cm)')\n",
    "    axes[1].set_title('Place Field')\n",
    "    plt.colorbar(im, ax=axes[1], label='Firing Rate')\n",
    "    \n",
    "    # MI values for this neuron\n",
    "    mi_values = []\n",
    "    features_list = ['x_position', 'y_position', 'speed', 'head_direction']\n",
    "    for feat in features_list:\n",
    "        if feat in spatial_neurons[pc_id]:\n",
    "            stats = exp.get_neuron_feature_pair_stats(pc_id, feat)\n",
    "            mi_values.append(stats.get('me', 0))\n",
    "        else:\n",
    "            mi_values.append(0)\n",
    "    \n",
    "    axes[2].bar(range(len(features_list)), mi_values, \n",
    "               color=['green' if mi > 0 else 'gray' for mi in mi_values])\n",
    "    axes[2].set_xticks(range(len(features_list)))\n",
    "    axes[2].set_xticklabels(features_list, rotation=45, ha='right')\n",
    "    axes[2].set_ylabel('Mutual Information')\n",
    "    axes[2].set_title('Feature Selectivity')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Advanced Workflows\n",
    "\n",
    "### Mixed Selectivity Analysis\n",
    "\n",
    "When neurons respond to multiple correlated features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for neurons with mixed spatial/task selectivity\n",
    "if mixed_cells:\n",
    "    print(f\"Analyzing mixed selectivity for {len(mixed_cells)} neurons...\")\n",
    "    \n",
    "    # Example: Disentangle position vs reward selectivity\n",
    "    mixed_id = mixed_cells[0]\n",
    "    \n",
    "    # Get the stats for each feature\n",
    "    features_to_analyze = []\n",
    "    mi_values = {}\n",
    "    \n",
    "    for feat in spatial_neurons[mixed_id]:\n",
    "        stats = exp.get_neuron_feature_pair_stats(mixed_id, feat)\n",
    "        mi_values[feat] = stats.get('me', 0)\n",
    "        features_to_analyze.append(feat)\n",
    "    \n",
    "    print(f\"\\nNeuron {mixed_id} selectivity:\")\n",
    "    for feat, mi in sorted(mi_values.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"  - {feat}: MI = {mi:.3f}\")\n",
    "    \n",
    "    # You can use disentanglement analysis here\n",
    "    # See examples/mixed_selectivity.py for full implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Saving and Loading Results\n",
    "\n",
    "For large datasets, save intermediate results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to HDF5 format\n",
    "def save_intense_results(filename, exp, stats, significance, info, results):\n",
    "    \"\"\"Save INTENSE results to HDF5 file.\"\"\"\n",
    "    with h5py.File(filename, 'w') as f:\n",
    "        # Save metadata\n",
    "        meta = f.create_group('metadata')\n",
    "        meta.attrs['signature'] = exp.signature\n",
    "        meta.attrs['n_cells'] = exp.n_cells\n",
    "        meta.attrs['n_frames'] = exp.n_frames\n",
    "        meta.attrs['fps'] = exp.fps\n",
    "        \n",
    "        # Save significance matrix\n",
    "        f.create_dataset('significance', data=significance)\n",
    "        \n",
    "        # Save feature names\n",
    "        feat_names = list(exp.dynamic_features.keys())\n",
    "        f.create_dataset('feature_names', \n",
    "                        data=[n.encode() for n in feat_names])\n",
    "        \n",
    "        # Save detailed results\n",
    "        if results:\n",
    "            results_grp = f.create_group('results')\n",
    "            for i, res in enumerate(results):\n",
    "                res_grp = results_grp.create_group(f'pair_{i}')\n",
    "                for key, value in res.items():\n",
    "                    if value is not None:\n",
    "                        try:\n",
    "                            res_grp.attrs[key] = value\n",
    "                        except:\n",
    "                            pass  # Skip non-serializable values\n",
    "    \n",
    "    print(f\"Results saved to {filename}\")\n",
    "\n",
    "# Example usage (uncomment to save)\n",
    "# save_intense_results('intense_results.h5', exp, stats_spatial, \n",
    "#                     sig_spatial, info_spatial, results_spatial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export summary for further analysis\n",
    "def export_summary_table(exp):\n",
    "    \"\"\"Export a summary table of all significant relationships.\"\"\"\n",
    "    sig_neurons = exp.get_significant_neurons()\n",
    "    \n",
    "    summary_data = []\n",
    "    for neuron_id, features in sig_neurons.items():\n",
    "        for feat in features:\n",
    "            stats = exp.get_neuron_feature_pair_stats(neuron_id, feat)\n",
    "            \n",
    "            summary_data.append({\n",
    "                'neuron_id': neuron_id,\n",
    "                'feature': feat,\n",
    "                'mi': stats.get('me', np.nan),\n",
    "                'pvalue': stats.get('pval', np.nan),\n",
    "                'optimal_delay': stats.get('shift_used', 0),\n",
    "                'effect_size': stats.get('me', 0) / stats.get('mean_bs', 1)\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(summary_data)\n",
    "    return df\n",
    "\n",
    "# Create summary\n",
    "summary_df = export_summary_table(exp)\n",
    "if not summary_df.empty:\n",
    "    print(\"Summary Statistics:\")\n",
    "    print(summary_df.groupby('feature')['mi'].describe())\n",
    "    \n",
    "    # Save to CSV (uncomment to save)\n",
    "    # summary_df.to_csv('neuron_selectivity_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices for Real Data\n",
    "\n",
    "### 1. Data Preparation\n",
    "- **Synchronization**: Ensure neural and behavioral data are perfectly aligned\n",
    "- **Sampling rates**: Downsample if needed (typically 10-30 Hz for calcium)\n",
    "- **Quality control**: Remove motion artifacts and dead neurons\n",
    "\n",
    "### 2. Feature Engineering\n",
    "- **Continuous features**: Consider smoothing noisy measurements\n",
    "- **Discrete features**: Ensure sufficient samples per category\n",
    "- **Derived features**: Create task-relevant variables (e.g., distance to goal)\n",
    "\n",
    "### 3. Computational Considerations\n",
    "- **Start small**: Test with subset of neurons first\n",
    "- **Parallelize**: Use n_jobs=-1 for all cores\n",
    "- **Save progress**: Export intermediate results\n",
    "- **Memory**: ~8 bytes per neuron × timepoint × shuffle\n",
    "\n",
    "### 4. Statistical Rigor\n",
    "- **Shuffle numbers**: 10,000+ for publication-quality results\n",
    "- **Multiple comparisons**: Built-in Holm-Bonferroni correction\n",
    "- **Effect sizes**: Report both significance and effect magnitude\n",
    "\n",
    "### 5. Validation\n",
    "- **Positive controls**: Include known relationships\n",
    "- **Negative controls**: Test with shuffled neuron identities\n",
    "- **Cross-validation**: Split data temporally\n",
    "\n",
    "## Troubleshooting Common Issues\n",
    "\n",
    "**Issue: No significant results**\n",
    "- Check behavioral variable coverage\n",
    "- Increase recording duration\n",
    "- Verify spike detection from calcium\n",
    "\n",
    "**Issue: Too many significant results**\n",
    "- Increase shuffle numbers\n",
    "- Check for global artifacts\n",
    "- Consider more stringent p-value threshold\n",
    "\n",
    "**Issue: Slow computation**\n",
    "- Downsample temporally\n",
    "- Reduce delay search window\n",
    "- Use two-stage testing\n",
    "- Parallelize with n_jobs\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "You now have the tools to:\n",
    "1. Load and format your neural data\n",
    "2. Run comprehensive INTENSE analysis\n",
    "3. Interpret results in biological context\n",
    "4. Export findings for publication\n",
    "\n",
    "For more advanced analyses:\n",
    "- See `examples/mixed_selectivity.py` for disentanglement\n",
    "- Use `compute_feat_feat_significance` for behavioral relationships\n",
    "- Explore `compute_cell_cell_significance` for neural correlations\n",
    "\n",
    "Happy discovering! 🔬🧠"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}