{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Real Neural Data\n",
    "\n",
    "This notebook demonstrates how to use INTENSE with your own neural recordings. We'll cover:\n",
    "- Data preparation and formatting\n",
    "- Creating Experiment objects from various data sources\n",
    "- Handling common data issues\n",
    "- Advanced analysis workflows\n",
    "- Integration with other analysis pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
    "\n",
    "import driada\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "print(\"Setup complete! âœ“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Formats and Requirements\n",
    "\n",
    "INTENSE requires:\n",
    "1. **Neural signals**: Calcium traces or spike trains\n",
    "2. **Behavioral variables**: Time-aligned features\n",
    "3. **Metadata**: Sampling rate, calcium dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Simulating realistic data structure\n",
    "# In practice, you would load this from your files\n",
    "\n",
    "# Simulate realistic calcium imaging data\n",
    "n_neurons = 100\n",
    "n_timepoints = 36000  # 30 minutes at 20 Hz\n",
    "fps = 20.0\n",
    "\n",
    "# Generate base calcium traces with realistic properties\n",
    "time = np.arange(n_timepoints) / fps\n",
    "calcium_traces = np.zeros((n_neurons, n_timepoints))\n",
    "\n",
    "# Add realistic calcium dynamics\n",
    "for i in range(n_neurons):\n",
    "    # Baseline fluorescence\n",
    "    baseline = 100 + np.random.randn() * 10\n",
    "    \n",
    "    # Add calcium transients\n",
    "    n_events = np.random.poisson(0.1 * n_timepoints / fps)  # ~0.1 Hz firing rate\n",
    "    event_times = np.random.choice(n_timepoints - 100, n_events, replace=False)\n",
    "    \n",
    "    trace = np.ones(n_timepoints) * baseline\n",
    "    for event_time in event_times:\n",
    "        # Calcium transient with rise and decay\n",
    "        t_event = np.arange(100)\n",
    "        rise_time = 0.5 * fps  # 0.5 seconds rise\n",
    "        decay_time = 2.0 * fps  # 2 seconds decay\n",
    "        transient = 20 * (1 - np.exp(-t_event/rise_time)) * np.exp(-t_event/decay_time)\n",
    "        trace[event_time:event_time+100] += transient\n",
    "    \n",
    "    # Add noise\n",
    "    trace += np.random.randn(n_timepoints) * 2\n",
    "    calcium_traces[i] = trace\n",
    "\n",
    "print(f\"Generated calcium traces: {calcium_traces.shape}\")\n",
    "print(f\"Duration: {n_timepoints/fps/60:.1f} minutes at {fps} Hz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate realistic behavioral data\n",
    "\n",
    "# Continuous variables: Animal position in a 2D arena\n",
    "# Simulate exploration with realistic movement patterns\n",
    "velocity = 5.0  # cm/s average\n",
    "dt = 1/fps\n",
    "\n",
    "# Random walk with momentum\n",
    "x_pos = np.zeros(n_timepoints)\n",
    "y_pos = np.zeros(n_timepoints)\n",
    "vx, vy = 0, 0\n",
    "\n",
    "for t in range(1, n_timepoints):\n",
    "    # Update velocity with small random changes\n",
    "    vx += (np.random.randn() * 2 - 0.1 * vx) * dt\n",
    "    vy += (np.random.randn() * 2 - 0.1 * vy) * dt\n",
    "    \n",
    "    # Limit velocity\n",
    "    speed = np.sqrt(vx**2 + vy**2)\n",
    "    if speed > velocity * 2:\n",
    "        vx *= velocity * 2 / speed\n",
    "        vy *= velocity * 2 / speed\n",
    "    \n",
    "    # Update position\n",
    "    x_pos[t] = x_pos[t-1] + vx * dt\n",
    "    y_pos[t] = y_pos[t-1] + vy * dt\n",
    "    \n",
    "    # Boundary conditions (50x50 cm arena)\n",
    "    if abs(x_pos[t]) > 25:\n",
    "        vx *= -1\n",
    "        x_pos[t] = np.clip(x_pos[t], -25, 25)\n",
    "    if abs(y_pos[t]) > 25:\n",
    "        vy *= -1\n",
    "        y_pos[t] = np.clip(y_pos[t], -25, 25)\n",
    "\n",
    "# Calculate derived features\n",
    "speed = np.sqrt(np.gradient(x_pos)**2 + np.gradient(y_pos)**2) * fps\n",
    "head_direction = np.arctan2(np.gradient(y_pos), np.gradient(x_pos))\n",
    "\n",
    "# Discrete variables: Trial types and rewards\n",
    "# Simulate task structure with trials\n",
    "trial_duration = int(30 * fps)  # 30 second trials\n",
    "n_trials = n_timepoints // trial_duration\n",
    "\n",
    "trial_type = np.zeros(n_timepoints, dtype=int)\n",
    "reward = np.zeros(n_timepoints, dtype=int)\n",
    "\n",
    "for trial in range(n_trials):\n",
    "    start = trial * trial_duration\n",
    "    end = (trial + 1) * trial_duration\n",
    "    \n",
    "    # Randomly assign trial type (0: left, 1: right)\n",
    "    ttype = np.random.choice([0, 1])\n",
    "    trial_type[start:end] = ttype\n",
    "    \n",
    "    # Reward at end of trial (80% correct)\n",
    "    if np.random.rand() < 0.8:\n",
    "        reward[end-int(2*fps):end] = 1  # 2 second reward period\n",
    "\n",
    "print(\"Generated behavioral variables:\")\n",
    "print(f\"  - Position (x, y): continuous, {x_pos.shape[0]} samples\")\n",
    "print(f\"  - Speed: continuous, range {speed.min():.1f} to {speed.max():.1f} cm/s\")\n",
    "print(\"  - Head direction: continuous, -Ï€ to Ï€\")\n",
    "print(f\"  - Trial type: discrete, {len(np.unique(trial_type))} types\")\n",
    "print(f\"  - Reward: discrete, {reward.sum()/fps:.1f} seconds total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Creating an Experiment Object\n",
    "\n",
    "Now let's create a proper Experiment object with this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Basic Experiment creation\n",
    "exp = driada.Experiment(\n",
    "    signature='RealDataExample',\n",
    "    calcium=calcium_traces,\n",
    "    spikes=None,  # Will be inferred from calcium\n",
    "    exp_identificators={\n",
    "        'animal_id': 'mouse_001',\n",
    "        'session': 'session_001',\n",
    "        'date': '2024-01-15',\n",
    "        'experiment_type': 'navigation_task'\n",
    "    },\n",
    "    static_features={\n",
    "        'fps': fps,\n",
    "        't_rise_sec': 0.5,    # GCaMP6f rise time\n",
    "        't_off_sec': 2.0,     # GCaMP6f decay time\n",
    "        'imaging_depth': 150,  # microns\n",
    "        'objective': '16x',\n",
    "        'indicator': 'GCaMP6f'\n",
    "    },\n",
    "    dynamic_features={\n",
    "        'x_position': x_pos,\n",
    "        'y_position': y_pos,\n",
    "        'speed': speed,\n",
    "        'head_direction': head_direction,\n",
    "        'trial_type': trial_type,\n",
    "        'reward': reward\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Created Experiment:\")\n",
    "print(f\"  - Neurons: {exp.n_cells}\")\n",
    "print(f\"  - Duration: {exp.n_frames / exp.fps / 60:.1f} minutes\")\n",
    "print(f\"  - Features: {list(exp.dynamic_features.keys())}\")\n",
    "print(f\"  - Memory usage: ~{exp.calcium.data.nbytes / 1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Data Quality Checks\n",
    "\n",
    "Before running INTENSE, let's check data quality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check 1: Visualize calcium traces\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 8), sharex=True)\n",
    "\n",
    "# Plot a few example neurons\n",
    "time_slice = slice(0, int(60 * fps))  # First minute\n",
    "time_axis = np.arange(len(calcium_traces[0, time_slice])) / fps\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    neuron_idx = i * 10  # Sample neurons\n",
    "    trace = calcium_traces[neuron_idx, time_slice]\n",
    "    \n",
    "    ax.plot(time_axis, trace, 'k-', linewidth=0.5)\n",
    "    ax.set_ylabel(f'Neuron {neuron_idx}\\nÎ”F')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Mark detected spikes if available\n",
    "    if hasattr(exp.neurons[neuron_idx], 'sp') and exp.neurons[neuron_idx].sp is not None:\n",
    "        spike_times = np.where(exp.neurons[neuron_idx].sp.data[time_slice] > 0)[0] / fps\n",
    "        ax.scatter(spike_times, \n",
    "                  trace[exp.neurons[neuron_idx].sp.data[time_slice] > 0], \n",
    "                  color='red', s=20, zorder=5)\n",
    "\n",
    "axes[-1].set_xlabel('Time (seconds)')\n",
    "axes[0].set_title('Example Calcium Traces')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check 2: Behavioral data coverage\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Spatial coverage\n",
    "axes[0, 0].plot(x_pos[::10], y_pos[::10], 'k-', alpha=0.3, linewidth=0.5)\n",
    "axes[0, 0].scatter(x_pos[::100], y_pos[::100], c=time[::100], \n",
    "                   cmap='viridis', s=2, alpha=0.5)\n",
    "axes[0, 0].set_xlabel('X position (cm)')\n",
    "axes[0, 0].set_ylabel('Y position (cm)')\n",
    "axes[0, 0].set_title('Spatial Coverage')\n",
    "axes[0, 0].set_aspect('equal')\n",
    "\n",
    "# Speed distribution\n",
    "axes[0, 1].hist(speed, bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[0, 1].set_xlabel('Speed (cm/s)')\n",
    "axes[0, 1].set_ylabel('Count')\n",
    "axes[0, 1].set_title('Speed Distribution')\n",
    "axes[0, 1].axvline(speed.mean(), color='red', linestyle='--', \n",
    "                   label=f'Mean: {speed.mean():.1f} cm/s')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Head direction coverage\n",
    "axes[1, 0].hist(head_direction, bins=36, alpha=0.7, edgecolor='black')\n",
    "axes[1, 0].set_xlabel('Head Direction (radians)')\n",
    "axes[1, 0].set_ylabel('Count')\n",
    "axes[1, 0].set_title('Head Direction Distribution')\n",
    "axes[1, 0].set_xlim(-np.pi, np.pi)\n",
    "\n",
    "# Trial structure\n",
    "trial_starts = np.where(np.diff(trial_type) != 0)[0]\n",
    "reward_times = np.where(reward > 0)[0] / fps / 60  # Convert to minutes\n",
    "\n",
    "axes[1, 1].plot(time / 60, trial_type, 'k-', linewidth=1)\n",
    "axes[1, 1].scatter(reward_times, np.ones_like(reward_times) * 0.5, \n",
    "                   color='green', s=20, marker='o', label='Rewards')\n",
    "axes[1, 1].set_xlabel('Time (minutes)')\n",
    "axes[1, 1].set_ylabel('Trial Type')\n",
    "axes[1, 1].set_title('Task Structure')\n",
    "axes[1, 1].set_ylim(-0.5, 1.5)\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Data Quality Summary:\")\n",
    "print(f\"  - Spatial coverage: {(len(np.unique(x_pos.astype(int))) * len(np.unique(y_pos.astype(int)))) / (50*50) * 100:.1f}% of arena\")\n",
    "print(f\"  - Mean firing rate: {np.mean([len(np.where(exp.neurons[i].sp.data > 0)[0]) / (n_timepoints/fps) for i in range(10)]):.2f} Hz\")\n",
    "print(f\"  - Number of trials: {len(trial_starts)}\")\n",
    "print(f\"  - Reward rate: {len(reward_times) / len(trial_starts) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Running INTENSE with Real Data Considerations\n",
    "\n",
    "When working with real data, consider:\n",
    "1. Appropriate shuffle numbers\n",
    "2. Feature selection\n",
    "3. Computational resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for analysis\n",
    "# For spatial analysis\n",
    "spatial_features = ['x_position', 'y_position', 'speed', 'head_direction']\n",
    "\n",
    "# For task analysis  \n",
    "task_features = ['trial_type', 'reward']\n",
    "\n",
    "# Run INTENSE on spatial features\n",
    "print(\"Analyzing spatial selectivity...\")\n",
    "stats_spatial, sig_spatial, info_spatial, results_spatial = driada.compute_cell_feat_significance(\n",
    "    exp,\n",
    "    cell_bunch=None,  # Analyze all neurons\n",
    "    feat_bunch=spatial_features,\n",
    "    metric='mi',\n",
    "    mode='two_stage',\n",
    "    n_shuffles_stage1=100,\n",
    "    n_shuffles_stage2=2000,  # Increase for publication\n",
    "    pval_thr=0.01,\n",
    "    find_optimal_delays=True,\n",
    "    shift_window=2,  # Â±2 seconds for calcium dynamics\n",
    "    parallelize=True,  # Use multiple cores\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\nAnalyzing task selectivity...\")\n",
    "stats_task, sig_task, info_task, results_task = driada.compute_cell_feat_significance(\n",
    "    exp,\n",
    "    feat_bunch=task_features,\n",
    "    metric='mi',\n",
    "    mode='two_stage',\n",
    "    n_shuffles_stage1=100,\n",
    "    n_shuffles_stage2=2000,\n",
    "    pval_thr=0.01,\n",
    "    find_optimal_delays=True,\n",
    "    shift_window=5,  # Longer window for task events\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Interpreting Results in Context\n",
    "\n",
    "Let's analyze results with domain knowledge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize neurons by selectivity type\n",
    "spatial_neurons = exp.get_significant_neurons()\n",
    "\n",
    "# Identify different cell types\n",
    "place_cells = []  # Selective to x AND y\n",
    "speed_cells = []  # Selective to speed\n",
    "head_direction_cells = []  # Selective to head direction\n",
    "task_cells = []  # Selective to trial type or reward\n",
    "mixed_cells = []  # Selective to multiple categories\n",
    "\n",
    "for neuron_id, features in spatial_neurons.items():\n",
    "    spatial_sel = [f for f in features if f in spatial_features]\n",
    "    task_sel = [f for f in features if f in task_features]\n",
    "    \n",
    "    if 'x_position' in features and 'y_position' in features:\n",
    "        place_cells.append(neuron_id)\n",
    "    if 'speed' in features:\n",
    "        speed_cells.append(neuron_id)\n",
    "    if 'head_direction' in features:\n",
    "        head_direction_cells.append(neuron_id)\n",
    "    if len(task_sel) > 0:\n",
    "        task_cells.append(neuron_id)\n",
    "    if len(spatial_sel) > 0 and len(task_sel) > 0:\n",
    "        mixed_cells.append(neuron_id)\n",
    "\n",
    "print(\"Cell Type Classification:\")\n",
    "print(f\"  - Place cells: {len(place_cells)} ({len(place_cells)/exp.n_cells*100:.1f}%)\")\n",
    "print(f\"  - Speed cells: {len(speed_cells)} ({len(speed_cells)/exp.n_cells*100:.1f}%)\")\n",
    "print(f\"  - Head direction cells: {len(head_direction_cells)} ({len(head_direction_cells)/exp.n_cells*100:.1f}%)\")\n",
    "print(f\"  - Task-modulated cells: {len(task_cells)} ({len(task_cells)/exp.n_cells*100:.1f}%)\")\n",
    "print(f\"  - Mixed selectivity: {len(mixed_cells)} ({len(mixed_cells)/exp.n_cells*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize place cell example\n",
    "if place_cells:\n",
    "    # Pick a place cell\n",
    "    pc_id = place_cells[0]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Trajectory with neural activity\n",
    "    neural_activity = exp.neurons[pc_id].ca.data\n",
    "    scatter = axes[0].scatter(x_pos[::10], y_pos[::10], \n",
    "                             c=neural_activity[::10], \n",
    "                             cmap='hot', s=2, alpha=0.7)\n",
    "    axes[0].set_xlabel('X position (cm)')\n",
    "    axes[0].set_ylabel('Y position (cm)')\n",
    "    axes[0].set_title(f'Place Cell {pc_id} Activity')\n",
    "    plt.colorbar(scatter, ax=axes[0], label='Activity')\n",
    "    \n",
    "    # Place field (2D histogram)\n",
    "    occupancy, xedges, yedges = np.histogram2d(x_pos, y_pos, bins=20)\n",
    "    activity_map, _, _ = np.histogram2d(x_pos, y_pos, bins=20, \n",
    "                                       weights=neural_activity)\n",
    "    \n",
    "    # Normalize by occupancy\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        place_field = activity_map / occupancy\n",
    "        place_field[occupancy < 10] = np.nan  # Mask unvisited bins\n",
    "    \n",
    "    im = axes[1].imshow(place_field.T, origin='lower', \n",
    "                       extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]],\n",
    "                       cmap='jet', interpolation='gaussian')\n",
    "    axes[1].set_xlabel('X position (cm)')\n",
    "    axes[1].set_ylabel('Y position (cm)')\n",
    "    axes[1].set_title('Place Field')\n",
    "    plt.colorbar(im, ax=axes[1], label='Firing Rate')\n",
    "    \n",
    "    # MI values for this neuron\n",
    "    mi_values = []\n",
    "    features_list = ['x_position', 'y_position', 'speed', 'head_direction']\n",
    "    for feat in features_list:\n",
    "        if feat in spatial_neurons[pc_id]:\n",
    "            stats = exp.get_neuron_feature_pair_stats(pc_id, feat)\n",
    "            mi_values.append(stats.get('me', 0))\n",
    "        else:\n",
    "            mi_values.append(0)\n",
    "    \n",
    "    axes[2].bar(range(len(features_list)), mi_values, \n",
    "               color=['green' if mi > 0 else 'gray' for mi in mi_values])\n",
    "    axes[2].set_xticks(range(len(features_list)))\n",
    "    axes[2].set_xticklabels(features_list, rotation=45, ha='right')\n",
    "    axes[2].set_ylabel('Mutual Information')\n",
    "    axes[2].set_title('Feature Selectivity')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Advanced Workflows\n",
    "\n",
    "### Mixed Selectivity Analysis\n",
    "\n",
    "When neurons respond to multiple correlated features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for neurons with mixed spatial/task selectivity\n",
    "if mixed_cells:\n",
    "    print(f\"Analyzing mixed selectivity for {len(mixed_cells)} neurons...\")\n",
    "    \n",
    "    # Example: Disentangle position vs reward selectivity\n",
    "    mixed_id = mixed_cells[0]\n",
    "    \n",
    "    # Get the stats for each feature\n",
    "    features_to_analyze = []\n",
    "    mi_values = {}\n",
    "    \n",
    "    for feat in spatial_neurons[mixed_id]:\n",
    "        stats = exp.get_neuron_feature_pair_stats(mixed_id, feat)\n",
    "        mi_values[feat] = stats.get('me', 0)\n",
    "        features_to_analyze.append(feat)\n",
    "    \n",
    "    print(f\"\\nNeuron {mixed_id} selectivity:\")\n",
    "    for feat, mi in sorted(mi_values.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"  - {feat}: MI = {mi:.3f}\")\n",
    "    \n",
    "    # You can use disentanglement analysis here\n",
    "    # See examples/mixed_selectivity.py for full implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Saving and Loading Results\n",
    "\n",
    "For large datasets, save intermediate results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to HDF5 format\n",
    "def save_intense_results(filename, exp, stats, significance, info, results):\n",
    "    \"\"\"Save INTENSE results to HDF5 file.\"\"\"\n",
    "    with h5py.File(filename, 'w') as f:\n",
    "        # Save metadata\n",
    "        meta = f.create_group('metadata')\n",
    "        meta.attrs['signature'] = exp.signature\n",
    "        meta.attrs['n_cells'] = exp.n_cells\n",
    "        meta.attrs['n_frames'] = exp.n_frames\n",
    "        meta.attrs['fps'] = exp.fps\n",
    "        \n",
    "        # Save significance matrix\n",
    "        f.create_dataset('significance', data=significance)\n",
    "        \n",
    "        # Save feature names\n",
    "        feat_names = list(exp.dynamic_features.keys())\n",
    "        f.create_dataset('feature_names', \n",
    "                        data=[n.encode() for n in feat_names])\n",
    "        \n",
    "        # Save detailed results\n",
    "        if results:\n",
    "            results_grp = f.create_group('results')\n",
    "            for i, res in enumerate(results):\n",
    "                res_grp = results_grp.create_group(f'pair_{i}')\n",
    "                for key, value in res.items():\n",
    "                    if value is not None:\n",
    "                        try:\n",
    "                            res_grp.attrs[key] = value\n",
    "                        except:\n",
    "                            pass  # Skip non-serializable values\n",
    "    \n",
    "    print(f\"Results saved to {filename}\")\n",
    "\n",
    "# Example usage (uncomment to save)\n",
    "# save_intense_results('intense_results.h5', exp, stats_spatial, \n",
    "#                     sig_spatial, info_spatial, results_spatial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export summary for further analysis\n",
    "def export_summary_table(exp):\n",
    "    \"\"\"Export a summary table of all significant relationships.\"\"\"\n",
    "    sig_neurons = exp.get_significant_neurons()\n",
    "    \n",
    "    summary_data = []\n",
    "    for neuron_id, features in sig_neurons.items():\n",
    "        for feat in features:\n",
    "            stats = exp.get_neuron_feature_pair_stats(neuron_id, feat)\n",
    "            \n",
    "            summary_data.append({\n",
    "                'neuron_id': neuron_id,\n",
    "                'feature': feat,\n",
    "                'mi': stats.get('me', np.nan),\n",
    "                'pvalue': stats.get('pval', np.nan),\n",
    "                'optimal_delay': stats.get('shift_used', 0),\n",
    "                'effect_size': stats.get('me', 0) / stats.get('mean_bs', 1)\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(summary_data)\n",
    "    return df\n",
    "\n",
    "# Create summary\n",
    "summary_df = export_summary_table(exp)\n",
    "if not summary_df.empty:\n",
    "    print(\"Summary Statistics:\")\n",
    "    print(summary_df.groupby('feature')['mi'].describe())\n",
    "    \n",
    "    # Save to CSV (uncomment to save)\n",
    "    # summary_df.to_csv('neuron_selectivity_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices for Real Data\n",
    "\n",
    "### 1. Data Preparation\n",
    "- **Synchronization**: Ensure neural and behavioral data are perfectly aligned\n",
    "- **Sampling rates**: Downsample if needed (typically 10-30 Hz for calcium)\n",
    "- **Quality control**: Remove motion artifacts and dead neurons\n",
    "\n",
    "### 2. Feature Engineering\n",
    "- **Continuous features**: Consider smoothing noisy measurements\n",
    "- **Discrete features**: Ensure sufficient samples per category\n",
    "- **Derived features**: Create task-relevant variables (e.g., distance to goal)\n",
    "\n",
    "### 3. Computational Considerations\n",
    "- **Start small**: Test with subset of neurons first\n",
    "- **Parallelize**: Use n_jobs=-1 for all cores\n",
    "- **Save progress**: Export intermediate results\n",
    "- **Memory**: ~8 bytes per neuron Ã— timepoint Ã— shuffle\n",
    "\n",
    "### 4. Statistical Rigor\n",
    "- **Shuffle numbers**: 10,000+ for publication-quality results\n",
    "- **Multiple comparisons**: Built-in Holm-Bonferroni correction\n",
    "- **Effect sizes**: Report both significance and effect magnitude\n",
    "\n",
    "### 5. Validation\n",
    "- **Positive controls**: Include known relationships\n",
    "- **Negative controls**: Test with shuffled neuron identities\n",
    "- **Cross-validation**: Split data temporally\n",
    "\n",
    "## Troubleshooting Common Issues\n",
    "\n",
    "**Issue: No significant results**\n",
    "- Check behavioral variable coverage\n",
    "- Increase recording duration\n",
    "- Verify spike detection from calcium\n",
    "\n",
    "**Issue: Too many significant results**\n",
    "- Increase shuffle numbers\n",
    "- Check for global artifacts\n",
    "- Consider more stringent p-value threshold\n",
    "\n",
    "**Issue: Slow computation**\n",
    "- Downsample temporally\n",
    "- Reduce delay search window\n",
    "- Use two-stage testing\n",
    "- Parallelize with n_jobs\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "You now have the tools to:\n",
    "1. Load and format your neural data\n",
    "2. Run comprehensive INTENSE analysis\n",
    "3. Interpret results in biological context\n",
    "4. Export findings for publication\n",
    "\n",
    "For more advanced analyses:\n",
    "- See `examples/mixed_selectivity.py` for disentanglement\n",
    "- Use `compute_feat_feat_significance` for behavioral relationships\n",
    "- Explore `compute_cell_cell_significance` for neural correlations\n",
    "\n",
    "Happy discovering! ðŸ”¬ðŸ§ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}