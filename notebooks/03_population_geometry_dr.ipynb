{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "851fe0cb",
   "metadata": {},
   "source": [
    "# Population geometry & dimensionality reduction\n",
    "\n",
    "Individual neurons encode specific variables (Notebook 02), but the\n",
    "population *as a whole* forms a low-dimensional manifold whose geometry\n",
    "reflects the task.  [**DRIADA**](https://driada.readthedocs.io) provides\n",
    "a unified DR toolkit to extract, compare, and evaluate these manifolds.\n",
    "\n",
    "| Step | Notebook | What it does |\n",
    "|---|---|---|\n",
    "| **Overview** | [00 -- DRIADA overview](https://colab.research.google.com/github/iabs-neuro/driada/blob/main/notebooks/00_driada_overview.ipynb) | Core data structures, quick tour of INTENSE, DR, networks |\n",
    "| Neuron analysis | [01 -- Neuron analysis](https://colab.research.google.com/github/iabs-neuro/driada/blob/main/notebooks/01_data_loading_and_neurons.ipynb) | Spike reconstruction, kinetics optimization, quality metrics, surrogates |\n",
    "| Single-neuron selectivity | [02 -- INTENSE](https://colab.research.google.com/github/iabs-neuro/driada/blob/main/notebooks/02_selectivity_detection_intense.ipynb) | Detect which neurons encode which behavioral variables |\n",
    "| **Population geometry** | **03 -- this notebook** | Extract low-dimensional manifolds from population activity |\n",
    "| Network analysis | [04 -- Networks](https://colab.research.google.com/github/iabs-neuro/driada/blob/main/notebooks/04_network_analysis.ipynb) | Build and analyze cell-cell interaction graphs |\n",
    "| Putting it together | [05 -- Advanced](https://colab.research.google.com/github/iabs-neuro/driada/blob/main/notebooks/05_advanced_capabilities.ipynb) | Combine INTENSE + DR, leave-one-out importance, RSA, RNN analysis |\n",
    "\n",
    "**Sections:**\n",
    "\n",
    "1. **DR API quick reference** -- [`MVData`](https://driada.readthedocs.io/en/latest/api/dim_reduction/data_structures.html#driada.dim_reduction.data.MVData) wraps a matrix and provides\n",
    "   one-line access to 15 DR methods.\n",
    "2. **Method comparison** -- Benchmark PCA, Isomap, and UMAP on a Swiss\n",
    "   roll with quality metrics.\n",
    "3. **Circular manifold & dimensionality estimation** -- Head direction\n",
    "   cells encode a ring. Extract it via DR and estimate intrinsic\n",
    "   dimensionality.\n",
    "4. **Autoencoder-based DR** -- Standard AE with `continue_learning`,\n",
    "   Beta-VAE on the same circular data. Requires PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b10abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: revert to '!pip install -q driada' after v1.0.0 PyPI release\n",
    "!pip install -q git+https://github.com/iabs-neuro/driada.git@main\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from sklearn.datasets import make_swiss_roll\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# DRIADA dimensionality reduction\n",
    "from driada.dim_reduction import (\n",
    "    MVData,\n",
    "    dr_sequence,\n",
    "    knn_preservation_rate,\n",
    "    trustworthiness,\n",
    "    continuity,\n",
    "    stress,\n",
    ")\n",
    "from driada.dim_reduction.manifold_metrics import (\n",
    "    compute_embedding_alignment_metrics,\n",
    ")\n",
    "\n",
    "# DRIADA network analysis (used for ProximityGraph demo in Section 1.3)\n",
    "from driada.network import Network\n",
    "\n",
    "# DRIADA experiment / synthetic data\n",
    "from driada.experiment import generate_circular_manifold_exp\n",
    "\n",
    "# DRIADA dimensionality estimation\n",
    "from driada.dimensionality import (\n",
    "    eff_dim,\n",
    "    correlation_dimension,\n",
    "    geodesic_dimension,\n",
    "    pca_dimension,\n",
    ")\n",
    "\n",
    "# DRIADA visualization\n",
    "from driada.utils.visual import (\n",
    "    visualize_circular_manifold,\n",
    "    plot_trajectories,\n",
    "    DEFAULT_DPI,\n",
    ")\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59da7c75",
   "metadata": {},
   "source": [
    "## 1. DR API quick reference\n",
    "\n",
    "[`MVData`](https://driada.readthedocs.io/en/latest/api/dim_reduction/data_structures.html#driada.dim_reduction.data.MVData) wraps a *(n_features x n_samples)* matrix and provides one-line\n",
    "DR via [`get_embedding`](https://driada.readthedocs.io/en/latest/api/dim_reduction/data_structures.html#driada.dim_reduction.data.MVData.get_embedding).\n",
    "For multi-step pipelines, see [`dr_sequence`](https://driada.readthedocs.io/en/latest/api/dim_reduction/algorithms.html#driada.dim_reduction.sequences.dr_sequence).\n",
    "\n",
    "Each method is described by a\n",
    "[`DRMethod`](https://driada.readthedocs.io/en/latest/api/dim_reduction/data_structures.html#driada.dim_reduction.dr_base.DRMethod)\n",
    "object that specifies whether it is linear, requires a proximity graph,\n",
    "distance matrix, or neural network.\n",
    "\n",
    "| Method | Type | Graph | Disconnected |\n",
    "|---|---|---|---|\n",
    "| `pca` | Linear | -- | -- |\n",
    "| `le` / `auto_le` | Spectral | k-NN | No |\n",
    "| `dmaps` / `auto_dmaps` | Spectral | k-NN (weighted) | No |\n",
    "| `isomap` | Geodesic | k-NN | No |\n",
    "| `lle` / `hlle` | Local linear | k-NN | No |\n",
    "| `mvu` | SDP | k-NN | No |\n",
    "| `mds` | Distance | -- (needs dist matrix) | -- |\n",
    "| `tsne` | Probabilistic | -- | -- |\n",
    "| `umap` | Topological | k-NN | **Yes** |\n",
    "| `ae` / `vae` / `flexible_ae` | Neural network | -- | -- |\n",
    "\n",
    "Graph-based methods (9 of 15) construct a\n",
    "[`ProximityGraph`](https://driada.readthedocs.io/en/latest/api/dim_reduction/data_structures.html#driada.dim_reduction.graph.ProximityGraph)\n",
    "that inherits from\n",
    "[`Network`](https://driada.readthedocs.io/en/latest/api/network/core.html#driada.network.net_base.Network),\n",
    "giving access to spectral analysis, entropy, and community detection\n",
    "(see cells below and [Notebook 04](https://colab.research.google.com/github/iabs-neuro/driada/blob/main/notebooks/04_network_analysis.ipynb))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcd7c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Swiss roll data for demonstration\n",
    "n_samples = 1000\n",
    "X_raw, color = make_swiss_roll(n_samples, noise=0.1, random_state=42)\n",
    "X = X_raw.T  # Transpose to match MVData format (features x samples)\n",
    "\n",
    "# Create MVData object\n",
    "mvdata = MVData(X)\n",
    "\n",
    "emb_pca = mvdata.get_embedding(method='pca')\n",
    "print(f'PCA: {emb_pca.coords.shape}')\n",
    "\n",
    "emb_iso = mvdata.get_embedding(method='isomap')\n",
    "print(f'Isomap: {emb_iso.coords.shape}')\n",
    "\n",
    "emb_le = mvdata.get_embedding(method='le')\n",
    "print(f'Laplacian Eigenmaps: {emb_le.coords.shape}')\n",
    "\n",
    "emb_umap = mvdata.get_embedding(method='umap', n_neighbors=50, min_dist=0.3)\n",
    "print(f'UMAP: {emb_umap.coords.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31502ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize PCA, Isomap, UMAP, LE side by side\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, (emb, name) in enumerate(zip(\n",
    "    [emb_pca, emb_iso, emb_umap, emb_le],\n",
    "    ['PCA', 'Isomap', 'UMAP', 'Laplacian Eigenmaps'],\n",
    ")):\n",
    "    ax = axes[i]\n",
    "    coords = emb.coords\n",
    "\n",
    "    scatter = ax.scatter(\n",
    "        coords[0, :], coords[1, :], c=color, cmap='viridis', s=20, alpha=0.7\n",
    "    )\n",
    "    ax.set_title(f'{name} Embedding')\n",
    "    ax.set_xlabel('Component 1')\n",
    "    ax.set_ylabel('Component 2')\n",
    "\n",
    "    # Add colorbar to first subplot\n",
    "    if i == 0:\n",
    "        plt.colorbar(scatter, ax=ax, label='Position on roll')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e5b8bf",
   "metadata": {},
   "source": [
    "### Advanced: sequential DR, custom metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00517cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential dimensionality reduction (PCA -> UMAP)\n",
    "\n",
    "# Generate high-dimensional data\n",
    "high_dim_data = np.random.randn(100, 500)  # 100 features, 500 samples\n",
    "mvdata_highdim = MVData(high_dim_data)\n",
    "\n",
    "print('\\n1. High-dimensional data:')\n",
    "emb_10d = mvdata_highdim.get_embedding(method='pca', dim=10)\n",
    "print(f'   -> 10D embedding shape: {emb_10d.coords.shape}')\n",
    "\n",
    "mvdata_10d = MVData(emb_10d.coords)\n",
    "emb_2d = mvdata_10d.get_embedding(method='umap')\n",
    "print(f'   -> Final 2D embedding shape: {emb_2d.coords.shape}')\n",
    "\n",
    "print('\\n2. Using custom metrics:')\n",
    "emb_cosine = mvdata.get_embedding(method='isomap', metric='cosine')\n",
    "print(f'   -> Cosine metric embedding shape: {emb_cosine.coords.shape}')\n",
    "\n",
    "print('\\n3. Handling sparse data:')\n",
    "sparse_data = csr_matrix(X)\n",
    "print(f'   -> Sparse matrix shape: {sparse_data.shape}')\n",
    "mvdata_sparse = MVData(sparse_data)\n",
    "emb_sparse = mvdata_sparse.get_embedding(method='pca')\n",
    "print(f'   -> Sparse data embedding shape: {emb_sparse.coords.shape}')\n",
    "\n",
    "print('\\n4. Sequential dimensionality reduction (use high-dim data):')\n",
    "print('   Method 1 (intuitive - manual chaining):')\n",
    "emb1_seq = mvdata_highdim.get_embedding(method='pca', dim=20)\n",
    "mvdata2_seq = MVData(emb1_seq.coords)\n",
    "emb2_seq = mvdata2_seq.get_embedding(method='umap', dim=2)\n",
    "print(f'   -> Result shape: {emb2_seq.coords.shape}')\n",
    "\n",
    "print('\\n   Method 2 (recommended - using dr_sequence):')\n",
    "emb_seq = dr_sequence(mvdata_highdim, steps=[\n",
    "    ('pca', {'dim': 20}),\n",
    "    ('umap', {'dim': 2})\n",
    "])\n",
    "print(f'   -> Result shape: {emb_seq.coords.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678e0f56",
   "metadata": {},
   "source": [
    "### Graph structure behind DR\n",
    "\n",
    "Graph-based DR methods (Isomap, LLE, Laplacian Eigenmaps) don't just\n",
    "produce coordinates -- they construct an internal **proximity graph** where\n",
    "nodes are data points and edges connect neighbors. In DRIADA, this graph\n",
    "is a [`ProximityGraph`](https://driada.readthedocs.io/en/latest/api/dim_reduction/data_structures.html#driada.dim_reduction.graph.ProximityGraph)\n",
    "that **inherits from [`Network`](https://driada.readthedocs.io/en/latest/api/network/core.html#driada.network.net_base.Network)**,\n",
    "giving you access to spectral decomposition, entropy, community detection,\n",
    "and all other `Network` analysis methods.\n",
    "\n",
    "Access it via `embedding.graph` after running any graph-based method.\n",
    "For a full treatment of network spectral analysis, see\n",
    "[Notebook 04 -- Network analysis](https://colab.research.google.com/github/iabs-neuro/driada/blob/main/notebooks/04_network_analysis.ipynb).\n",
    "\n",
    "**Lost nodes:** When the k-NN graph is disconnected, DRIADA extracts the\n",
    "giant connected component and discards all nodes outside it. The removed\n",
    "indices are stored in `embedding.graph.lost_nodes` (a set, empty if no\n",
    "nodes were lost). The `max_deleted_nodes` parameter (default 0.5)\n",
    "controls the maximum fraction of points that can be discarded before an\n",
    "error is raised -- set it higher if your data is expected to have\n",
    "outliers or sparse regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea013b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pgraph = emb_iso.graph\n",
    "\n",
    "print(f\"Type: {type(pgraph).__name__}\")\n",
    "print(f\"  inherits from Network: {isinstance(pgraph, Network)}\")\n",
    "print(f\"Nodes: {pgraph.n}\")\n",
    "print(f\"Edges: {pgraph.adj.nnz // 2}\")\n",
    "print(f\"Mean degree: {pgraph.deg.mean():.1f}\")\n",
    "print(f\"Metric used: {pgraph.metric}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226be41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pgraph.diagonalize(mode='nlap')\n",
    "nlap_spectrum = pgraph.get_spectrum('nlap')\n",
    "ipr = pgraph.get_ipr('nlap')\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Normalized Laplacian spectrum\n",
    "sorted_spec = np.sort(np.real(nlap_spectrum))\n",
    "axes[0].plot(sorted_spec, 'o', markersize=2)\n",
    "axes[0].set_xlabel('Index')\n",
    "axes[0].set_ylabel('Eigenvalue')\n",
    "axes[0].set_title('Normalized Laplacian spectrum')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# IPR -- eigenvector localization\n",
    "axes[1].plot(np.sort(ipr), 'o', markersize=2)\n",
    "axes[1].axhline(1.0 / pgraph.n, color='r', linestyle='--',\n",
    "                label=f'1/N = {1.0/pgraph.n:.4f}')\n",
    "axes[1].set_xlabel('Eigenvector index (sorted)')\n",
    "axes[1].set_ylabel('IPR')\n",
    "axes[1].set_title('Inverse participation ratio')\n",
    "axes[1].legend(fontsize=9)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Thermodynamic entropy\n",
    "tlist = np.logspace(-2, 2, 50)\n",
    "entropy = pgraph.calculate_thermodynamic_entropy(tlist, norm=True)\n",
    "axes[2].semilogx(tlist, entropy, linewidth=2)\n",
    "axes[2].set_xlabel('Temperature')\n",
    "axes[2].set_ylabel('Entropy (bits)')\n",
    "axes[2].set_title('Von Neumann entropy S(t)')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Spectral analysis of Isomap k-NN graph', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Fiedler value: {sorted_spec[1]:.4f}')\n",
    "print(f'Spectral gap: {sorted_spec[1] - sorted_spec[0]:.4f}')\n",
    "print(f'Max entropy: {np.max(entropy):.2f} bits '\n",
    "      f'(upper bound = log2(N) = {np.log2(pgraph.n):.2f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c65097f",
   "metadata": {},
   "source": [
    "The Laplacian spectrum reveals the graph's connectivity structure:\n",
    "a large spectral gap indicates the graph is well-connected, while\n",
    "clustered eigenvalues near zero suggest loosely connected components.\n",
    "The IPR shows whether eigenvectors are delocalized (spread across\n",
    "all nodes) or localized (concentrated on a few).\n",
    "\n",
    "These same spectral tools apply to *any* [`Network`](https://driada.readthedocs.io/en/latest/api/network/core.html#driada.network.net_base.Network) -- functional\n",
    "connectivity from INTENSE, structural connectomes, or correlation\n",
    "networks. See [Notebook 04](https://colab.research.google.com/github/iabs-neuro/driada/blob/main/notebooks/04_network_analysis.ipynb)\n",
    "for the full spectral analysis toolkit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab254a0",
   "metadata": {},
   "source": [
    "## 2. Method comparison\n",
    "\n",
    "The API handles the mechanics. But which method should you use? The following\n",
    "benchmark on a Swiss Roll manifold reveals the trade-offs.\n",
    "\n",
    "DRIADA provides four quality metrics to evaluate DR embeddings:\n",
    "\n",
    "- [`knn_preservation_rate`](https://driada.readthedocs.io/en/latest/api/dim_reduction/manifold_metrics.html#driada.dim_reduction.manifold_metrics.knn_preservation_rate) -- fraction of original k nearest neighbors preserved.\n",
    "- [`trustworthiness`](https://driada.readthedocs.io/en/latest/api/dim_reduction/manifold_metrics.html#driada.dim_reduction.manifold_metrics.trustworthiness) -- are embedding neighbors real neighbors?\n",
    "- [`continuity`](https://driada.readthedocs.io/en/latest/api/dim_reduction/manifold_metrics.html#driada.dim_reduction.manifold_metrics.continuity) -- do true neighbors stay close?\n",
    "- [`stress`](https://driada.readthedocs.io/en/latest/api/dim_reduction/manifold_metrics.html#driada.dim_reduction.manifold_metrics.stress) -- normalized distance distortion.\n",
    "\n",
    "We compare PCA, Isomap, and UMAP on a Swiss roll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f88354d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare PCA, Isomap, UMAP on Swiss roll\n",
    "X_swiss, color_swiss = make_swiss_roll(1000, noise=0.05, random_state=42)\n",
    "\n",
    "methods_cmp = {\n",
    "    'PCA': {},\n",
    "    'Isomap': {'n_neighbors': 10, 'max_deleted_nodes': 0.3},  # 10 neighbors: local geodesics\n",
    "    'UMAP': {'n_neighbors': 15, 'min_dist': 0.1},  # min_dist: tighter clusters\n",
    "}\n",
    "cmp_results = {}\n",
    "\n",
    "for name, params in methods_cmp.items():\n",
    "    mvd = MVData(X_swiss.T)\n",
    "    t0 = time.time()\n",
    "    emb = mvd.get_embedding(method=name.lower(), **params)\n",
    "    dt = time.time() - t0\n",
    "    coords = emb.coords.T\n",
    "\n",
    "    # Handle lost nodes for graph-based methods\n",
    "    data_cmp, color_cmp = X_swiss, color_swiss\n",
    "    if hasattr(emb, 'graph') and hasattr(emb.graph, 'lost_nodes') and len(emb.graph.lost_nodes) > 0:\n",
    "        mask = np.ones(len(X_swiss), dtype=bool)\n",
    "        mask[emb.graph.lost_nodes] = False\n",
    "        data_cmp, color_cmp = X_swiss[mask], color_swiss[mask]\n",
    "\n",
    "    cmp_results[name] = {\n",
    "        'coords': coords, 'color': color_cmp, 'time': dt,\n",
    "        'knn': knn_preservation_rate(data_cmp, coords, k=10),\n",
    "        'trust': trustworthiness(data_cmp, coords, k=10),\n",
    "        'cont': continuity(data_cmp, coords, k=10),\n",
    "        'stress': stress(data_cmp, coords, normalized=True),\n",
    "    }\n",
    "    print(f'{name:8s}  k-NN={cmp_results[name][\"knn\"]:.3f}  '\n",
    "          f'Trust={cmp_results[name][\"trust\"]:.3f}  '\n",
    "          f'Stress={cmp_results[name][\"stress\"]:.3f}  '\n",
    "          f'Time={dt:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb05743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Swiss roll embeddings\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for ax, (name, res) in zip(axes, cmp_results.items()):\n",
    "    sc = ax.scatter(\n",
    "        res['coords'][:, 0], res['coords'][:, 1],\n",
    "        c=res['color'], cmap='viridis', s=20, alpha=0.7,\n",
    "    )\n",
    "    ax.set_title(\n",
    "        f'{name}\\n'\n",
    "        f'k-NN={res[\"knn\"]:.3f}  Trust={res[\"trust\"]:.3f}'\n",
    "    )\n",
    "    ax.set_xlabel('Dim 1')\n",
    "    ax.set_ylabel('Dim 2')\n",
    "\n",
    "plt.suptitle('Swiss roll embeddings', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae8e980",
   "metadata": {},
   "source": [
    "## 3. Circular manifold & dimensionality estimation\n",
    "\n",
    "Synthetic benchmarks show what methods *can* do; real neural data shows what\n",
    "they *must* handle. Head direction cells encode a circular variable — a\n",
    "topology that some DR methods preserve better than others.\n",
    "\n",
    "Head direction cells encode a ring. We generate 100 HD cells with\n",
    "[`generate_circular_manifold_exp`](https://driada.readthedocs.io/en/latest/api/experiment/synthetic.html#driada.experiment.generate_circular_manifold_exp)\n",
    "and estimate intrinsic dimensionality using the\n",
    "[`driada.dimensionality`](https://driada.readthedocs.io/en/latest/api/dimensionality/index.html) module.\n",
    "\n",
    "This module provides several estimators:\n",
    "- **Linear:** [`pca_dimension`](https://driada.readthedocs.io/en/latest/api/dimensionality/linear.html#driada.dimensionality.linear.pca_dimension) (variance threshold), [`effective_rank`](https://driada.readthedocs.io/en/latest/api/dimensionality/linear.html#driada.dimensionality.linear.effective_rank), [`pca_dimension_profile`](https://driada.readthedocs.io/en/latest/api/dimensionality/linear.html#driada.dimensionality.linear.pca_dimension_profile)\n",
    "- **Intrinsic:** [`correlation_dimension`](https://driada.readthedocs.io/en/latest/api/dimensionality/intrinsic.html#driada.dimensionality.intrinsic.correlation_dimension), [`geodesic_dimension`](https://driada.readthedocs.io/en/latest/api/dimensionality/intrinsic.html#driada.dimensionality.intrinsic.geodesic_dimension), [`nn_dimension`](https://driada.readthedocs.io/en/latest/api/dimensionality/intrinsic.html#driada.dimensionality.intrinsic.nn_dimension) (TWO-NN)\n",
    "- **Effective:** [`eff_dim`](https://driada.readthedocs.io/en/latest/api/dimensionality/effective.html#driada.dimensionality.effective.eff_dim) (Renyi entropy of eigenvalues)\n",
    "\n",
    "Below we use a subset of these, compare real vs shuffled data,\n",
    "and extract the circular manifold via DR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d28afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_dimensionality(neural_data, methods=None, ds=1):\n",
    "    \"\"\"Estimate intrinsic dimensionality using multiple DRIADA methods.\"\"\"\n",
    "    if methods is None:\n",
    "        methods = [\n",
    "            'pca_90', 'pca_95', 'participation_ratio',\n",
    "            'correlation_dim', 'geodesic_dim',\n",
    "        ]\n",
    "\n",
    "    dim_estimates = {}\n",
    "\n",
    "    # Downsample data if requested\n",
    "    if ds > 1:\n",
    "        neural_data_ds = neural_data[:, ::ds]\n",
    "        print(f'  Downsampled: {neural_data.shape} -> {neural_data_ds.shape}')\n",
    "    else:\n",
    "        neural_data_ds = neural_data\n",
    "\n",
    "    # Transpose data for methods that expect (n_samples, n_features)\n",
    "    data_transposed = neural_data_ds.T\n",
    "\n",
    "    # Linear methods\n",
    "    if 'pca_90' in methods:\n",
    "        dim_estimates['pca_90'] = pca_dimension(data_transposed, threshold=0.90)\n",
    "    if 'pca_95' in methods:\n",
    "        dim_estimates['pca_95'] = pca_dimension(data_transposed, threshold=0.95)\n",
    "\n",
    "    # Nonlinear intrinsic methods\n",
    "    if 'correlation_dim' in methods:\n",
    "        try:\n",
    "            print('  Computing correlation dimension...')\n",
    "            dim_estimates['correlation_dim'] = correlation_dimension(data_transposed)\n",
    "        except Exception as e:\n",
    "            print(f'  Warning: correlation_dimension failed: {e}')\n",
    "            dim_estimates['correlation_dim'] = np.nan\n",
    "\n",
    "    if 'geodesic_dim' in methods:\n",
    "        try:\n",
    "            print('  Computing geodesic dimension (this may take time)...')\n",
    "            dim_estimates['geodesic_dim'] = geodesic_dimension(\n",
    "                data_transposed, k=20, mode='fast', factor=4\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f'  Warning: geodesic_dimension failed: {e}')\n",
    "            dim_estimates['geodesic_dim'] = np.nan\n",
    "\n",
    "    # Effective dimensionality (participation ratio)\n",
    "    if 'participation_ratio' in methods:\n",
    "        dim_estimates['participation_ratio'] = eff_dim(\n",
    "            neural_data_ds.T, enable_correction=False, q=2\n",
    "        )\n",
    "\n",
    "    return dim_estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f57b6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('1. Generating head direction cell population...')\n",
    "\n",
    "# Generate synthetic head direction cells\n",
    "exp_circ, info_circ = generate_circular_manifold_exp(\n",
    "    n_neurons=100,\n",
    "    duration=600,  # 10 minutes\n",
    "    kappa=4.0,     # Tuning width\n",
    "    seed=42,\n",
    "    verbose=True,\n",
    "    return_info=True,\n",
    ")\n",
    "\n",
    "# Extract neural activity and true head directions\n",
    "neural_data_circ = exp_circ.calcium.scdata  # Shape: (n_neurons, n_timepoints)\n",
    "true_angles = info_circ['head_direction']   # Ground truth angles\n",
    "\n",
    "print(f'\\nGenerated {neural_data_circ.shape[0]} neurons, '\n",
    "      f'{neural_data_circ.shape[1]} timepoints')\n",
    "print(f'Neural activity shape: {neural_data_circ.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b40422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate intrinsic dimensionality\n",
    "print('\\n2. Estimating intrinsic dimensionality of neural population...')\n",
    "print('-' * 50)\n",
    "\n",
    "dim_methods = [\n",
    "    'pca_90', 'pca_95', 'participation_ratio',\n",
    "    'correlation_dim', 'geodesic_dim',\n",
    "]\n",
    "\n",
    "# Use ds=5 downsampling for faster computation\n",
    "dim_estimates = estimate_dimensionality(\n",
    "    neural_data_circ, methods=dim_methods, ds=5\n",
    ")\n",
    "\n",
    "print('Dimensionality estimates:')\n",
    "for method, estimate in dim_estimates.items():\n",
    "    print(f'  {method:20s}: {estimate:.2f}')\n",
    "\n",
    "print('\\nNote: Head direction cells should have intrinsic dimensionality ~ 1')\n",
    "print('      (circular manifold), but finite sampling may increase estimates')\n",
    "\n",
    "# Compare with temporally shuffled data to demonstrate manifold structure\n",
    "print('\\n2b. Comparing with temporally shuffled data (destroys manifold)...')\n",
    "print('-' * 50)\n",
    "\n",
    "# Get shuffled calcium data from experiment\n",
    "shuffled_calcium = exp_circ.get_multicell_shuffled_calcium()\n",
    "\n",
    "# Estimate dimensionality on shuffled data\n",
    "dim_estimates_shuffled = estimate_dimensionality(\n",
    "    shuffled_calcium, methods=dim_methods, ds=5\n",
    ")\n",
    "\n",
    "print('\\nDimensionality estimates (SHUFFLED data):')\n",
    "for method, estimate in dim_estimates_shuffled.items():\n",
    "    print(f'  {method:20s}: {estimate:.2f}')\n",
    "\n",
    "print('\\nComparison (Real vs Shuffled):')\n",
    "print(f'{\"Method\":<20s} {\"Real\":>8s} {\"Shuffled\":>8s} {\"Increase\":>10s}')\n",
    "print('-' * 50)\n",
    "for method in dim_methods:\n",
    "    real = dim_estimates[method]\n",
    "    shuffled = dim_estimates_shuffled[method]\n",
    "    increase = ((shuffled - real) / real) * 100\n",
    "    print(f'{method:<20s} {real:8.2f} {shuffled:8.2f} {increase:+9.1f}%')\n",
    "\n",
    "print('\\nInterpretation: Temporal shuffling destroys the circular manifold structure,')\n",
    "print('                dramatically increasing dimensionality.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c71a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot eigenvalue spectrum\n",
    "print('\\n3. Plotting eigenvalue spectrum...')\n",
    "\n",
    "# Compute correlation matrix\n",
    "data_centered = neural_data_circ - np.mean(neural_data_circ, axis=1, keepdims=True)\n",
    "corr_mat = np.corrcoef(data_centered)\n",
    "\n",
    "# Get eigenvalues\n",
    "eigenvalues = np.linalg.eigvalsh(corr_mat)[::-1]  # Descending order\n",
    "eigenvalues = eigenvalues[eigenvalues > 0]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Eigenvalue spectrum\n",
    "ax1.plot(eigenvalues, 'o-', markersize=4)\n",
    "ax1.set_xlabel('Component')\n",
    "ax1.set_ylabel('Eigenvalue')\n",
    "ax1.set_title('Eigenvalue spectrum')\n",
    "ax1.set_yscale('log')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Cumulative variance explained\n",
    "cumvar = np.cumsum(eigenvalues) / np.sum(eigenvalues)\n",
    "ax2.plot(cumvar, 'o-', markersize=4)\n",
    "ax2.axhline(0.9, color='r', linestyle='--', label='90% variance')\n",
    "ax2.axhline(0.95, color='orange', linestyle='--', label='95% variance')\n",
    "ax2.set_xlabel('Number of Components')\n",
    "ax2.set_ylabel('Cumulative Variance Explained')\n",
    "ax2.set_title('Cumulative variance explained')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9c168d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply dimensionality reduction using MVData\n",
    "print('\\n4. Applying dimensionality reduction methods using MVData...')\n",
    "print('-' * 50)\n",
    "\n",
    "# Create MVData object from calcium data with downsampling\n",
    "downsampling_circ = 10  # use every 10th frame for speed\n",
    "mvdata_circ = MVData(neural_data_circ, downsampling=downsampling_circ)\n",
    "\n",
    "# Downsample true angles to match\n",
    "true_angles_ds = true_angles[::downsampling_circ]\n",
    "\n",
    "# Dictionary to store embeddings\n",
    "embeddings_dict_circ = {}\n",
    "\n",
    "# PCA\n",
    "print('- PCA...')\n",
    "pca_embedding_circ = mvdata_circ.get_embedding(method='pca', dim=2)\n",
    "embeddings_dict_circ['PCA'] = pca_embedding_circ.coords.T\n",
    "print(\n",
    "    f'  First 2 PCs explain '\n",
    "    f'{100 * sum(pca_embedding_circ.reducer_.explained_variance_ratio_):.1f}% of variance'\n",
    ")\n",
    "\n",
    "# Isomap\n",
    "print('- Isomap...')\n",
    "isomap_embedding_circ = mvdata_circ.get_embedding(\n",
    "    method='isomap', dim=2, n_neighbors=50\n",
    ")\n",
    "embeddings_dict_circ['Isomap'] = isomap_embedding_circ.coords.T\n",
    "\n",
    "# UMAP with increased parameters for better global structure\n",
    "print('- UMAP...')\n",
    "umap_embedding_circ = mvdata_circ.get_embedding(\n",
    "    method='umap', n_components=2, n_neighbors=100, min_dist=0.5\n",
    ")\n",
    "embeddings_dict_circ['UMAP'] = umap_embedding_circ.coords.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebc4d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize extracted manifolds\n",
    "print('\\n5. Visualizing extracted manifolds...')\n",
    "\n",
    "# Create embedding comparison visualization\n",
    "embeddings_list_circ = [\n",
    "    embeddings_dict_circ[m] for m in ['PCA', 'Isomap', 'UMAP']\n",
    "]\n",
    "fig_embedding = visualize_circular_manifold(\n",
    "    embeddings_list_circ, true_angles_ds, ['PCA', 'Isomap', 'UMAP']\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# Trajectory visualization\n",
    "print('\\n6. Analyzing temporal continuity of extracted manifolds...')\n",
    "\n",
    "# Use only first 1000 timepoints for trajectory visualization\n",
    "traj_len = min(1000, embeddings_dict_circ['PCA'].shape[0])\n",
    "trajectories_dict = {\n",
    "    method: emb[:traj_len] for method, emb in embeddings_dict_circ.items()\n",
    "}\n",
    "\n",
    "fig3 = plot_trajectories(\n",
    "    embeddings=trajectories_dict,\n",
    "    trajectory_kwargs={'arrow_spacing': 50, 'linewidth': 0.5, 'alpha': 0.5},\n",
    "    figsize=(15, 5),\n",
    "    dpi=DEFAULT_DPI,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f188990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print('\\n7. Summary of manifold extraction quality:')\n",
    "print('-' * 60)\n",
    "print(f'{\"Method\":10s} | {\"Correlation\":12s} | {\"Mean Error\":12s} | {\"Quality\":8s}')\n",
    "print('-' * 60)\n",
    "\n",
    "for method, embedding in embeddings_dict_circ.items():\n",
    "    # Use manifold metrics API\n",
    "    alignment_metrics = compute_embedding_alignment_metrics(\n",
    "        embedding, true_angles_ds, 'circular'\n",
    "    )\n",
    "    r = alignment_metrics['correlation']\n",
    "    error = alignment_metrics['error']\n",
    "\n",
    "    # Quality assessment\n",
    "    if abs(r) > 0.95:\n",
    "        quality_str = 'Excellent'\n",
    "    elif abs(r) > 0.85:\n",
    "        quality_str = 'Good'\n",
    "    elif abs(r) > 0.70:\n",
    "        quality_str = 'Fair'\n",
    "    else:\n",
    "        quality_str = 'Poor'\n",
    "\n",
    "    print(f'{method:10s} | {r:12.3f} | {error:9.3f} rad | {quality_str:8s}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab0d4cf",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "- Head direction cells encode a 1D ring, but finite sampling, noise, and\n",
    "  calcium dynamics inflate dimensionality estimates above the true value.\n",
    "- Temporal shuffling destroys manifold structure (dimensionality increases),\n",
    "  confirming the manifold is real.\n",
    "- Nonlinear methods (Isomap, UMAP) better preserve circular topology.\n",
    "- PCA captures variance but may distort circular structure.\n",
    "- Higher `n_neighbors` helps preserve global structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ec7e85",
   "metadata": {},
   "source": [
    "## 4. Autoencoder-based DR\n",
    "\n",
    "The methods above (PCA, Isomap, UMAP) use fixed neighborhoods or geodesics.\n",
    "How do neural network methods handle the same circular manifold data?\n",
    "Autoencoders learn a flexible nonlinear mapping — at the cost of more\n",
    "hyperparameters and training time.\n",
    "\n",
    "Neural network DR via [`flexible_ae`](https://driada.readthedocs.io/en/latest/api/dim_reduction/neural_methods.html): **standard autoencoder** (AE) with\n",
    "`continue_learning`, and **Beta-VAE** with KL divergence, compared against PCA.\n",
    "Key parameters: `architecture` (`'ae'` or `'vae'`) selects the model type,\n",
    "and `continue_learning` resumes training without resetting weights.\n",
    "Requires PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ee5b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import torch  # noqa: F401\n",
    "    HAS_TORCH = True\n",
    "    print('PyTorch available -- autoencoder examples will run.')\n",
    "except ImportError:\n",
    "    HAS_TORCH = False\n",
    "    print(\n",
    "        'PyTorch not found. Install with: pip install torch\\n'\n",
    "        'Autoencoder cells will be skipped.'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97a65b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_TORCH:\n",
    "    print('[1] Reusing head direction cell data from Section 3')\n",
    "    print('-' * 40)\n",
    "    calcium_ae = neural_data_circ  # (n_neurons, n_timepoints) from Section 3\n",
    "    head_direction_ae = true_angles  # from Section 3\n",
    "    print(f'  Calcium shape: {calcium_ae.shape}')\n",
    "    print(f'  Head direction shape: {head_direction_ae.shape}')\n",
    "\n",
    "    mvdata_ae = MVData(calcium_ae, downsampling=5, verbose=False)\n",
    "    color_ae = head_direction_ae[::5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eefcb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_TORCH:\n",
    "    print('\\n[2] Standard autoencoder')\n",
    "    print('-' * 40)\n",
    "\n",
    "    # Train for 5 epochs (not fully converged)\n",
    "    emb_ae = mvdata_ae.get_embedding(\n",
    "        method='flexible_ae',\n",
    "        dim=2,\n",
    "        architecture='ae',\n",
    "        inter_dim=64,  # bottleneck width\n",
    "        epochs=5,  # under-trained for demo\n",
    "        lr=1e-3,\n",
    "        feature_dropout=0.1,\n",
    "        loss_components=[{'name': 'reconstruction', 'weight': 1.0, 'loss_type': 'mse'}],\n",
    "        verbose=False,\n",
    "    )\n",
    "    print(f'  After 5 epochs   - loss: {emb_ae.nn_loss:.4f}')\n",
    "\n",
    "    # Continue training for 25 more epochs\n",
    "    emb_ae.continue_learning(25, lr=1e-3, verbose=False)\n",
    "    print(f'  After 25 more    - loss: {emb_ae.nn_loss:.4f}')\n",
    "\n",
    "    # Fine-tune with lower learning rate\n",
    "    emb_ae.continue_learning(20, lr=1e-4, verbose=False)\n",
    "    print(f'  After 20 fine-tune - loss: {emb_ae.nn_loss:.4f}')\n",
    "\n",
    "    print('\\n[3] Beta-VAE (beta=4.0)')\n",
    "    print('-' * 40)\n",
    "    emb_vae = mvdata_ae.get_embedding(\n",
    "        method='flexible_ae',\n",
    "        dim=2,\n",
    "        architecture='vae',\n",
    "        inter_dim=64,\n",
    "        epochs=150,\n",
    "        lr=1e-3,\n",
    "        feature_dropout=0.1,\n",
    "        loss_components=[\n",
    "            {'name': 'reconstruction', 'weight': 1.0, 'loss_type': 'mse'},\n",
    "            {'name': 'beta_vae', 'weight': 1.0, 'beta': 4.0},  # beta > 1: encourages disentanglement\n",
    "        ],\n",
    "        verbose=False,\n",
    "    )\n",
    "    print(f'  Embedding shape: {emb_vae.coords.shape}')\n",
    "    print(f'  Test loss (reconstruction + KL): {emb_vae.nn_loss:.4f}')\n",
    "\n",
    "    print('\\n[4] PCA (for comparison)')\n",
    "    print('-' * 40)\n",
    "    emb_pca_ae = mvdata_ae.get_embedding(method='pca', dim=2)\n",
    "    print(f'  Embedding shape: {emb_pca_ae.coords.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49d83ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_TORCH:\n",
    "    print('[5] Creating comparison plot')\n",
    "    print('-' * 40)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    embeddings_ae = [\n",
    "        (emb_pca_ae, 'PCA'),\n",
    "        (emb_ae, 'AE (5 + 25 + 20 epochs)'),\n",
    "        (emb_vae, 'Beta-VAE'),\n",
    "    ]\n",
    "\n",
    "    for ax, (emb, title) in zip(axes, embeddings_ae):\n",
    "        coords = emb.coords  # (dim, n_samples)\n",
    "        sc = ax.scatter(\n",
    "            coords[0], coords[1], c=color_ae, cmap='hsv',\n",
    "            s=2, alpha=0.5, vmin=0, vmax=2 * np.pi\n",
    "        )\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel('Dim 1')\n",
    "        ax.set_ylabel('Dim 2')\n",
    "\n",
    "    fig.colorbar(sc, ax=axes[-1], label='Head direction (rad)')\n",
    "    plt.suptitle('Circular manifold recovery (colored by head direction)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80b330f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_TORCH:\n",
    "    print('[6] Alignment metrics for autoencoder methods')\n",
    "    print('-' * 60)\n",
    "    print(f'{\"Method\":20s} | {\"Correlation\":12s} | {\"Mean Error\":12s} | {\"Quality\":8s}')\n",
    "    print('-' * 60)\n",
    "\n",
    "    ae_embeddings = {\n",
    "        'PCA': emb_pca_ae.coords.T,\n",
    "        'AE': emb_ae.coords.T,\n",
    "        'Beta-VAE': emb_vae.coords.T,\n",
    "    }\n",
    "\n",
    "    for method, embedding in ae_embeddings.items():\n",
    "        alignment_metrics = compute_embedding_alignment_metrics(\n",
    "            embedding, color_ae, 'circular'\n",
    "        )\n",
    "        r = alignment_metrics['correlation']\n",
    "        error = alignment_metrics['error']\n",
    "\n",
    "        if abs(r) > 0.95:\n",
    "            quality_str = 'Excellent'\n",
    "        elif abs(r) > 0.85:\n",
    "            quality_str = 'Good'\n",
    "        elif abs(r) > 0.70:\n",
    "            quality_str = 'Fair'\n",
    "        else:\n",
    "            quality_str = 'Poor'\n",
    "\n",
    "        print(f'{method:20s} | {r:12.3f} | {error:9.3f} rad | {quality_str:8s}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c080217e",
   "metadata": {},
   "source": [
    "## Further reading\n",
    "\n",
    "Standalone examples (run directly, no external data needed):\n",
    "- [compare_dr_methods](https://github.com/iabs-neuro/driada/tree/main/examples/compare_dr_methods) -- DR method comparison with quality metrics\n",
    "- [autoencoder_dr](https://github.com/iabs-neuro/driada/tree/main/examples/autoencoder_dr) -- AE and Beta-VAE on circular manifold data\n",
    "- [circular_manifold](https://github.com/iabs-neuro/driada/tree/main/examples/circular_manifold) -- Dimensionality estimation and manifold extraction\n",
    "- [intense_dr_pipeline](https://github.com/iabs-neuro/driada/tree/main/examples/intense_dr_pipeline) -- INTENSE-guided neuron selection for DR\n",
    "\n",
    "[All examples](https://github.com/iabs-neuro/driada/tree/main/examples)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
