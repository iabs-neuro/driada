{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e823f33e",
   "metadata": {},
   "source": [
    "# Network analysis\n",
    "\n",
    "Neurons do not act in isolation -- their pairwise interactions form a\n",
    "network whose topology reveals modular organization and hub neurons.\n",
    "[**DRIADA**](https://driada.readthedocs.io) builds these networks from\n",
    "significance-tested mutual information and provides both structural and\n",
    "spectral analysis tools.\n",
    "\n",
    "| Step | Notebook | What it does |\n",
    "|---|---|---|\n",
    "| **Overview** | [00 -- DRIADA overview](https://colab.research.google.com/github/iabs-neuro/driada/blob/main/notebooks/00_driada_overview.ipynb) | Core data structures, quick tour of INTENSE, DR, networks |\n",
    "| Load & inspect | [01 -- Data loading](https://colab.research.google.com/github/iabs-neuro/driada/blob/main/notebooks/01_data_loading_and_neurons.ipynb) | Wrap your recording into an `Experiment`, reconstruct spikes, assess quality |\n",
    "| Single-neuron selectivity | [02 -- INTENSE](https://colab.research.google.com/github/iabs-neuro/driada/blob/main/notebooks/02_selectivity_detection_intense.ipynb) | Detect which neurons encode which behavioral variables |\n",
    "| Population geometry | [03 -- Dimensionality reduction](https://colab.research.google.com/github/iabs-neuro/driada/blob/main/notebooks/03_population_geometry_dr.ipynb) | Extract low-dimensional manifolds from population activity |\n",
    "| **Network analysis** | **04 -- this notebook** | Build and analyze cell-cell interaction graphs |\n",
    "| Putting it together | [05 -- Advanced](https://colab.research.google.com/github/iabs-neuro/driada/blob/main/notebooks/05_advanced_capabilities.ipynb) | Combine INTENSE + DR, leave-one-out importance, RSA, RNN analysis |\n",
    "\n",
    "**Overview:** INTENSE computes pairwise mutual-information between\n",
    "all neuron pairs and determines which connections are statistically\n",
    "significant via permutation testing. The resulting adjacency matrix\n",
    "defines a *functional network* whose topology reveals modular\n",
    "organization, hub neurons, and spectral fingerprints.\n",
    "\n",
    "**Sections:**\n",
    "\n",
    "1. **Network structure** -- Binary and weighted network properties,\n",
    "   module detection (Louvain), degree distribution, null model\n",
    "   comparison (degree-preserving randomization).\n",
    "2. **Spectral analysis** -- Eigendecomposition of adjacency and\n",
    "   normalized Laplacian matrices. IPR (eigenvector localization),\n",
    "   complex spacing ratios, localization signatures, thermodynamic\n",
    "   entropy, communicability, hyperbolicity, Laplacian Eigenmaps\n",
    "   embedding, and directed-network eigenvalue analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ebba88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: revert to '!pip install -q driada' after v1.0.0 PyPI release\n",
    "!pip install -q git+https://github.com/iabs-neuro/driada.git@main\n",
    "%matplotlib inline\n",
    "\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import networkx.algorithms.community as nx_comm\n",
    "import scipy.sparse as sp\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "from driada.network import Network\n",
    "from driada.network.matrix_utils import turn_to_partially_directed\n",
    "from driada.intense import compute_cell_cell_significance\n",
    "from driada.experiment.synthetic import generate_tuned_selectivity_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542bc150",
   "metadata": {},
   "source": [
    "## Building the network\n",
    "\n",
    "Create a synthetic modular population (120 neurons, 6 functional\n",
    "groups) with [`generate_tuned_selectivity_exp`](https://driada.readthedocs.io/en/latest/api/experiment/synthetic.html#driada.experiment.synthetic.generators.generate_tuned_selectivity_exp),\n",
    "compute pairwise significance with\n",
    "[`compute_cell_cell_significance`](https://driada.readthedocs.io/en/latest/api/intense/pipelines.html#driada.intense.pipelines.compute_cell_cell_significance),\n",
    "and construct a [`Network`](https://driada.readthedocs.io/en/latest/api/network/core.html#driada.network.net_base.Network)\n",
    "object.  This network is reused in both analysis sections below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267c8f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_modular_experiment(duration=300, seed=42):\n",
    "    \"\"\"\n",
    "    Create synthetic experiment with hierarchical modular structure.\n",
    "\n",
    "    Creates 120 neurons in 6 functional groups:\n",
    "    - 3 single-feature modules (30 neurons each): respond to event_0, event_1, or event_2\n",
    "    - 3 dual-feature modules (10 neurons each): respond to pairs of events in OR mode\n",
    "      (event_0 OR event_1, event_0 OR event_2, event_1 OR event_2)\n",
    "\n",
    "    This creates a realistic hierarchical network with both specialized\n",
    "    and multi-selective neurons.\n",
    "    \"\"\"\n",
    "    # Create population with mixed selectivity\n",
    "    population = [\n",
    "        # Single-feature modules (30 neurons each)\n",
    "        {\n",
    "            \"name\": \"event_0_cells\",\n",
    "            \"count\": 30,\n",
    "            \"features\": [\"event_0\"],\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"event_1_cells\",\n",
    "            \"count\": 30,\n",
    "            \"features\": [\"event_1\"],\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"event_2_cells\",\n",
    "            \"count\": 30,\n",
    "            \"features\": [\"event_2\"],\n",
    "        },\n",
    "        # Dual-feature modules (10 neurons each, OR combination)\n",
    "        {\n",
    "            \"name\": \"event_0_or_1_cells\",\n",
    "            \"count\": 10,\n",
    "            \"features\": [\"event_0\", \"event_1\"],\n",
    "            \"combination\": \"or\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"event_0_or_2_cells\",\n",
    "            \"count\": 10,\n",
    "            \"features\": [\"event_0\", \"event_2\"],\n",
    "            \"combination\": \"or\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"event_1_or_2_cells\",\n",
    "            \"count\": 10,\n",
    "            \"features\": [\"event_1\", \"event_2\"],\n",
    "            \"combination\": \"or\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # Generate experiment with hierarchical structure\n",
    "    exp = generate_tuned_selectivity_exp(\n",
    "        population=population,\n",
    "        n_discrete_features=3,  # Three distinct events\n",
    "        duration=duration,\n",
    "        fps=20.0,\n",
    "        baseline_rate=0.05,\n",
    "        peak_rate=2.0,\n",
    "        decay_time=2.0,\n",
    "        calcium_noise=0.02,\n",
    "        seed=seed,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    # Return info about true module structure\n",
    "    n_modules = 6\n",
    "    module_sizes = [30, 30, 30, 10, 10, 10]\n",
    "\n",
    "    return exp, n_modules, module_sizes\n",
    "\n",
    "\n",
    "print(\"Creating synthetic experiment with hierarchical modular structure...\")\n",
    "print(\"  120 neurons: 30+30+30 (single-feature) + 10+10+10 (dual-feature)\")\n",
    "exp, n_modules_true, module_sizes_true = create_modular_experiment(duration=300)\n",
    "print(f\"Created {len(exp.neurons)} neurons in {n_modules_true} functional groups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecd473f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick look at the calcium activity\n",
    "fig, ax = plt.subplots(figsize=(14, 4))\n",
    "ax.imshow(exp.calcium.data, aspect='auto', cmap='hot', interpolation='none')\n",
    "ax.set_xlabel('Frame')\n",
    "ax.set_ylabel('Neuron')\n",
    "ax.set_title(f'Calcium traces ({exp.n_cells} neurons, {exp.n_frames} frames)')\n",
    "plt.colorbar(ax.images[0], ax=ax, fraction=0.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e19f253",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Computing cell-cell functional connectivity\")\n",
    "\n",
    "sim_mat, sig_mat, pval_mat, cells_list, info = compute_cell_cell_significance(\n",
    "    exp,\n",
    "    data_type=\"calcium\",\n",
    "    ds=5,                      # Downsample by 5x for speed (~5x faster)\n",
    "    n_shuffles_stage1=100,     # Stage 1 screening\n",
    "    n_shuffles_stage2=10000,   # FFT makes high shuffle counts fast!\n",
    "    pval_thr=0.001,\n",
    "    multicomp_correction=\"holm\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\nAnalysis complete!\")\n",
    "print(f\"Total neuron pairs: {len(cells_list) * (len(cells_list)-1) / 2:.0f}\")\n",
    "print(f\"Significant connections: {np.sum(sig_mat) / 2:.0f}\")  # Divide by 2 for symmetry\n",
    "print(f\"Connection density: {np.sum(sig_mat) / (len(cells_list) * (len(cells_list)-1)):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378afad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating functional network\")\n",
    "\n",
    "sig_sparse = sp.csr_matrix(sig_mat)\n",
    "net_binary = Network(\n",
    "    adj=sig_sparse,\n",
    "    preprocessing=\"giant_cc\",\n",
    "    name=\"Neural Functional Network (Binary)\"\n",
    ")\n",
    "\n",
    "# Create weighted network (similarity values for significant edges only)\n",
    "weighted_mat = sim_mat * sig_mat  # Zero out non-significant\n",
    "weighted_sparse = sp.csr_matrix(weighted_mat)\n",
    "net_weighted = Network(\n",
    "    adj=weighted_sparse,\n",
    "    preprocessing=\"giant_cc\",\n",
    "    name=\"Neural Functional Network (Weighted)\"\n",
    ")\n",
    "\n",
    "print(f\"Binary network: {net_binary.n} nodes, {net_binary.graph.number_of_edges()} edges\")\n",
    "print(f\"Weighted network: {net_weighted.n} nodes, {net_weighted.graph.number_of_edges()} edges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd585411",
   "metadata": {},
   "source": [
    "## 1. Network structure\n",
    "\n",
    "Binary and weighted network properties: degree distribution,\n",
    "connected components, clustering, module detection via Louvain\n",
    "community detection, and comparison against a degree-preserving\n",
    "null model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86785324",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Network properties analysis\")\n",
    "\n",
    "# Basic properties\n",
    "net = net_weighted\n",
    "print(f\"Network type: {'Directed' if net.directed else 'Undirected'}, \"\n",
    "      f\"{'Weighted' if net.weighted else 'Binary'}\")\n",
    "print(f\"Number of nodes: {net.n}\")\n",
    "print(f\"Number of edges: {net.graph.number_of_edges()}\")\n",
    "\n",
    "# Degree statistics\n",
    "degrees = [d for n, d in net.graph.degree()]\n",
    "print(f\"Average degree: {np.mean(degrees):.2f} +- {np.std(degrees):.2f}\")\n",
    "print(f\"Max degree: {np.max(degrees)}\")\n",
    "\n",
    "# Clustering coefficient\n",
    "if not net.directed:\n",
    "    clustering = nx.average_clustering(net.graph)\n",
    "    print(f\"Average clustering coefficient: {clustering:.3f}\")\n",
    "\n",
    "# Connected components\n",
    "if net.directed:\n",
    "    n_weak = nx.number_weakly_connected_components(net.graph)\n",
    "    n_strong = nx.number_strongly_connected_components(net.graph)\n",
    "    print(f\"Weakly connected components: {n_weak}\")\n",
    "    print(f\"Strongly connected components: {n_strong}\")\n",
    "else:\n",
    "    n_cc = nx.number_connected_components(net.graph)\n",
    "    print(f\"Connected components: {n_cc}\")\n",
    "\n",
    "# Spectral properties\n",
    "print(\"\\nSpectral analysis:\")\n",
    "adj_spectrum = net.get_spectrum(\"adj\")\n",
    "print(f\"Largest eigenvalue (spectral radius): {np.max(np.abs(adj_spectrum)):.3f}\")\n",
    "\n",
    "if not net.directed:\n",
    "    lap_spectrum = net.get_spectrum(\"lap\")\n",
    "    # Second smallest eigenvalue (algebraic connectivity)\n",
    "    sorted_lap = np.sort(np.real(lap_spectrum))\n",
    "    if len(sorted_lap) > 1:\n",
    "        print(f\"Algebraic connectivity: {sorted_lap[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cc6938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted network: weight distribution\n",
    "if net.weighted:\n",
    "    edges = net.graph.edges(data=True)\n",
    "    weights = [d[\"weight\"] for _, _, d in edges]\n",
    "    print(f\"Weight statistics:\")\n",
    "    print(f\"  Mean weight: {np.mean(weights):.4f}\")\n",
    "    print(f\"  Std weight:  {np.std(weights):.4f}\")\n",
    "    print(f\"  Min weight:  {np.min(weights):.4f}\")\n",
    "    print(f\"  Max weight:  {np.max(weights):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1778eb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Detecting functional modules\")\n",
    "\n",
    "# Use Louvain community detection\n",
    "# For weighted network, use weight attribute\n",
    "if net.weighted:\n",
    "    communities = nx_comm.louvain_communities(net.graph, weight=\"weight\", seed=42)\n",
    "else:\n",
    "    communities = nx_comm.louvain_communities(net.graph, seed=42)\n",
    "\n",
    "print(f\"Found {len(communities)} functional modules:\")\n",
    "for i, community in enumerate(communities):\n",
    "    print(f\"  Module {i+1}: {len(community)} neurons\")\n",
    "\n",
    "# Create module assignment dictionary\n",
    "module_assignment = {}\n",
    "for module_idx, community in enumerate(communities):\n",
    "    for node in community:\n",
    "        module_assignment[node] = module_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8748c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Null model comparison (degree-preserving randomization)\")\n",
    "\n",
    "n_replicates = 10\n",
    "\n",
    "# Real network properties\n",
    "real_clustering = nx.average_clustering(net.graph)\n",
    "real_modularity = nx_comm.modularity(net.graph, communities)\n",
    "lap_spectrum = net.get_spectrum(\"lap\")\n",
    "real_connectivity = np.sort(np.real(lap_spectrum))[1]\n",
    "\n",
    "# Generate random networks and measure properties\n",
    "null_clustering = []\n",
    "null_modularity = []\n",
    "null_connectivity = []\n",
    "\n",
    "for i in range(n_replicates):\n",
    "    rand_net = net.randomize(rmode=\"adj_iom\")\n",
    "    null_clustering.append(nx.average_clustering(rand_net.graph))\n",
    "    rand_comms = nx_comm.louvain_communities(rand_net.graph, seed=i)\n",
    "    null_modularity.append(nx_comm.modularity(rand_net.graph, rand_comms))\n",
    "    rand_lap = rand_net.get_spectrum(\"lap\")\n",
    "    null_connectivity.append(np.sort(np.real(rand_lap))[1])\n",
    "\n",
    "# Print comparison table\n",
    "print(f\"\\n  {'Metric':<25s} {'Real':>8s} {'Null (mean +/- std)':>22s}\")\n",
    "print(f\"  {'-' * 57}\")\n",
    "\n",
    "rows = [\n",
    "    (\"Clustering coefficient\", real_clustering, null_clustering),\n",
    "    (\"Modularity\", real_modularity, null_modularity),\n",
    "    (\"Algebraic connectivity\", real_connectivity, null_connectivity),\n",
    "]\n",
    "for name, real_val, null_vals in rows:\n",
    "    null_mean = np.mean(null_vals)\n",
    "    null_std = np.std(null_vals)\n",
    "    print(f\"  {name:<25s} {real_val:>8.3f} {null_mean:>10.3f} +/- {null_std:.3f}\")\n",
    "\n",
    "print(f\"\\n  Replicates: {n_replicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f5e66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: adjacency matrix, degree distribution, network graph\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "\n",
    "# Get unique modules and create consistent color mapping\n",
    "unique_modules = sorted(set(module_assignment.values()))\n",
    "n_modules = len(unique_modules)\n",
    "module_colors = plt.cm.tab10(np.linspace(0, 1, n_modules))\n",
    "module_to_color = {mod: module_colors[i] for i, mod in enumerate(unique_modules)}\n",
    "\n",
    "# 1. Similarity matrix\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "im1 = ax1.imshow(sim_mat, cmap=\"hot\", aspect=\"auto\")\n",
    "ax1.set_title(\"Similarity matrix (MI)\", fontsize=12)\n",
    "ax1.set_xlabel(\"Neuron ID\")\n",
    "ax1.set_ylabel(\"Neuron ID\")\n",
    "plt.colorbar(im1, ax=ax1, fraction=0.046)\n",
    "\n",
    "# Add module boundaries if known (for 30/30/30/10/10/10 structure)\n",
    "if module_sizes_true is not None:\n",
    "    cumsum = np.cumsum([0] + module_sizes_true)\n",
    "    for boundary in cumsum[1:-1]:\n",
    "        ax1.axhline(boundary - 0.5, color=\"cyan\", linewidth=2)\n",
    "        ax1.axvline(boundary - 0.5, color=\"cyan\", linewidth=2)\n",
    "\n",
    "# 2. Significance matrix\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "ax2.imshow(sig_mat, cmap=\"RdBu_r\", aspect=\"auto\", vmin=0, vmax=1)\n",
    "ax2.set_title(\"Significance matrix\", fontsize=12)\n",
    "ax2.set_xlabel(\"Neuron ID\")\n",
    "ax2.set_ylabel(\"Neuron ID\")\n",
    "\n",
    "# 3. Network visualization with modules using spring layout\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "\n",
    "# Use spring layout with parameters optimized for clustering\n",
    "pos = nx.spring_layout(\n",
    "    net.graph,\n",
    "    k=1.5/np.sqrt(len(net.graph)),  # Optimal distance\n",
    "    iterations=100,  # More iterations for better convergence\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Draw nodes colored by detected module\n",
    "node_colors = [module_to_color[module_assignment[node]] for node in net.graph.nodes()]\n",
    "nx.draw_networkx_nodes(\n",
    "    net.graph, pos,\n",
    "    node_color=node_colors,\n",
    "    node_size=20,  # Smaller for 300 nodes\n",
    "    ax=ax3,\n",
    "    alpha=0.8\n",
    ")\n",
    "\n",
    "# Draw edges\n",
    "if net.weighted:\n",
    "    edges = net.graph.edges()\n",
    "    weights = [net.graph[u][v][\"weight\"] for u, v in edges]\n",
    "    nx.draw_networkx_edges(net.graph, pos, alpha=0.1, width=weights, ax=ax3)\n",
    "else:\n",
    "    nx.draw_networkx_edges(net.graph, pos, alpha=0.1, ax=ax3)\n",
    "\n",
    "ax3.set_title(\"Functional network modules\", fontsize=12)\n",
    "ax3.axis(\"off\")\n",
    "\n",
    "# 4. Degree distribution\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "degrees = [d for n, d in net.graph.degree()]\n",
    "ax4.hist(degrees, bins=20, alpha=0.7, color=\"blue\", edgecolor=\"black\")\n",
    "ax4.set_xlabel(\"Degree\")\n",
    "ax4.set_ylabel(\"Count\")\n",
    "ax4.set_title(\"Degree distribution\", fontsize=12)\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Module size distribution\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "detected_sizes = {}\n",
    "for node, module in module_assignment.items():\n",
    "    detected_sizes[module] = detected_sizes.get(module, 0) + 1\n",
    "\n",
    "modules = sorted(detected_sizes.keys())\n",
    "sizes = [detected_sizes[m] for m in modules]\n",
    "colors = [module_to_color[m] for m in modules]\n",
    "\n",
    "ax5.bar(modules, sizes, color=colors)\n",
    "ax5.set_xlabel(\"Module ID\")\n",
    "ax5.set_ylabel(\"Number of neurons\")\n",
    "ax5.set_title(\"Module sizes\", fontsize=12)\n",
    "ax5.grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "# 6. Similarity distribution\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "# Get upper triangle p-values (excluding diagonal)\n",
    "triu_indices = np.triu_indices_from(sig_mat, k=1)\n",
    "pvals_upper = sim_mat[triu_indices]\n",
    "\n",
    "ax6.hist(pvals_upper, bins=50, alpha=0.7, color=\"green\", edgecolor=\"black\")\n",
    "ax6.set_xlabel(\"Similarity (MI)\")\n",
    "ax6.set_ylabel(\"Count\")\n",
    "ax6.set_title(\"Similarity distribution\", fontsize=12)\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e772bb40",
   "metadata": {},
   "source": [
    "### Save and load\n",
    "\n",
    "Demonstrate sparse save/load roundtrip for the network adjacency,\n",
    "similarity, and p-value matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6254e3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save/load sparse roundtrip\n",
    "def save_network(filename, sim_mat, sig_mat, pval_mat, cells, info):\n",
    "    \"\"\"\n",
    "    Save network as sparse adjacency matrix with essential metadata only.\n",
    "\n",
    "    Saves only:\n",
    "    - Sparse adjacency matrix (significant connections)\n",
    "    - Similarity/p-values for significant edges only\n",
    "    - Cell IDs and scalar metadata\n",
    "    - Excludes large shuffle arrays (random_shifts, me_total)\n",
    "    \"\"\"\n",
    "    # Get indices of significant connections\n",
    "    sig_indices = np.where(sig_mat > 0)\n",
    "\n",
    "    # Extract only significant edges (sparse format)\n",
    "    sparse_data = {\n",
    "        \"sig_mat_data\": sig_mat[sig_indices],  # Binary significance\n",
    "        \"sim_values\": sim_mat[sig_indices],    # Similarity for significant edges\n",
    "        \"pval_values\": pval_mat[sig_indices],  # P-values for significant edges\n",
    "        \"sig_indices_i\": sig_indices[0],       # Row indices\n",
    "        \"sig_indices_j\": sig_indices[1],       # Column indices\n",
    "        \"matrix_shape\": np.array(sig_mat.shape),  # Shape for reconstruction\n",
    "        \"cells\": np.array(cells),\n",
    "    }\n",
    "\n",
    "    # Add optimal delays if available (only for significant edges)\n",
    "    if \"optimal_delays\" in info:\n",
    "        sparse_data[\"optimal_delays\"] = info[\"optimal_delays\"][sig_indices]\n",
    "\n",
    "    # Add only scalar metadata (exclude huge shuffle arrays!)\n",
    "    exclude_keys = {\"random_shifts1\", \"me_total1\", \"random_shifts2\", \"me_total2\"}\n",
    "    for k, v in info.items():\n",
    "        if k not in exclude_keys and isinstance(v, (int, float, str, np.integer, np.floating)):\n",
    "            sparse_data[f\"info_{k}\"] = v\n",
    "\n",
    "    # Save as compressed NPZ\n",
    "    filename = filename if filename.endswith(\".npz\") else f\"{filename}.npz\"\n",
    "    np.savez_compressed(filename, **sparse_data)\n",
    "\n",
    "    # Report size savings\n",
    "    n_sig = len(sig_indices[0])\n",
    "    n_total = sig_mat.shape[0] * sig_mat.shape[1]\n",
    "    density = n_sig / n_total\n",
    "    print(f\"Network saved to {filename}\")\n",
    "    print(f\"  Significant edges: {n_sig}/{n_total} ({density*100:.2f}% density)\")\n",
    "    print(f\"  Sparse storage: ~{n_sig * 32 / 1024:.1f} KB (vs {n_total * 8 / 1024:.1f} KB full matrix)\")\n",
    "\n",
    "\n",
    "def load_network(filename):\n",
    "    \"\"\"\n",
    "    Load network from sparse format.\n",
    "    \"\"\"\n",
    "    if not filename.endswith(\".npz\"):\n",
    "        filename = f\"{filename}.npz\"\n",
    "\n",
    "    data = np.load(filename, allow_pickle=True)\n",
    "\n",
    "    # Load sparse format\n",
    "    shape = tuple(data[\"matrix_shape\"])\n",
    "    sig_indices_i = data[\"sig_indices_i\"]\n",
    "    sig_indices_j = data[\"sig_indices_j\"]\n",
    "\n",
    "    # Initialize full matrices\n",
    "    sig_mat_loaded = np.zeros(shape)\n",
    "    sim_mat_loaded = np.zeros(shape)\n",
    "    pval_mat_loaded = np.ones(shape)  # Initialize with 1.0 (non-significant)\n",
    "\n",
    "    # Fill in significant edges\n",
    "    sig_mat_loaded[sig_indices_i, sig_indices_j] = data[\"sig_mat_data\"]\n",
    "    sim_mat_loaded[sig_indices_i, sig_indices_j] = data[\"sim_values\"]\n",
    "    pval_mat_loaded[sig_indices_i, sig_indices_j] = data[\"pval_values\"]\n",
    "\n",
    "    cells_loaded = data[\"cells\"].tolist()\n",
    "\n",
    "    # Reconstruct info dict (with optimal delays if present)\n",
    "    info_loaded = {}\n",
    "    if \"optimal_delays\" in data:\n",
    "        info_loaded[\"optimal_delays\"] = np.zeros(shape)\n",
    "        info_loaded[\"optimal_delays\"][sig_indices_i, sig_indices_j] = data[\"optimal_delays\"]\n",
    "\n",
    "    # Add scalar metadata\n",
    "    for k, v in data.items():\n",
    "        if k.startswith(\"info_\"):\n",
    "            info_loaded[k.replace(\"info_\", \"\")] = v\n",
    "\n",
    "    print(f\"Network loaded from {filename}\")\n",
    "    print(f\"  Neurons: {len(cells_loaded)}\")\n",
    "    print(f\"  Significant connections: {len(sig_indices_i) // 2:.0f} (undirected)\")\n",
    "\n",
    "    return sim_mat_loaded, sig_mat_loaded, pval_mat_loaded, cells_loaded, info_loaded\n",
    "\n",
    "\n",
    "# Roundtrip demo using a temporary file\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    tmp_path = tmpdir + \"/test_network\"\n",
    "    save_network(tmp_path, sim_mat, sig_mat, pval_mat, cells_list, info)\n",
    "\n",
    "    sim_rt, sig_rt, pval_rt, cells_rt, info_rt = load_network(tmp_path)\n",
    "\n",
    "    # Verify roundtrip\n",
    "    assert np.allclose(sim_mat * sig_mat, sim_rt * sig_rt), \"Similarity mismatch!\"\n",
    "    assert np.array_equal(sig_mat, sig_rt), \"Significance mismatch!\"\n",
    "    print(\"\\nRoundtrip verification: OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8658a8e8",
   "metadata": {},
   "source": [
    "> **Cross-reference:** The spectral analysis below applies to *any*\n",
    "> [`Network`](https://driada.readthedocs.io/en/latest/api/network/core.html#driada.network.net_base.Network) object -- not just cell-cell functional networks. Graph-based\n",
    "> DR methods (Isomap, LLE, Laplacian Eigenmaps) construct a\n",
    "> `ProximityGraph` that inherits from `Network`, so all the spectral,\n",
    "> entropy, and community analysis shown below works on DR graphs too.\n",
    "> See the \"Graph structure behind DR\" subsection of\n",
    "> [Notebook 03](https://colab.research.google.com/github/iabs-neuro/driada/blob/main/notebooks/03_population_geometry_dr.ipynb)\n",
    "> for a demonstration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c72db0",
   "metadata": {},
   "source": [
    "## 2. Spectral analysis\n",
    "\n",
    "Eigendecomposition of the adjacency and normalized Laplacian matrices\n",
    "reveals global structure that is invisible to local metrics.\n",
    "\n",
    "**Adjacency spectrum.** The adjacency eigenvalues reflect community\n",
    "structure: isolated clusters produce near-degenerate eigenvalue groups.\n",
    "The spectral radius (largest $|\\lambda|$) scales with the mean degree\n",
    "for random graphs.\n",
    "\n",
    "**Normalized Laplacian.**\n",
    "$L_{\\text{norm}} = I - D^{-1/2} A D^{-1/2}$\n",
    "has eigenvalues bounded in $[0, 2]$ regardless of network size or degree\n",
    "distribution, making it suitable for cross-network comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67de889",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_spectral = net_binary\n",
    "\n",
    "print(\"Eigendecomposition\")\n",
    "\n",
    "adj_spectrum = net_spectral.get_spectrum(\"adj\")\n",
    "print(f\"\\nAdjacency matrix:\")\n",
    "print(f\"  Spectral radius (max |lambda|): {np.max(np.abs(adj_spectrum)):.3f}\")\n",
    "print(f\"  Min eigenvalue: {np.min(np.real(adj_spectrum)):.3f}\")\n",
    "print(f\"  Max eigenvalue: {np.max(np.real(adj_spectrum)):.3f}\")\n",
    "\n",
    "nlap_spectrum = net_spectral.get_spectrum(\"nlap\")\n",
    "sorted_nlap = np.sort(np.real(nlap_spectrum))\n",
    "\n",
    "# Each zero eigenvalue corresponds to one connected component.\n",
    "# Since we extracted the giant connected component, expect exactly 1.\n",
    "n_zero = int(np.sum(np.abs(sorted_nlap) < 1e-6))\n",
    "n_components = n_zero\n",
    "\n",
    "print(f\"\\nNormalized Laplacian (L = I - D^(-1/2) A D^(-1/2)):\")\n",
    "print(f\"  Eigenvalue range: [0, 2]\")\n",
    "print(f\"  Smallest eigenvalue: {sorted_nlap[0]:.6f}\")\n",
    "print(f\"  Zero eigenvalues: {n_zero}  (= number of connected components)\")\n",
    "if n_components == 1:\n",
    "    print(f\"  Graph is connected (single component)\")\n",
    "else:\n",
    "    print(f\"  WARNING: graph has {n_components} disconnected components\")\n",
    "\n",
    "# The Fiedler value (first non-zero eigenvalue) is the algebraic\n",
    "# connectivity of the normalized Laplacian. Larger values indicate\n",
    "# a graph that is harder to disconnect by removing edges.\n",
    "if len(sorted_nlap) > n_zero:\n",
    "    fiedler = sorted_nlap[n_zero]\n",
    "    print(f\"  Fiedler value (lambda_{n_zero + 1}): {fiedler:.4f}\")\n",
    "    print(f\"    (Algebraic connectivity -- larger = harder to disconnect)\")\n",
    "print(f\"  Spectral gap: {sorted_nlap[n_zero] - sorted_nlap[0]:.4f}\")\n",
    "print(f\"  Largest eigenvalue: {sorted_nlap[-1]:.4f}\")\n",
    "\n",
    "adj_vecs = net_spectral.get_eigenvectors(\"adj\")\n",
    "print(f\"\\nAdjacency eigenvectors: {adj_vecs.shape}  (N x N matrix)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee75e4db",
   "metadata": {},
   "source": [
    "### Spectral metrics\n",
    "\n",
    "**IPR (Inverse Participation Ratio):**\n",
    "$\\text{IPR} = \\sum_i |v_i|^4$ for each eigenvector $v$.\n",
    "For a vector uniformly spread over $N$ nodes, $\\text{IPR} = 1/N$.\n",
    "For a vector concentrated on one node, $\\text{IPR} = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ada0111",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"IPR analysis (eigenvector localization)\")\n",
    "\n",
    "ipr_adj = net_spectral.get_ipr(\"adj\")\n",
    "ipr_nlap = net_spectral.get_ipr(\"nlap\")\n",
    "\n",
    "delocalized_bound = 1.0 / net_spectral.n\n",
    "\n",
    "print(f\"\\nAdjacency IPR:\")\n",
    "print(f\"  Mean: {np.mean(ipr_adj):.4f}\")\n",
    "print(f\"  Min:  {np.min(ipr_adj):.4f}  (delocalized bound 1/N = {delocalized_bound:.4f})\")\n",
    "print(f\"  Max:  {np.max(ipr_adj):.4f}\")\n",
    "\n",
    "print(f\"\\nNormalized Laplacian IPR:\")\n",
    "print(f\"  Mean: {np.mean(ipr_nlap):.4f}\")\n",
    "print(f\"  Min:  {np.min(ipr_nlap):.4f}\")\n",
    "print(f\"  Max:  {np.max(ipr_nlap):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9545c090",
   "metadata": {},
   "source": [
    "**Complex spacing ratios.**\n",
    "For a symmetric (Hermitian) matrix all eigenvalues are real, so the\n",
    "complex spacing ratios $z = (\\lambda_{\\text{nn}} - \\lambda) /\n",
    "(\\lambda_{\\text{nnn}} - \\lambda)$ collapse to the real line and\n",
    "$\\arg(z)$ is either $0$ or $\\pi$. `get_z_values` builds a\n",
    "$k$-d tree in the complex plane and returns one ratio per unique\n",
    "eigenvalue.\n",
    "\n",
    "**Localization signatures.**\n",
    "$\\langle\\cos(\\arg z)\\rangle$ measures phase coherence of spacing ratios;\n",
    "$\\langle 1/|z|^2 \\rangle$ amplifies cases where nearest and next-nearest\n",
    "neighbour distances differ strongly. Zero $z$-values (from degenerate\n",
    "eigenvalues) are filtered internally to avoid singularities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645e608c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Spacing ratios and localization signatures\")\n",
    "\n",
    "z_dict = net_spectral.get_z_values(\"nlap\")\n",
    "\n",
    "# Discard the z-value for the zero eigenvalue (one per connected component).\n",
    "# It is trivial and would distort 1/|z|^2 statistics.\n",
    "z_filtered = {k: v for k, v in z_dict.items() if np.abs(k) > 1e-6}\n",
    "n_discarded = len(z_dict) - len(z_filtered)\n",
    "z_list = np.array(list(z_filtered.values()))\n",
    "z_mags = np.abs(z_list)\n",
    "\n",
    "print(f\"\\n  Total eigenvalues with z-values: {len(z_dict)}\")\n",
    "print(f\"  Discarded (zero eigenvalues): {n_discarded}\")\n",
    "print(f\"  Used for analysis: {len(z_filtered)}\")\n",
    "\n",
    "print(f\"\\nComplex spacing ratios z = (lambda_nn - lambda) / (lambda_nnn - lambda):\")\n",
    "print(f\"  Count: {len(z_list)}\")\n",
    "print(f\"  Mean |z|: {np.mean(z_mags):.4f}  (bounded in [0, 1])\")\n",
    "print(f\"  Std |z|:  {np.std(z_mags):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d059d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_inv_r2, mean_cos_phi = net_spectral.localization_signatures(\"nlap\")\n",
    "print(f\"\\nLocalization signatures (undirected, normalized Laplacian):\")\n",
    "print(f\"  <cos(arg(z))>: {mean_cos_phi:.4f}\")\n",
    "print(f\"  <1/|z|^2>:     {mean_inv_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcbb3a0",
   "metadata": {},
   "source": [
    "**Communicability.**\n",
    "Estrada communicability $\\text{EE} = \\sum_i \\exp(\\lambda_i)$ where\n",
    "$\\lambda_i$ are adjacency eigenvalues. This counts walks of all lengths,\n",
    "weighted by $1/k!$.\n",
    "\n",
    "**Bipartivity index.** Ratio of even-length to total weighted walks,\n",
    "using both $\\exp(\\lambda)$ and $\\exp(-\\lambda)$ of the adjacency spectrum.\n",
    "\n",
    "**Gromov hyperbolicity.** For every 4-point set, measures how far the\n",
    "shortest-path metric deviates from a tree metric.\n",
    "$\\delta = 0$ means the network is a tree; larger values indicate cycles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf087fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Communicability and network geometry\")\n",
    "\n",
    "comm = net_spectral.calculate_estrada_communicability()\n",
    "print(f\"\\nEstrada communicability index: {comm:.4g}\")\n",
    "\n",
    "bipartivity = net_spectral.get_estrada_bipartivity_index()\n",
    "print(f\"Estrada bipartivity index: {bipartivity:.4f}\")\n",
    "print(f\"  (1.0 = perfectly bipartite, 0.0 = far from bipartite)\")\n",
    "\n",
    "hyp = net_spectral.calculate_gromov_hyperbolicity(num_samples=50000)\n",
    "print(f\"\\nGromov hyperbolicity (mean delta): {hyp:.3f}\")\n",
    "print(f\"  (0 = tree-like, higher = more cycle-rich)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5ca9ec",
   "metadata": {},
   "source": [
    "**Thermodynamic entropy.**\n",
    "Temperature sweep: low $t$ probes local structure, high $t$ probes global.\n",
    "\n",
    "- **Von Neumann entropy:** $S(t) = -\\sum_i p_i \\log_2 p_i$ where\n",
    "  $p_i = \\exp(-\\lambda_i / t) / Z$ is the Boltzmann distribution over\n",
    "  normalized Laplacian eigenvalues.\n",
    "- **Free entropy:** $F(t) = \\log_2 Z$ where $Z = \\sum_i \\exp(-\\lambda_i / t)$.\n",
    "- **Renyi $q$-entropy:** $S_q(t) = \\log_2(\\sum_i p_i^q) / (1 - q)$.\n",
    "  At $q = 2$, this is related to the purity of the Gibbs state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39f2ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Thermodynamic entropy analysis\")\n",
    "\n",
    "tlist = np.logspace(-2, 2, 50)\n",
    "\n",
    "vn_entropy = net_spectral.calculate_thermodynamic_entropy(tlist, norm=True)\n",
    "print(f\"\\nVon Neumann entropy S(t) [normalized Laplacian]:\")\n",
    "print(f\"  At t=0.01: {vn_entropy[0]:.3f} bits\")\n",
    "print(f\"  At t=1.00: {vn_entropy[len(tlist) // 2]:.3f} bits\")\n",
    "print(f\"  At t=100:  {vn_entropy[-1]:.3f} bits\")\n",
    "print(f\"  Max entropy: {np.max(vn_entropy):.3f} bits\"\n",
    "      f\"  (upper bound = log2(N) = {np.log2(net_spectral.n):.2f})\")\n",
    "\n",
    "free_ent = net_spectral.calculate_free_entropy(tlist, norm=True)\n",
    "print(f\"\\nFree entropy F(t) = log2(Z):\")\n",
    "print(f\"  At t=0.01: {free_ent[0]:.3f}\")\n",
    "print(f\"  At t=100:  {free_ent[-1]:.3f}\")\n",
    "\n",
    "q_ent = net_spectral.calculate_q_entropy(q=2, tlist=tlist, norm=True)\n",
    "print(f\"\\nRenyi 2-entropy S_2(t):\")\n",
    "print(f\"  At t=0.01: {q_ent[0]:.3f} bits\")\n",
    "print(f\"  At t=100:  {q_ent[-1]:.3f} bits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a365a7dc",
   "metadata": {},
   "source": [
    "### Laplacian Eigenmaps embedding\n",
    "\n",
    "LEM uses the normalized Laplacian and selects the smallest non-zero\n",
    "eigenvectors as embedding coordinates. Nearby nodes in the graph map\n",
    "to nearby points in the embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660813d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Laplacian Eigenmaps embedding\")\n",
    "\n",
    "dim = 3\n",
    "net_spectral.construct_lem_embedding(dim)\n",
    "\n",
    "# Access stored embedding (shape: dim x n_nodes)\n",
    "if hasattr(net_spectral.lem_emb, \"toarray\"):\n",
    "    emb_data = np.real(net_spectral.lem_emb.toarray())\n",
    "else:\n",
    "    emb_data = np.real(np.asarray(net_spectral.lem_emb))\n",
    "\n",
    "print(f\"\\nLEM embedding ({dim}D):\")\n",
    "print(f\"  Shape: {emb_data.shape}\")\n",
    "print(f\"  Dim 1 range: [{emb_data[0].min():.3f}, {emb_data[0].max():.3f}]\")\n",
    "print(f\"  Dim 2 range: [{emb_data[1].min():.3f}, {emb_data[1].max():.3f}]\")\n",
    "print(f\"  Dim 3 range: [{emb_data[2].min():.3f}, {emb_data[2].max():.3f}]\")\n",
    "\n",
    "# Plot LEM embedding colored by detected module\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "# Map nodes in the spectral network to their modules\n",
    "node_list = list(net_spectral.graph.nodes())\n",
    "node_module_colors = [module_to_color.get(module_assignment.get(n, 0), \"gray\") for n in node_list]\n",
    "ax.scatter(emb_data[0], emb_data[1], s=15, alpha=0.7, c=node_module_colors, edgecolors=\"none\")\n",
    "ax.set_xlabel(\"LEM dim 1\")\n",
    "ax.set_ylabel(\"LEM dim 2\")\n",
    "ax.set_title(\"Laplacian Eigenmaps (colored by module)\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058b3124",
   "metadata": {},
   "source": [
    "### Directed variant\n",
    "\n",
    "Randomly orienting edges breaks the Hermitian symmetry, giving complex\n",
    "eigenvalues and $z$-values that spread across the complex plane. This\n",
    "demonstrates the full capability of the complex spacing ratio framework.\n",
    "In practice, directed networks arise from causal or effective\n",
    "connectivity (e.g. Granger causality, transfer entropy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d6e390",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_adj = turn_to_partially_directed(net_spectral.adj, directed=1.0)\n",
    "dir_net = Network(adj=dir_adj, preprocessing=None, name=\"Directed variant\")\n",
    "\n",
    "z_dict_dir = dir_net.get_z_values(\"adj\")\n",
    "z_list_dir = np.array(list(z_dict_dir.values()))\n",
    "z_mags_dir = np.abs(z_list_dir)\n",
    "\n",
    "print(f\"\\nDirected variant (randomly oriented edges):\")\n",
    "print(f\"  Eigenvalues: {len(z_dict_dir)} (complex)\")\n",
    "print(f\"  Mean |z|: {np.mean(z_mags_dir):.4f}\")\n",
    "print(f\"  Std |z|:  {np.std(z_mags_dir):.4f}\")\n",
    "\n",
    "mean_inv_r2_d, mean_cos_phi_d = dir_net.localization_signatures(\"adj\")\n",
    "print(f\"\\nLocalization signatures (directed adjacency):\")\n",
    "print(f\"  <cos(arg(z))>: {mean_cos_phi_d:.4f}\")\n",
    "print(f\"  <1/|z|^2>:     {mean_inv_r2_d:.4f}\")\n",
    "\n",
    "# Plot complex eigenvalues\n",
    "dir_spectrum = dir_net.get_spectrum(\"adj\")\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.scatter(np.real(dir_spectrum), np.imag(dir_spectrum), s=20, alpha=0.6,\n",
    "           c=\"steelblue\", edgecolors=\"none\")\n",
    "theta = np.linspace(0, 2 * np.pi, 200)\n",
    "r_max = np.max(np.abs(dir_spectrum))\n",
    "ax.plot(r_max * np.cos(theta), r_max * np.sin(theta), \"k--\", alpha=0.3, linewidth=0.8)\n",
    "ax.set_xlabel(\"Re(lambda)\")\n",
    "ax.set_ylabel(\"Im(lambda)\")\n",
    "ax.set_title(\"Directed network eigenvalues\")\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2634f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Spectral null model comparison (degree-preserving randomization)\")\n",
    "\n",
    "real_ipr = np.mean(net_spectral.get_ipr(\"nlap\"))\n",
    "nlap_sorted = np.sort(np.real(net_spectral.get_spectrum(\"nlap\")))\n",
    "real_fiedler = nlap_sorted[nlap_sorted > 1e-6][0]\n",
    "\n",
    "n_replicates = 10\n",
    "null_comm = []\n",
    "null_bipart = []\n",
    "null_ipr = []\n",
    "null_fiedler = []\n",
    "\n",
    "for _ in range(n_replicates):\n",
    "    rand_net = net_spectral.randomize(rmode=\"adj_iom\")\n",
    "    null_comm.append(rand_net.calculate_estrada_communicability())\n",
    "    null_bipart.append(rand_net.get_estrada_bipartivity_index())\n",
    "    null_ipr.append(np.mean(rand_net.get_ipr(\"nlap\")))\n",
    "    rand_nlap = np.sort(np.real(rand_net.get_spectrum(\"nlap\")))\n",
    "    nonzero = rand_nlap[rand_nlap > 1e-6]\n",
    "    null_fiedler.append(nonzero[0] if len(nonzero) > 0 else 0.0)\n",
    "\n",
    "print(f\"\\n  {'Metric':<28s} {'Real':>12s} {'Null (mean +/- std)':>25s}\")\n",
    "print(f\"  {'-' * 67}\")\n",
    "\n",
    "rows = [\n",
    "    (\"Communicability\", comm, null_comm),\n",
    "    (\"Bipartivity\", bipartivity, null_bipart),\n",
    "    (\"Mean nlap IPR\", real_ipr, null_ipr),\n",
    "    (\"Fiedler value\", real_fiedler, null_fiedler),\n",
    "]\n",
    "for name, real_val, null_vals in rows:\n",
    "    null_mean = np.mean(null_vals)\n",
    "    null_std = np.std(null_vals)\n",
    "    print(f\"  {name:<28s} {real_val:>12.4g} {null_mean:>12.4g} +/- {null_std:.4g}\")\n",
    "\n",
    "print(f\"\\n  Replicates: {n_replicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8426e003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2x3 spectral summary figure\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 11))\n",
    "\n",
    "# 1. Adjacency spectrum histogram\n",
    "ax = axes[0, 0]\n",
    "real_spec = np.real(adj_spectrum)\n",
    "nbins = int(np.ceil(np.log2(len(real_spec)))) + 1\n",
    "ax.hist(real_spec, bins=nbins, edgecolor=\"black\", linewidth=0.5, alpha=0.8)\n",
    "ax.set_xlabel(\"Eigenvalue\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Adjacency spectrum\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Normalized Laplacian IPR (sorted by magnitude)\n",
    "ax = axes[0, 1]\n",
    "ax.plot(np.sort(ipr_nlap), \"o-\", markersize=2, linewidth=0.8)\n",
    "ax.axhline(1.0 / net_spectral.n, color=\"r\", linestyle=\"--\", label=f\"1/N = {1.0/net_spectral.n:.4f}\")\n",
    "ax.set_xlabel(\"Eigenvector index (sorted)\")\n",
    "ax.set_ylabel(\"IPR\")\n",
    "ax.set_title(\"Normalized Laplacian IPR\")\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Thermodynamic entropy curve\n",
    "ax = axes[0, 2]\n",
    "ax.semilogx(tlist, vn_entropy, \"b-\", linewidth=2)\n",
    "ax.set_xlabel(\"Temperature (t)\")\n",
    "ax.set_ylabel(\"Entropy (bits)\")\n",
    "ax.set_title(\"Von Neumann entropy S(t)\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Complex spacing ratio density (directed network).\n",
    "# Randomly orienting edges breaks the Hermitian symmetry, giving\n",
    "# complex eigenvalues whose z-values spread across the unit disk.\n",
    "# The density pattern is a fingerprint of the spectral universality class.\n",
    "ax = axes[1, 0]\n",
    "zr, zi = np.real(z_list_dir), np.imag(z_list_dir)\n",
    "xy = np.vstack([zr, zi])\n",
    "kde = gaussian_kde(xy, bw_method=0.25)\n",
    "grid_n = 200\n",
    "pad = 0.15\n",
    "xmin, xmax = zr.min() - pad, zr.max() + pad\n",
    "ymin, ymax = zi.min() - pad, zi.max() + pad\n",
    "xg = np.linspace(xmin, xmax, grid_n)\n",
    "yg = np.linspace(ymin, ymax, grid_n)\n",
    "Xg, Yg = np.meshgrid(xg, yg)\n",
    "Z = kde(np.vstack([Xg.ravel(), Yg.ravel()])).reshape(grid_n, grid_n)\n",
    "ax.pcolormesh(Xg, Yg, Z, shading=\"auto\", cmap=\"inferno\")\n",
    "# Unit circle for reference (|z| <= 1)\n",
    "theta = np.linspace(0, 2 * np.pi, 200)\n",
    "ax.plot(np.cos(theta), np.sin(theta), \"w--\", linewidth=0.8, alpha=0.5)\n",
    "ax.set_xlabel(\"Re(z)\")\n",
    "ax.set_ylabel(\"Im(z)\")\n",
    "ax.set_title(\"Complex spacing ratios (directed)\")\n",
    "ax.set_aspect(\"equal\")\n",
    "\n",
    "# 5. LEM embedding (first 2 dims)\n",
    "ax = axes[1, 1]\n",
    "ax.scatter(emb_data[0], emb_data[1], s=15, alpha=0.7, c=\"steelblue\", edgecolors=\"none\")\n",
    "ax.set_xlabel(\"LEM dim 1\")\n",
    "ax.set_ylabel(\"LEM dim 2\")\n",
    "ax.set_title(\"Laplacian Eigenmaps\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Real vs null communicability\n",
    "ax = axes[1, 2]\n",
    "ax.hist(null_comm, bins=8, edgecolor=\"black\", linewidth=0.5, alpha=0.6,\n",
    "        color=\"gray\", label=\"Null model\")\n",
    "ax.axvline(comm, color=\"red\", linewidth=2, label=f\"Real = {comm:.1f}\")\n",
    "ax.set_xlabel(\"Communicability\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Real vs null model\")\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
